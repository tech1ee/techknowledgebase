---
title: "Garbage Collection: как компьютер убирает за тобой"
created: 2026-01-04
modified: 2026-02-13
type: deep-dive
reading_time: 26
difficulty: 5
study_status: not_started
mastery: 0
last_reviewed:
next_review:
status: published
tags:
  - topic/cs-foundations
  - type/deep-dive
  - level/intermediate
related:
  - "[[memory-model-fundamentals]]"
  - "[[reference-counting-arc]]"
prerequisites:
  - "[[memory-model-fundamentals]]"
---

# Garbage Collection: как компьютер убирает за тобой

> **TL;DR:** Garbage Collection — автоматическое освобождение неиспользуемой памяти. Изобретён в 1959 году для Lisp. Два базовых подхода: tracing (находим живое) и reference counting (считаем ссылки). Современные сборщики используют поколения (молодые объекты умирают быстро) и работают параллельно с программой. JVM предлагает 7 коллекторов для разных задач. Kotlin/Native использует mark-and-sweep без поколений.

---

## Prerequisites

| Тема | Зачем нужно | Где изучить |
|------|-------------|-------------|
| **Stack vs Heap** | GC работает с heap-памятью | [[memory-model-fundamentals]] |

---

## Терминология

| Термин | Что это | Аналогия |
|--------|---------|----------|
| **Garbage** | Объекты, к которым нет доступа | Грязные тарелки, которые больше никому не нужны |
| **Roots** | Точки входа в граф объектов (стек, глобальные переменные) | Входные двери в здание |
| **Reachable** | Объект, к которому можно добраться от roots | Комната, до которой можно дойти от входа |
| **Mark** | Пометить объект как живой | Наклейка "не выбрасывать" |
| **Sweep** | Удалить непомеченные объекты | Уборка всего без наклеек |
| **Compaction** | Дефрагментация — сдвинуть объекты вместе | Сложить книги на полке без пробелов |
| **STW (Stop-the-World)** | Пауза приложения для GC | Закрыть ресторан на санитарный день |
| **Generational** | Разделение heap на поколения | Отдельная корзина для скоропортящегося |

---

## ПОЧЕМУ существует Garbage Collection

### Проблема: ручное управление памятью

В [[memory-model-fundamentals]] мы разобрали, что heap-память требует явного управления. В языках C/C++ программист сам вызывает `malloc`/`free` или `new`/`delete`. Это создаёт целый класс ошибок:

```
┌─────────────────────────────────────────────────────────────────┐
│              ОШИБКИ РУЧНОГО УПРАВЛЕНИЯ ПАМЯТЬЮ                 │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│   Memory Leak          Забыл вызвать free()                    │
│   ──────────────       → память никогда не освободится         │
│                        → приложение "течёт"                    │
│                                                                 │
│   Use-After-Free       Используешь объект после free()         │
│   ──────────────       → undefined behavior                    │
│                        → crash или security vulnerability      │
│                                                                 │
│   Double-Free          Вызвал free() дважды для одного адреса  │
│   ──────────────       → corrupted heap                        │
│                        → crash                                 │
│                                                                 │
│   Dangling Pointer     Указатель на освобождённую память       │
│   ──────────────       → те же проблемы что use-after-free     │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

Эти ошибки коварны: программа может работать годами, пока не произойдёт "правильная" комбинация событий. Отладка занимает дни и недели.

### История: John McCarthy и Lisp (1959-1960)

В конце 1950-х John McCarthy в MIT работал над языком Lisp для искусственного интеллекта. Lisp манипулировал связанными списками, которые постоянно создавались и уничтожались. Ручное управление памятью было бы кошмаром.

McCarthy придумал элегантное решение: пусть компьютер сам определяет, какая память больше не используется. Он описал алгоритм mark-and-sweep всего в трёх абзацах своей статьи 1960 года. Термин "garbage collection" впервые появился именно там.

Интересно, что McCarthy сначала отложил реализацию GC, потому что тестировал только маленькие примеры. Когда память стала заканчиваться на реальных программах, команда быстро реализовала сборщик.

В том же 1960 году George E. Collins предложил альтернативный подход — reference counting. Вместо периодического обхода графа объектов, каждый объект хранит счётчик ссылок на себя. Когда счётчик обнуляется, объект сразу удаляется.

### Что на самом деле делает GC

Есть популярное заблуждение: "GC — это когда операционная среда автоматически освобождает неиспользуемую память". Raymond Chen из Microsoft объясняет, почему это неправильно:

> Это как сказать, что работа пожарного — "ездить на красной машине и поливать водой".

GC не столько освобождает память, сколько **симулирует компьютер с бесконечной памятью**. С точки зрения программиста, ты просто создаёшь объекты, и они существуют пока нужны. Не надо думать об освобождении — память как будто бесконечная.

---

## ЧТО такое Garbage Collection

### Главный вопрос: что считать мусором?

GC не может читать мысли программиста. Он использует консервативное приближение: **память считается нужной, если к ней можно добраться по ссылкам от известных "корней"**.

```
┌─────────────────────────────────────────────────────────────────┐
│                    ГРАФ ОБЪЕКТОВ В ПАМЯТИ                       │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│   ROOTS (корни)                                                 │
│   ├── Stack: локальные переменные                              │
│   ├── Globals: глобальные переменные                           │
│   └── CPU registers: текущие значения                          │
│                                                                 │
│         │                                                       │
│         ▼                                                       │
│   ┌─────────┐     ┌─────────┐     ┌─────────┐                  │
│   │ Object  │────▶│ Object  │────▶│ Object  │  ← REACHABLE     │
│   │    A    │     │    B    │     │    C    │                  │
│   └─────────┘     └─────────┘     └─────────┘                  │
│                                                                 │
│                                                                 │
│   ┌─────────┐     ┌─────────┐                                  │
│   │ Object  │────▶│ Object  │  ← UNREACHABLE (garbage)         │
│   │    D    │◀────│    E    │                                  │
│   └─────────┘     └─────────┘                                  │
│        ▲               │                                        │
│        └───────────────┘  (цикл!)                              │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

Объекты A, B, C достижимы от корней — они живые. Объекты D и E ссылаются друг на друга, но от корней к ним не добраться — это мусор.

### Два фундаментальных подхода

Исследователи из Cornell доказали интересный факт: tracing и reference counting — это дуалы друг друга, как материя и антиматерия. Tracing находит живые объекты и удаляет остальное. Reference counting находит мёртвые объекты (с нулевым счётчиком) и удаляет их.

Все реальные сборщики — гибриды этих двух подходов.

---

## Алгоритм Mark-and-Sweep: пошаговое объяснение

### Аналогия: инвентаризация на складе

Чтобы по-настоящему понять mark-and-sweep, представь себе огромный склад. На складе тысячи коробок. Некоторые нужны — к ним приходят люди, берут товар, приносят обратно. Другие забыты — их никто не заказывает, но они занимают место.

Как определить, какие коробки можно выбросить? Нельзя просто спросить каждую коробку "ты нужна?" — коробки не умеют отвечать. Но есть журнал заказов: список всех активных клиентов и того, что им нужно.

**Шаг 1 (Mark):** Берём журнал заказов (roots). Идём по каждому заказу: клиент A заказал коробку 7, в коробке 7 есть ссылка на коробку 12, а в 12 — на коробку 3. Клеим на каждую посещённую коробку наклейку "НУЖНА". Проходим так по всем заказам.

**Шаг 2 (Sweep):** Идём по всему складу. Все коробки без наклейки — выбрасываем. Те, что с наклейкой — снимаем наклейку (для следующей инвентаризации).

Вот и весь алгоритм. Он удивительно прост в идее, хотя дьявол, как всегда, в деталях.

### Формальное описание

Классический tracing GC работает в две фазы:

**Фаза 1: Mark (разметка).**

Начинаем с корней и обходим граф объектов в глубину (DFS) или в ширину (BFS). Каждый посещённый объект помечаем битом "живой". Для пометки используется один бит в заголовке объекта — поэтому overhead минимален.

```
Алгоритм MARK (словами):

1. Создать рабочий стек (worklist)
2. Поместить в worklist все корневые ссылки
3. Пока worklist не пуст:
   a. Извлечь объект из worklist
   b. Если объект уже помечен → пропустить
   c. Пометить объект битом "живой"
   d. Для каждой ссылки внутри объекта:
      - Добавить referenced объект в worklist
4. Готово: все достижимые объекты помечены
```

Обрати внимание на проверку "уже помечен" в пункте 3b. Без неё алгоритм зациклится на циклических ссылках (D ↔ E из примера выше). Это то, что делает mark-and-sweep устойчивым к циклам — в отличие от reference counting.

**Фаза 2: Sweep (уборка).**

Проходим по всей памяти heap линейно, от начала до конца. Непомеченные объекты — мусор, освобождаем их память, добавляя освободившийся блок в free list.

```
Алгоритм SWEEP (словами):

1. Установить указатель scan на начало heap
2. Пока scan не достиг конца heap:
   a. Если объект по адресу scan помечен:
      - Сбросить метку (для следующего цикла GC)
      - Сдвинуть scan на размер объекта
   b. Если объект НЕ помечен:
      - Освободить память (добавить в free list)
      - Сдвинуть scan на размер объекта
3. Готово: непомеченные объекты удалены
```

### Преимущества Mark-and-Sweep

- **Обрабатывает циклы.** В примере выше D↔E образуют цикл, но они недостижимы от корней — будут удалены. Алгоритм не зависит от структуры ссылок — только от достижимости.
- **Нет overhead при работе программы.** Во время обычной работы никаких лишних операций — только при запуске GC. Это контрастирует с reference counting, где каждая операция присваивания ссылки несёт накладные расходы.

### Недостатки

- **Stop-the-World.** Классический mark-and-sweep останавливает всё приложение на время сборки. Если heap большой — пауза может быть секунды.
- **Фрагментация.** После удаления объектов в памяти остаются "дырки". Со временем невозможно выделить большой непрерывный блок, хотя суммарно памяти достаточно.

---

## ПОЧЕМУ Stop-The-World паузы неизбежны

### Аналогия: уборка в ресторане

Представь ресторан, который работает 24/7. Менеджер решает провести генеральную уборку — убрать со столов грязную посуду. Но есть проблема: пока уборщик идёт от стола к столу, гости продолжают есть. Кто-то ставит новую тарелку на стол, который уборщик уже проверил (и пометил как "чистый"). Кто-то забирает тарелку со стола, который уборщик ещё не проверил.

Результат: уборщик может случайно убрать тарелку, которой ещё пользуется гость (use-after-free). Или пропустить тарелку, которую уже поставили на "проверенный" стол (memory leak).

Самое простое решение: закрыть ресторан на 30 минут. Гости ждут, но уборка гарантированно корректна. Это и есть Stop-The-World.

### Формальная причина: задача согласованности

Проблема глубже, чем кажется. Mark-and-sweep предполагает, что граф объектов **не меняется** во время обхода. Но программа (mutator, в терминологии GC) постоянно модифицирует граф: создаёт новые объекты, удаляет ссылки, перенаправляет указатели.

Рассмотрим конкретный сценарий. GC начал фазу Mark, пометил объект A как живой и перешёл к сканированию ссылок A. В это время программа:

1. Создаёт ссылку из A на новый объект Z
2. Удаляет единственную ссылку из B на объект C

GC уже просканировал A (не видит Z). GC ещё не дошёл до B (не знает, что C теперь недостижим). Результат: Z — живой объект, но GC не помечен. При sweep Z будет удалён. Это катастрофа — программа получит dangling pointer.

Dijkstra, Lamport и другие исследователи в 1970-х доказали: без какой-либо формы координации между GC и программой корректная сборка мусора невозможна. STW — самая простая форма координации: "программа не работает — GC может спокойно сканировать".

> **Ключевая идея:** STW паузы — не баг и не лень разработчиков. Это фундаментальное следствие того, что GC работает с общими данными, которые программа модифицирует. Уменьшить паузы можно (concurrent GC), устранить полностью — нельзя (нужен хотя бы краткий момент согласования).

---

## Tricolor Abstraction: модель для понимания concurrent GC

### Зачем нужны три цвета

Когда GC работает параллельно с программой, сложно рассуждать о корректности. Dijkstra, Lamport, Martin и Scholten в 1978 году предложили модель "трёх цветов" — tricolor abstraction. Это не реализация, а способ думать о том, что происходит.

Каждый объект в каждый момент времени имеет один из трёх цветов:

**Белый (White)** — объект ещё не обнаружен GC. В начале все объекты белые. Белые объекты в конце работы — мусор.

**Серый (Grey)** — объект обнаружен (достижим), но его ссылки ещё не просканированы. Серый объект — это "заметка для себя": мы знаем, что он живой, но ещё не проверили, на кого он ссылается.

**Чёрный (Black)** — объект полностью обработан. Он достижим, и все его ссылки просканированы. Чёрный объект — это "дело закрыто".

### Пошаговая визуализация

Рассмотрим граф из 6 объектов. Root → A → B → C, A → D, отдельно E → F (недостижимы от root).

```
Шаг 0: Начало — все белые
  Root → [A:W] → [B:W] → [C:W]
                ↘ [D:W]
         [E:W] → [F:W]

  W = White (не обнаружен)


Шаг 1: Корни становятся серыми
  Root → [A:G] → [B:W] → [C:W]
                ↘ [D:W]
         [E:W] → [F:W]

  G = Grey (обнаружен, ссылки не просканированы)


Шаг 2: Сканируем A → находим B и D
  Root → [A:B] → [B:G] → [C:W]
                ↘ [D:G]
         [E:W] → [F:W]

  B = Black (полностью обработан)
  A стал чёрным — все его ссылки (B, D) обнаружены


Шаг 3: Сканируем B → находим C
  Root → [A:B] → [B:B] → [C:G]
                ↘ [D:G]
         [E:W] → [F:W]

  B стал чёрным, C стал серым


Шаг 4: Сканируем C (нет ссылок) и D (нет ссылок)
  Root → [A:B] → [B:B] → [C:B]
                ↘ [D:B]
         [E:W] → [F:W]

  Серых объектов больше нет — STOP


Шаг 5: Результат
  Чёрные (живые): A, B, C, D
  Белые (мусор):  E, F  ← будут удалены
```

### Инвариант трёх цветов

Корректность алгоритма обеспечивается одним простым инвариантом:

> **Tri-color invariant:** Чёрный объект никогда не ссылается напрямую на белый объект.

Почему это важно? Если чёрный объект ссылается на белый — белый может быть удалён, хотя он достижим. Чёрный объект уже "обработан", GC не будет сканировать его снова. Значит, белый объект, на который он ссылается, останется незамеченным.

В STW-варианте инвариант тривиально соблюдается: программа остановлена, граф не меняется. В concurrent-варианте нужны специальные механизмы (barriers), чтобы программа не создала "запрещённую" связь чёрный → белый.

### Почему именно три цвета, а не два

Может возникнуть вопрос: зачем серый? Не достаточно ли просто "обнаружен / не обнаружен" (два цвета)?

Ответ: серый цвет — это граница между обработанной частью графа (чёрная) и необработанной (белая). Без этой границы невозможно понять, какие объекты ещё нужно просканировать. Серая "волна" продвигается через граф: за ней — чёрные (обработанные), перед ней — белые (неизвестные).

Представь это как фронт пожара: огонь (серый) движется, за ним — выжженная земля (чёрный), перед ним — нетронутый лес (белый). Когда огонь потух (серых нет) — всё определено.

---

## Алгоритм Copying (Semi-space)

Cheney в 1970 году предложил другой подход. Делим heap пополам:

```
┌─────────────────────────────────────────────────────────────────┐
│                     COPYING COLLECTION                          │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│   ДО СБОРКИ:                                                   │
│   ┌────────────────────────┬────────────────────────┐          │
│   │    FROM-SPACE          │     TO-SPACE           │          │
│   │  [A][.][B][.][C][.]    │     (пусто)            │          │
│   └────────────────────────┴────────────────────────┘          │
│                                                                 │
│   ПОСЛЕ СБОРКИ:                                                │
│   ┌────────────────────────┬────────────────────────┐          │
│   │    FROM-SPACE          │     TO-SPACE           │          │
│   │  (теперь пусто)        │  [A][B][C]             │          │
│   └────────────────────────┴────────────────────────┘          │
│                                                                 │
│   Мусор остался в FROM-SPACE, живое скопировано в TO-SPACE     │
│   Потом пространства меняются ролями                           │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

### Как это работает

1. Аллоцируем только в FROM-space
2. Когда FROM-space заполнен, начинаем сборку
3. Копируем живые объекты в TO-space (компактно, без дырок)
4. Меняем FROM и TO местами
5. Старое FROM-space теперь полностью свободно

### Преимущества

- **Нет фрагментации.** Объекты копируются компактно.
- **Быстрое выделение.** Просто двигаем указатель (bump pointer allocation).
- **Время пропорционально живым объектам.** Если живого мало — сборка быстрая. Mark-and-sweep тратит время пропорционально всему heap.

### Недостатки

- **Требует вдвое больше памяти.** Половина heap всегда пустует.
- **Много копирования.** Долгоживущие объекты копируются снова и снова.

---

Мы разобрали два базовых алгоритма: mark-and-sweep (эффективен по памяти, но фрагментирует) и copying (нет фрагментации, но требует двойной памяти). Можно ли получить лучшее от обоих? Ответ — generational GC, и он основан на эмпирическом наблюдении о поведении реальных программ.

## Generational GC: главная оптимизация

### Generational hypothesis: почему она работает

В 1984 году David Ungar опубликовал работу "Generation Scavenging", в которой систематизировал наблюдение, известное ещё с 1970-х: **подавляющее большинство объектов умирает молодыми**.

Это не просто "правило большого пальца" — это статистически проверенный факт. Исследования Sun Microsystems (ныне Oracle) на реальных Java-приложениях показали конкретные цифры:

- **80-98% объектов** не переживают первую сборку мусора
- Типичный объект живёт **менее одного поколения** (между двумя Minor GC)
- Объекты, пережившие несколько сборок, с высокой вероятностью живут **очень долго**

Эти числа не случайны. Они отражают паттерн работы программ: большинство объектов — это промежуточные результаты вычислений, временные строки, итераторы, буферы. Они создаются, используются и тут же становятся ненужными.

```
┌─────────────────────────────────────────────────────────────────┐
│           INFANT MORTALITY: СМЕРТНОСТЬ ОБЪЕКТОВ                 │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│   Кол-во        ▓                                              │
│   объектов      ▓▓                                             │
│                 ▓▓▓                                            │
│                 ▓▓▓▓                                           │
│                 ▓▓▓▓▓                                          │
│                 ▓▓▓▓▓▓▓                                        │
│                 ▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓░░░░░░░░░░░░░░░░░░░░           │
│                 ──────────────────────────────────▶             │
│                 Очень          Средне         Очень             │
│                 коротко                       долго             │
│                                                                 │
│   Распределение имеет форму "infant mortality":                │
│   резкий пик слева (много короткоживущих)                      │
│   длинный хвост справа (немного долгоживущих)                  │
│                                                                 │
│   Исследования Sun/Oracle:                                     │
│   • 92% объектов в типичном Java-приложении                    │
│     не переживают первый Minor GC                              │
│   • Средний размер такого объекта: 80-100 байт                 │
│   • Долгоживущие объекты: кэши, singletons, конфиги            │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

Аналогия из реальной жизни: продуктовый магазин. Молоко, хлеб, овощи — скоропортящееся, покупается и потребляется быстро (молодые объекты). Консервы, крупы, специи — живут месяцами (старые объекты). Умный менеджер поставит скоропортящееся ближе к кассе и будет проверять его срок годности чаще. Полку с консервами можно проверять раз в месяц.

### Идея: разделить heap на поколения

Если 80-98% объектов умирает быстро, зачем каждый раз сканировать весь heap? Создадим отдельную область для молодых объектов и будем чистить её часто, а старую — редко.

```
┌─────────────────────────────────────────────────────────────────┐
│                  СТРУКТУРА GENERATIONAL HEAP                    │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│   YOUNG GENERATION (1/3 heap)        OLD GENERATION (2/3 heap) │
│   ┌──────────────────────────────┐  ┌────────────────────────┐ │
│   │ Eden │ S0 │ S1 │             │  │                        │ │
│   │      │    │    │             │  │   Долгоживущие         │ │
│   │ Все  │Sur-│Sur-│             │  │   объекты              │ │
│   │ new  │vi- │vi- │             │  │                        │ │
│   │ тут  │vor │vor │             │  │                        │ │
│   └──────────────────────────────┘  └────────────────────────┘ │
│                                                                 │
│   Minor GC: часто, быстро           Major GC: редко, долго    │
│   (только Young Gen)                (весь heap)               │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

### Как работает: жизненный путь объекта

Пройдём по жизни объекта от создания до удаления:

**1. Рождение в Eden.** Новый объект создаётся в Eden — "Райском саду" молодого поколения. Аллокация — простой сдвиг bump pointer, почти мгновенная.

**2. Первый Minor GC.** Когда Eden заполнен, срабатывает Minor GC. Он сканирует только Young Generation (не весь heap!). Живые объекты из Eden копируются в один из Survivor-пространств (S0). Мёртвые — остаются в Eden, который целиком обнуляется.

**3. Следующие Minor GC.** При каждом Minor GC живые объекты копируются между S0 и S1 по очереди. Каждый объект получает "возраст" — число пережитых сборок.

**4. Продвижение (promotion).** Когда возраст объекта превышает порог (обычно 15 для G1), он продвигается (promote) в Old Generation. Значит, объект доказал, что он долгоживущий.

**5. Major GC.** Когда Old Generation заполнен, запускается Major GC (или Full GC), который сканирует весь heap. Это долго, но происходит редко.

### Почему это эффективно: арифметика

Допустим, heap = 1 GB. Young Generation = 300 MB, Old = 700 MB.

- **Без поколений:** Каждый GC сканирует 1 GB. Если 92% мусора — это ~920 MB мусора, но нужно проверить все 1 GB.
- **С поколениями:** Minor GC сканирует 300 MB. 92% мусора в Young Gen → ~276 MB мусора. Сканируем в 3.3 раза меньше, а собираем ~30% от общего мусора.

Young Gen использует copying collection — быстрый и без фрагментации. Идеально для области, где 92% объектов мертвы: копируем только 8% живых, остальное обнуляется.

Old Gen использует mark-sweep-compact — медленнее, но запускается гораздо реже. Компактификация убирает фрагментацию.

### Межпоколенческие ссылки: проблема и решение

Есть тонкая проблема: объект в Old Generation может ссылаться на объект в Young Generation. При Minor GC мы сканируем только Young Gen, но корни включают ссылки из Old Gen. Сканировать весь Old Gen — это Major GC, что противоречит идее.

Решение: **card table** (или remembered set). Heap Old Generation делится на маленькие "карточки" (обычно 512 байт). Когда программа записывает ссылку из Old в Young, corresponding карточка помечается как "грязная". При Minor GC сканируются только грязные карточки, а не весь Old Gen.

```
Card Table: отслеживание межпоколенческих ссылок

Old Generation:
┌────┬────┬────┬────┬────┬────┬────┬────┐
│    │ *  │    │    │ *  │    │    │    │
└────┴────┴────┴────┴────┴────┴────┴────┘
Card:  0    1    2    3    4    5    6    7

Card Table:
[ 0 ][ 1 ][ 0 ][ 0 ][ 1 ][ 0 ][ 0 ][ 0 ]

* = содержит ссылку на Young Gen (карточка "грязная")

Minor GC сканирует ТОЛЬКО карточки 1 и 4
вместо всего Old Generation
```

---

## Concurrent GC и барьеры

Главная проблема concurrent GC: пока коллектор сканирует объекты, программа их меняет. Объект может стать недостижимым или, наоборот, достижимым между фазами mark и sweep.

### Решение: барьеры (barriers)

Барьер — это маленький кусок кода, который JVM вставляет при каждой записи или чтении указателя.

**Write barrier** перехватывает запись ссылки. Перед каждым присваиванием ссылочного поля JVM выполняет небольшой код, который уведомляет GC об изменении графа.

```kotlin
// Программист пишет:
obj.field = newValue

// JVM выполняет:
writeBarrier(obj, oldValue, newValue)  // ← барьер
obj.field = newValue
```

**Read barrier** перехватывает чтение. Более дорогой, потому что чтений гораздо больше, чем записей.

```kotlin
// Программист пишет:
val x = obj.field

// JVM выполняет:
val x = readBarrier(obj.field)  // ← барьер
```

Write barriers дешевле (записей меньше чем чтений), поэтому большинство GC используют их. Read barriers используют ZGC и Shenandoah — они сложнее, но позволяют перемещать объекты во время работы программы.

---

## КАК это работает на практике: JVM

JVM предлагает 7 сборщиков мусора. Каждый — trade-off между throughput (сколько работы делает приложение) и latency (длина пауз).

### Обзор JVM коллекторов

| Collector | Тип | Паузы | Когда использовать |
|-----------|-----|-------|-------------------|
| **Serial** | STW, 1 поток | Долгие | Маленькие heaps, embedded |
| **Parallel** | STW, N потоков | Средние | Batch jobs, throughput |
| **G1** | Generational, mostly concurrent | 50-200ms | Default с JDK 9 |
| **ZGC** | Concurrent, colored pointers | <10ms | Ultra-low latency |
| **Shenandoah** | Concurrent, forwarding | <10ms | Red Hat, low latency |
| **Epsilon** | Нет сборки | Нет | Тестирование, короткие программы |

### G1 GC: баланс

G1 (Garbage-First) — default collector с Java 9. Он делит heap на много маленьких регионов (не на два поколения). Регионы могут быть Eden, Survivor или Old. G1 собирает сначала регионы с наибольшим количеством мусора ("garbage first").

```
┌─────────────────────────────────────────────────────────────────┐
│                    G1 HEAP STRUCTURE                            │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│   ┌───┬───┬───┬───┬───┬───┬───┬───┬───┬───┬───┬───┐           │
│   │ E │ E │ S │ O │ O │ E │ O │ O │ S │ E │ O │ H │           │
│   └───┴───┴───┴───┴───┴───┴───┴───┴───┴───┴───┴───┘           │
│                                                                 │
│   E = Eden    S = Survivor    O = Old    H = Humongous         │
│                                                                 │
│   Регионы НЕ обязаны быть рядом!                               │
│   G1 сначала собирает регионы с максимумом мусора              │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

### ZGC: ultra-low latency

ZGC использует colored pointers — специальные биты в указателях для отслеживания состояния объектов. Это позволяет делать почти всю работу concurrent, с паузами <10ms даже на heap в терабайты.

С JDK 21 ZGC стал generational — получил преимущества обоих подходов.

### Выбор collector

```
Нужен максимальный throughput?
├── Heap < 2GB → Serial
└── Heap > 2GB → Parallel

Нужен баланс throughput/latency?
└── G1 (default)

Нужны минимальные паузы (<10ms)?
├── Heap до 32GB → ZGC или Shenandoah
└── Heap > 32GB → ZGC
```

---

## Kotlin/Native Memory Manager

Kotlin/Native использует собственный memory manager, отличный от JVM. Это важно для KMP — один и тот же Kotlin-код на JVM работает с JVM GC, а на iOS — с Kotlin/Native GC.

### Архитектура

- **Алгоритм:** stop-the-world mark + concurrent sweep
- **Поколения:** НЕТ (в отличие от JVM)
- **Запуск:** отдельный поток, по memory pressure или таймеру
- **Marking:** параллельный (несколько потоков)

### Особенности

```kotlin
import kotlin.native.internal.GC

// Принудительный запуск GC
GC.collect()

// Получить информацию о последней сборке
@OptIn(ExperimentalStdlibApi::class)
val info = GC.lastGCInfo
println("Memory after GC: ${info?.memoryUsageAfter}")
```

### Experimental: concurrent marking

Можно включить concurrent marking для уменьшения пауз:

```kotlin
// В build.gradle.kts
kotlin {
    targets.withType<org.jetbrains.kotlin.gradle.plugin.mpp.KotlinNativeTarget> {
        binaries.all {
            freeCompilerArgs += "-Xbinary=gc=cms"
        }
    }
}
```

### Взаимодействие с Swift/ARC

На iOS Kotlin объекты могут передаваться в Swift код. Swift использует ARC (reference counting), а Kotlin — tracing GC. Они работают вместе:

1. Kotlin-объект в Swift обёрнут в Swift-обёртку с ARC
2. Пока Swift держит ссылку, Kotlin GC не удалит объект
3. Когда Swift освобождает обёртку, объект становится доступен для Kotlin GC

Подробнее в [[reference-counting-arc]].

---

## Подводные камни

### Мифы о Garbage Collection

**Миф 1: "GC — для ленивых/неопытных разработчиков"**

Реальность: GC даёт архитектурные преимущества. Не тратишь время на отладку use-after-free. Можешь делать сложные структуры данных без страха утечек. Даже эксперты выбирают GC когда он подходит.

**Миф 2: "GC = никаких утечек памяти"**

Реальность: memory leaks возможны! Если ты держишь ссылку на объект, который больше не нужен (забытый listener, растущий кеш), GC не удалит его — объект же достижим.

```kotlin
// Memory leak в Android — Activity не может быть собрана GC,
// потому что статический список держит ссылку на Bitmap,
// а Bitmap принадлежит этой Activity
class MyActivity : Activity() {
    companion object {
        val cache = mutableListOf<Bitmap>()
    }

    fun loadImage() {
        cache.add(loadHugeBitmap())  // Bitmap никогда не удалится!
    }
}
```

Этот код демонстрирует, что GC гарантирует безопасность (нет dangling pointers), но не гарантирует оптимальность использования памяти.

**Миф 3: "Память освобождается сразу"**

Реальность: GC недетерминистичен. После `obj = null` объект может жить ещё долго, пока GC не запустится. Нельзя полагаться на timing.

**Миф 4: "Minor GC не паузит приложение"**

Реальность: Minor GC тоже stop-the-world (в классических реализациях). Паузы короче, но они есть.

**Миф 5: "Reference counting избегает пауз GC"**

Реальность: при удалении большого графа объектов RC может иметь длинные паузы — нужно рекурсивно уменьшить счётчики и удалить всю цепочку.

**Миф 6: "GC катастрофически влияет на производительность"**

Реальность: современные GC часто быстрее ручного управления. Bump pointer allocation дешевле malloc. Compaction улучшает cache locality.

### Когда GC НЕ подходит

- **Hard real-time системы** (контроль ракеты, медицинское оборудование) — непредсказуемые паузы недопустимы
- **Очень ограниченная память** — GC требует overhead (6x память для оптимальной производительности по исследованиям)
- **Системное программирование** — ядро ОС, драйверы не могут паузить

### Типичные проблемы

| Проблема | Симптом | Решение |
|----------|---------|---------|
| Частые Full GC | Высокий CPU, паузы | Увеличить heap, проверить leaks |
| Долгие паузы | Latency spikes | ZGC/Shenandoah, уменьшить Young Gen |
| Excessive allocation | GC не успевает | Оптимизировать код, object pooling |
| Memory leak | Heap растёт без конца | Профилировать, найти retained references |

---

## Связь с другими темами

### [[memory-model-fundamentals]] — Фундамент: Stack и Heap

GC работает исключительно с heap-памятью. Понимание того, что такое heap, как устроены аллокаторы и почему heap фрагментируется — необходимая база. Без этого невозможно понять, зачем GC делает compaction (для борьбы с фрагментацией) или почему bump-pointer allocation в Young Generation так быстр (потому что это по сути stack-like allocation в чистом пространстве). Рекомендуется читать memory-model-fundamentals перед этим материалом.

### [[reference-counting-arc]] — Альтернативный подход к управлению памятью

Reference Counting — дуал tracing GC. Если tracing находит живое, то RC находит мёртвое. У каждого подхода свои trade-offs: GC обрабатывает циклы, но имеет STW паузы; RC детерминистичен, но не справляется с циклами. Для KMP-разработчика понимание обоих подходов критично, потому что JVM-таргет использует GC, а iOS-таргет работает в среде Swift ARC. Логично читать после этого материала.

---

## Источники и дальнейшее чтение

- **Jones, R. & Lins, R. (1996). Garbage Collection: Algorithms for Automatic Dynamic Memory Management.** — каноническая монография по GC. Покрывает все алгоритмы от mark-and-sweep до generational и concurrent. Остаётся наиболее полным академическим источником, несмотря на возраст. Главы 1-4 — обязательное чтение для глубокого понимания.

- **Wilson, P. (1992). Uniprocessor Garbage Collection Techniques.** — обзорная статья (survey), которая систематизирует все подходы к GC на однопроцессорных системах. Более доступна, чем книга Jones & Lins, и даёт отличный обзор для первого знакомства с академической стороной GC.

- **Ungar, D. (1984). Generation Scavenging: A Non-disruptive High Performance Storage Reclamation Algorithm.** — оригинальная статья, формализовавшая generational подход. Содержит эмпирические данные о "infant mortality" объектов, которые обосновывают generational hypothesis.

- [Crafting Interpreters: Garbage Collection](https://craftinginterpreters.com/garbage-collection.html) — лучшее объяснение с аналогиями
- [Datadog: Java GC Deep Dive](https://www.datadoghq.com/blog/understanding-java-gc/) — сравнение JVM коллекторов
- [Kotlin/Native Memory Manager](https://kotlinlang.org/docs/native-memory-manager.html) — официальная документация
- [Holly Cummins: Six Myths of GC](https://hollycummins.com/six-myths-and-paradoxes-of-garbage/) — развенчание мифов
- [Cornell CS6120: Unified Theory of GC](https://www.cs.cornell.edu/courses/cs6120/2019fa/blog/unified-theory-gc/) — tracing vs RC как дуалы

---

## Проверь себя

> [!question]- Почему generational hypothesis работает, и в каких случаях она может подвести?
> Generational hypothesis утверждает: большинство объектов умирают молодыми. Это подтверждается статистикой: ~80-90% объектов не переживают первую сборку. Это работает для типичного кода (временные строки, промежуточные результаты). Может подвести, когда: (1) кэши хранят долгоживущие объекты в Young Gen, (2) batch-обработка создаёт много объектов одновременно, (3) паттерн создания объектов не соответствует "infant mortality".

> [!question]- У тебя Android-приложение с jank (пропуск кадров). Как GC может быть причиной и что делать?
> GC может вызвать jank из-за Stop-The-World пауз: все потоки приложения останавливаются, пока GC работает. Если пауза >16ms — пропуск кадра. Решения: (1) уменьшить аллокации в hot path (object pooling, примитивы вместо boxed), (2) избегать аллокаций в onDraw/onBindViewHolder, (3) использовать SoA вместо AoS для массивов, (4) профилировать через Android Studio Memory Profiler.

> [!question]- Чем принципиально отличаются tracing GC и reference counting?
> Tracing GC находит живые объекты, обходя граф от корней; всё остальное — мусор. Reference counting считает количество ссылок на каждый объект; когда count = 0 — объект мёртв. Tracing: может собирать циклы, но требует пауз (STW). RC: предсказуемые паузы, но не видит циклические ссылки без дополнительного цикл-детектора. Bacon et al. (2004) показали, что эти подходы — дуалы друг друга.

---

## Ключевые карточки

Что такое Garbage Collection?
?
Автоматическое освобождение неиспользуемой памяти. GC определяет, какие объекты больше не достижимы из корней (GC roots), и освобождает их память. Изобретён Джоном Маккарти в 1959 году для Lisp.

---

Что такое GC Roots?
?
Начальные точки обхода графа объектов. Типичные GC roots: локальные переменные на стеке, статические поля классов, JNI references, активные потоки. Всё, что достижимо от roots — живое, остальное — мусор.

---

Чем Mark-and-Sweep отличается от Mark-and-Compact?
?
Mark-and-Sweep: помечает живые, потом очищает мёртвые. Проблема — фрагментация. Mark-and-Compact: помечает живые, потом сдвигает их в начало heap, устраняя фрагментацию. Compact дороже, но позволяет bump-pointer аллокацию.

---

Что такое Stop-The-World (STW) пауза?
?
Остановка всех потоков приложения на время работы GC. Необходима для консистентного снимка графа объектов. Современные сборщики (ZGC, Shenandoah) минимизируют STW до <1ms через concurrent фазы.

---

Какой GC использует Kotlin/Native?
?
Tracing GC на основе mark-and-sweep. Работает concurrently с программой. В отличие от JVM, не использует поколения. С Kotlin 1.7.20+ все ограничения на многопоточность сняты (старая freeze модель заменена).

---

Что такое Tricolor Abstraction?
?
Метод корректной маркировки при concurrent GC. Три цвета: белый (не посещён, потенциальный мусор), серый (посещён, потомки не обработаны), чёрный (посещён, все потомки обработаны). Write barrier гарантирует, что чёрный не ссылается напрямую на белый.

---

## Куда дальше

| Направление | Куда | Зачем |
|-------------|------|-------|
| Следующий шаг | [[reference-counting-arc]] | Изучить альтернативный подход — подсчёт ссылок |
| Углубиться | [[memory-safety-ownership]] | Понять ownership как альтернативу GC |
| Смежная тема | [[memory-model-fundamentals]] | Вспомнить основы stack vs heap |
| Обзор | [[cs-foundations-overview]] | Вернуться к навигации по разделу |

---

*Проверено: 2026-02-13*
