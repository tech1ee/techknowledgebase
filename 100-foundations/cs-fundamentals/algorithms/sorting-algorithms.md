---
title: "Алгоритмы сортировки"
created: 2025-12-30
modified: 2026-02-13
type: deep-dive
status: published
difficulty: intermediate
confidence: high
cs-foundations:
  - divide-and-conquer
  - comparison-based-sorting
  - in-place-algorithm
  - stability-in-sorting
  - lower-bound-omega-nlogn
  - adaptive-algorithms
prerequisites:
  - "[[arrays-strings]]"
  - "[[recursion-fundamentals]]"
  - "[[heaps-priority-queues]]"
  - "[[big-o-complexity]]"
tags:
  - topic/cs-fundamentals
  - type/deep-dive
  - level/intermediate
  - interview
related:
  - "[[searching-algorithms]]"
  - "[[divide-and-conquer]]"
  - "[[two-pointers-pattern]]"

reading_time: 89
difficulty: 4
study_status: not_started
mastery: 0
last_reviewed:
next_review:
---

# Sorting Algorithms

## TL;DR

Sorting algorithms arrange elements in a specific order (ascending/descending). Comparison-based sorts (QuickSort, MergeSort, HeapSort) have O(n log n) lower bound; non-comparison sorts (Counting, Radix) can achieve O(n) for specific constraints. Modern languages use hybrid algorithms: TimSort (Python, Java objects), IntroSort (C++), Dual-Pivot QuickSort (Java primitives).

---

## Часть 1: Интуиция без кода

> **Цель:** понять ИДЕЮ сортировки до любого кода. Если ты понимаешь эти аналогии — ты уже понимаешь сортировку.

### Ты уже умеешь сортировать

Ты делаешь сортировку каждый день, даже не задумываясь:

| Ситуация | Что ты делаешь | Это и есть... |
|----------|----------------|---------------|
| **Раскладываешь карты в руке** | Берёшь новую карту, вставляешь на нужное место | Insertion Sort |
| **Расставляешь книги на полке** | Находишь самую маленькую, ставишь первой, повторяешь | Selection Sort |
| **Разбираешь стопку экзаменов** | Делишь пополам, сортируешь каждую часть, сливаешь | Merge Sort |
| **Ставишь человека по росту** | Выбираешь "среднего", все меньше — налево, больше — направо | QuickSort |

### Аналогия 1: Библиотека

Представь, что ты библиотекарь с 1000 книг на полу. Тебе нужно расставить их по алфавиту.

**Способ 1 (Selection Sort):**
Находишь книгу на "А", ставишь первой. Потом ищешь следующую "А", ставишь второй. И так далее.
- **Проблема:** каждый раз ищешь по ВСЕМ оставшимся книгам.
- **Время:** очень долго (1000 × 1000 = миллион сравнений)

**Способ 2 (Merge Sort):**
Раздаёшь книги 10 помощникам. Каждый сортирует свои 100 книг. Потом вы вместе СЛИВАЕТЕ отсортированные стопки.
- **Преимущество:** работаете параллельно, слияние быстрое
- **Время:** намного быстрее!

**Способ 3 (QuickSort):**
Берёшь случайную книгу (скажем, на "М"). Просишь всех: "книги до М — налево, после М — направо". Теперь у тебя две стопки. Повторяешь для каждой.
- **Преимущество:** не нужна дополнительная память
- **Время:** обычно быстрее всех!

### Аналогия 2: Раздача карт в покере

Когда ты получаешь карты в игре:

```
Ты получаешь карты по одной: 7♥, 2♠, K♦, 5♣, 9♥

Как ты их сортируешь в руке?

Вариант А: Каждую новую карту вставляешь на своё место
           (Insertion Sort — так делает большинство людей!)

Вариант Б: Раскладываешь все карты, потом ищешь наименьшую
           (Selection Sort — медленнее)

Вариант В: Делишь карты пополам, сортируешь каждую половину
           (Merge Sort — излишне для 5 карт)
```

**Важный инсайт:** Для МАЛЕНЬКИХ наборов данных (< 50 элементов) простые алгоритмы часто быстрее! Поэтому TimSort использует Insertion Sort для маленьких участков.

### Аналогия 3: Очередь по росту

Учитель физкультуры хочет выстроить класс из 30 человек по росту.

**Способ "Пузырёк" (Bubble Sort):**
Проходим вдоль очереди. Если сосед слева выше соседа справа — меняем местами. Повторяем пока все не встанут правильно. Самые высокие "всплывают" вверх как пузырьки.

**Способ "Разделяй и властвуй" (QuickSort):**
```
1. Учитель встаёт в середину: "Кто ниже меня — налево, выше — направо"
2. Теперь два "подкласса" по 15 человек
3. В каждом подклассе выбирается свой "средний"
4. Повторяем пока в группах по 1-2 человека
5. Все автоматически стоят по росту!
```

### Главный инсайт: Разные задачи — разные алгоритмы

| Если тебе нужно... | Используй... | Почему |
|--------------------|--------------|--------|
| Отсортировать 10 элементов | Insertion Sort | Простой, быстрый для малых n |
| Отсортировать миллион | QuickSort/MergeSort | O(n log n) критичен |
| Сохранить порядок равных | MergeSort | Стабильная сортировка |
| Работать с малой памятью | HeapSort | O(1) доп. памяти |
| Сортировать оценки 1-5 | Counting Sort | O(n) для малого диапазона |

---

## Часть 2: Почему сортировка сложна для понимания?

> **Цель:** понять, что сортировка — НЕ простая тема, и какие именно аспекты вызывают трудности.

### История: 16 лет до правильного binary search

Джон Бентли (автор "Programming Pearls") утверждал, что **90% профессиональных программистов не могут правильно написать бинарный поиск**. А это проще сортировки!

**Почему сортировка ещё сложнее:**

| Аспект | Трудность |
|--------|-----------|
| **Границы индексов** | off-by-one ошибки в low, high, mid |
| **Условия выхода** | Когда рекурсия останавливается? |
| **Partition в QuickSort** | Два разных схемы (Lomuto vs Hoare) путают |
| **Стабильность** | Неочевидно, когда это важно |
| **Выбор pivot** | Почему первый/последний элемент — плохо? |

### Почему студенты путаются в QuickSort

**Исследования показывают типичные заблуждения:**

1. **"Pivot всегда встаёт на своё место"**
   - В Lomuto — да
   - В Hoare — НЕТ! Pivot может быть где угодно в левой части

2. **"QuickSort всегда O(n log n)"**
   - НЕТ! На отсортированном массиве с плохим pivot — O(n²)
   - Поэтому важен random pivot или median-of-three

3. **"Partition — это просто"**
   - Джон Бентли признавал, что годами использовал схему Хоара, не понимая её до конца
   - Lomuto проще для понимания, но в 3 раза больше swap-ов

### Визуальное мышление vs Код

**Проблема:** сортировка легко визуализируется (переставь карты), но код НЕ интуитивен.

```
Визуально понятно:              В коде НЕ очевидно:
┌───┬───┬───┬───┬───┐
│ 5 │ 2 │ 8 │ 1 │ 9 │          var i = low - 1
└───┴───┴───┴───┴───┘          for (j in low until high) {
         ↓                         if (arr[j] <= pivot) {
┌───┬───┬───┬───┬───┐                  i++
│ 1 │ 2 │ 5 │ 8 │ 9 │                  swap(arr[i], arr[j])
└───┴───┴───┴───┴───┘              }
                               }
```

**Решение:** трассировка с конкретными числами (см. раздел "Как это работает").

### Что отличает новичка от эксперта

| Новичок | Эксперт |
|---------|---------|
| Запоминает код | Понимает ИНВАРИАНТ алгоритма |
| Путает Lomuto и Hoare | Знает когда какой использовать |
| Не думает о worst case | Всегда проверяет edge cases |
| Использует один алгоритм | Выбирает алгоритм под задачу |
| Пишет сортировку с нуля | Использует встроенные функции |

---

## Часть 3: Ментальные модели для сортировки

> **Цель:** дать 3 разных способа ДУМАТЬ о сортировке. Выбери тот, который тебе ближе.

### Модель 1: "Сравни и переставь"

**Идея:** Сортировка = повторять "сравни два элемента → переставь если нужно".

```
┌─────────────────────────────────────────────────────┐
│   Любая comparison-based сортировка сводится к:    │
│                                                     │
│   1. Выбрать два элемента для сравнения            │
│   2. Если arr[i] > arr[j] → swap                   │
│   3. Повторить достаточное количество раз          │
│                                                     │
│   Разница между алгоритмами — В ПОРЯДКЕ сравнений  │
└─────────────────────────────────────────────────────┘
```

**Алгоритмы через эту модель:**
- **Bubble Sort:** сравниваем СОСЕДЕЙ, слева направо, много раз
- **Selection Sort:** сравниваем ПЕРВЫЙ С ОСТАЛЬНЫМИ, находим минимум
- **Insertion Sort:** сравниваем НОВЫЙ элемент С УЖЕ ОТСОРТИРОВАННЫМИ

**Когда использовать:** для понимания простых O(n²) алгоритмов.

### Модель 2: "Разделяй и властвуй"

**Идея:** Большую задачу разбить на маленькие, решить их, собрать результат.

```
┌─────────────────────────────────────────────────────┐
│              DIVIDE AND CONQUER                     │
│                                                     │
│   РАЗДЕЛИТЬ: [5,2,8,1] → [5,2] + [8,1]             │
│                                                     │
│   РЕШИТЬ:    [5,2] → [2,5]                         │
│              [8,1] → [1,8]                          │
│                                                     │
│   СОЕДИНИТЬ: [2,5] + [1,8] → [1,2,5,8]             │
│                                                     │
│   База: массив из 1 элемента УЖЕ отсортирован     │
└─────────────────────────────────────────────────────┘
```

**Алгоритмы через эту модель:**
- **MergeSort:** DIVIDE легко (пополам), CONQUER сложнее (слияние)
- **QuickSort:** DIVIDE сложнее (partition), CONQUER легко (ничего не делаем!)

**Когда использовать:** для понимания O(n log n) алгоритмов.

### Модель 3: "Структура данных решает"

**Идея:** Используем специальную структуру данных, которая поддерживает порядок.

```
┌─────────────────────────────────────────────────────┐
│         SORTING THROUGH DATA STRUCTURES            │
│                                                     │
│   Heap (куча):                                      │
│   • Добавить все элементы в max-heap               │
│   • Извлекать максимум по одному                   │
│   • Результат: отсортированный массив              │
│                                                     │
│   BST (дерево):                                     │
│   • Добавить все элементы в BST                    │
│   • In-order обход                                  │
│   • Результат: отсортированный массив              │
└─────────────────────────────────────────────────────┘
```

**Алгоритм через эту модель:**
- **HeapSort:** build heap + extract max repeatedly

**Когда использовать:** когда важна память O(1) и гарантированное O(n log n).

### Модель 4: "Не сравнивай, а считай" (Non-comparison)

**Идея:** Если знаем диапазон значений — можем посчитать без сравнений.

```
┌─────────────────────────────────────────────────────┐
│              COUNTING, NOT COMPARING                │
│                                                     │
│   Оценки студентов: [3, 1, 2, 3, 2, 1, 3, 2]       │
│   Диапазон: 1-3 (всего 3 возможных значения)       │
│                                                     │
│   Считаем:                                          │
│   • count[1] = 2  (две единицы)                    │
│   • count[2] = 3  (три двойки)                     │
│   • count[3] = 3  (три тройки)                     │
│                                                     │
│   Результат: [1,1,2,2,2,3,3,3]                     │
│   Время: O(n + k) где k = диапазон                 │
└─────────────────────────────────────────────────────┘
```

**Алгоритмы через эту модель:**
- **Counting Sort:** считаем сколько каждого значения
- **Radix Sort:** сортируем по цифрам (единицы → десятки → сотни)
- **Bucket Sort:** раскладываем по "корзинам"

**Когда использовать:** для integers в известном диапазоне.

### Как выбрать ментальную модель?

```
                    Какие данные?
                         │
         ┌───────────────┼───────────────┐
         │               │               │
    Integers в      Любые данные    Данные почти
    малом диапазоне?  с сравнением?   отсортированы?
         │               │               │
         ↓               ↓               ↓
    Модель 4:       Модель 2:       Модель 1:
    "Считай"        "Разделяй"      "Вставляй"
    Counting Sort   MergeSort/      Insertion Sort
                    QuickSort       (или TimSort)
```

---

## Зачем это нужно?

**Реальная проблема:**

Представьте поисковую систему с миллиардами веб-страниц. Когда пользователь ищет "best restaurants near me", система должна:
1. Найти релевантные страницы
2. **Отсортировать по релевантности** за миллисекунды
3. Показать топ-10 результатов

Без эффективной сортировки каждый поиск занимал бы минуты вместо миллисекунд.

**Где используется:**

| Область | Применение | Масштаб |
|---------|------------|---------|
| Базы данных | ORDER BY, индексы | Миллиарды записей |
| E-commerce | Сортировка товаров по цене/рейтингу | Миллионы товаров |
| Социальные сети | Лента новостей по времени/релевантности | Миллиарды постов |
| Финансы | Транзакции по времени | Триллионы операций/год |
| Операционные системы | Планирование процессов по приоритету | Непрерывно |

**Статистика важности:**

- 25-30% времени CPU тратится на сортировку в типичных приложениях
- Amazon обрабатывает ~35 заказов/секунду — каждый требует сортировки доступных складов
- Google сортирует петабайты данных ежедневно для обновления индекса

---

## Prerequisites

| Тема | Зачем нужно | Где изучить |
|------|-------------|-------------|
| Arrays | Сортировка работает с массивами, понимание индексации обязательно | [[arrays-strings]] |
| Big O Notation | Анализ сложности алгоритмов O(n log n) vs O(n²) | [[big-o-complexity]] |
| Recursion | MergeSort и QuickSort — рекурсивные алгоритмы | [[recursion-fundamentals]] |
| Heaps | HeapSort использует структуру данных heap | [[heaps-priority-queues]] |
| **CS: Divide & Conquer** | Ключевой паттерн для QuickSort и MergeSort | Разделяй и властвуй |
| **CS: Amortized Analysis** | Понимание "среднего" случая для QuickSort | Амортизированный анализ |

---

## Что это такое?

### Объяснение для 5-летнего

Представь, что у тебя есть карточки с числами, разбросанные на столе:

```
[8] [3] [1] [5] [2]
```

**Сортировка** — это когда мы расставляем их по порядку:

```
[1] [2] [3] [5] [8]
```

Есть разные способы это сделать:
- **Простой способ**: берём самую маленькую карточку, ставим первой, повторяем
- **Умный способ**: делим карточки пополам, сортируем каждую половину, потом соединяем

### Формальное определение

**Сортировка** — алгоритм упорядочивания элементов последовательности согласно заданному отношению порядка.

Для массива A[0..n-1] с функцией сравнения ≤:
- **Результат**: перестановка A' такая, что A'[0] ≤ A'[1] ≤ ... ≤ A'[n-1]
- **Стабильная сортировка**: если A[i] = A[j] и i < j, то в результате относительный порядок сохраняется

**Нижняя граница**: любая comparison-based сортировка требует Ω(n log n) сравнений в худшем случае (доказывается через дерево решений).

---

## Терминология

| Термин | Определение | Пример |
|--------|-------------|--------|
| **In-place** | Использует O(1) дополнительной памяти | QuickSort (стек не считаем) |
| **Stable** | Сохраняет относительный порядок равных элементов | MergeSort |
| **Comparison-based** | Определяет порядок только через сравнения | QuickSort, MergeSort |
| **Non-comparison** | Использует свойства ключей (цифры, диапазон) | Counting Sort, Radix Sort |
| **Adaptive** | Быстрее на частично отсортированных данных | TimSort |
| **Pivot** | Опорный элемент в QuickSort | Элемент для разделения |
| **Partition** | Разделение массива относительно pivot | Lomuto, Hoare schemes |
| **Run** | Последовательность отсортированных элементов | Используется в TimSort |
| **Heapify** | Преобразование массива в кучу | Первая фаза HeapSort |

---

## Как это работает?

### Классификация алгоритмов сортировки

```
                    SORTING ALGORITHMS
                           │
           ┌───────────────┴───────────────┐
           │                               │
    COMPARISON-BASED                NON-COMPARISON
    (Lower bound: Ω(n log n))       (Can achieve O(n))
           │                               │
    ┌──────┼──────┐               ┌────────┼────────┐
    │      │      │               │        │        │
QuickSort Merge  Heap          Counting  Radix   Bucket
          Sort   Sort           Sort     Sort    Sort
    │
    └─── Hybrid Algorithms:
         • TimSort (Merge + Insertion)
         • IntroSort (Quick + Heap + Insertion)
         • Dual-Pivot QuickSort
```

---

## QuickSort

### Идея

Выбираем **pivot** (опорный элемент), переставляем элементы так, чтобы:
- Слева от pivot — элементы меньше него
- Справа от pivot — элементы больше него
- Рекурсивно сортируем обе части

### Визуализация

```
Initial: [8, 3, 1, 7, 0, 10, 2]    pivot = 7 (last element)

Partition step:
  i=-1
  [8, 3, 1, 7, 0, 10, 2]
       j

  8 > 7: skip
  3 < 7: i=0, swap A[0] with A[1]
  [3, 8, 1, 7, 0, 10, 2]    i=0, j=2

  1 < 7: i=1, swap A[1] with A[2]
  [3, 1, 8, 7, 0, 10, 2]    i=1, j=3

  7 = 7: skip (Lomuto doesn't move pivot yet)
  0 < 7: i=2, swap A[2] with A[4]
  [3, 1, 0, 7, 8, 10, 2]    i=2, j=5

  10 > 7: skip
  2 < 7: i=3, swap A[3] with A[6]
  [3, 1, 0, 2, 8, 10, 7]    i=3

  Final: place pivot at i+1
  [3, 1, 0, 2, 7, 10, 8]
              ↑
            pivot in final position

Recursively sort [3,1,0,2] and [10,8]
```

### Реализация (Kotlin) — с подробным объяснением

```kotlin
/**
 * QuickSort — один из самых быстрых алгоритмов сортировки на практике
 *
 * @param arr массив для сортировки (сортируется in-place)
 * @param low левая граница сортируемого участка
 * @param high правая граница сортируемого участка
 */
fun quickSort(arr: IntArray, low: Int = 0, high: Int = arr.lastIndex) {
    // Условие выхода из рекурсии:
    // если low >= high, значит участок пустой или из одного элемента
    if (low < high) {
        // КЛЮЧЕВОЙ МОМЕНТ: после partition()
        // элемент на позиции partitionIndex стоит НА СВОЁМ МЕСТЕ!
        // Все элементы слева от него меньше, справа — больше
        val partitionIndex = partition(arr, low, high)

        // Рекурсивно сортируем ДВЕ части:
        // 1. Левую часть: [low, partitionIndex - 1]
        // 2. Правую часть: [partitionIndex + 1, high]
        // ВАЖНО: сам partitionIndex НЕ включаем — он уже на месте!
        quickSort(arr, low, partitionIndex - 1)
        quickSort(arr, partitionIndex + 1, high)
    }
}

/**
 * Partition (схема Ломуто) — разделение массива относительно pivot
 *
 * Идея: выбираем последний элемент как pivot,
 * переставляем элементы так, чтобы:
 * - все элементы < pivot были слева
 * - все элементы > pivot были справа
 * - pivot встал на своё финальное место
 *
 * @return индекс, куда встал pivot
 */
fun partition(arr: IntArray, low: Int, high: Int): Int {
    // Выбираем последний элемент как опорный (pivot)
    // Почему последний? Просто для удобства — не нужно его перемещать во время обхода
    val pivot = arr[high]

    // i — указатель на ГРАНИЦУ между "меньше pivot" и "больше или равно pivot"
    // Изначально эта граница ПЕРЕД началом массива (ещё нет элементов < pivot)
    // Инвариант: arr[low..i] содержит элементы <= pivot
    var i = low - 1

    // j — текущий элемент, который мы рассматриваем
    // Обходим все элементы КРОМЕ последнего (он pivot)
    for (j in low until high) {
        // Если текущий элемент меньше или равен pivot
        if (arr[j] <= pivot) {
            // Расширяем "левую" секцию: сдвигаем границу вправо
            i++
            // Меняем местами arr[i] и arr[j]
            // Это перемещает маленький элемент в левую секцию
            arr[i] = arr[j].also { arr[j] = arr[i] }
        }
        // Если arr[j] > pivot — ничего не делаем, элемент остаётся справа
    }

    // После цикла:
    // arr[low..i] — элементы <= pivot
    // arr[i+1..high-1] — элементы > pivot
    // arr[high] — сам pivot

    // Ставим pivot на его финальное место (сразу после левой секции)
    arr[i + 1] = arr[high].also { arr[high] = arr[i + 1] }

    // Возвращаем индекс, где теперь находится pivot
    return i + 1
}

// ПОШАГОВЫЙ ПРИМЕР для arr = [8, 3, 1, 7, 0]
//
// partition(arr, 0, 4): pivot = 0
//   Начало: i = -1
//   j=0: arr[0]=8 > 0 → пропускаем
//   j=1: arr[1]=3 > 0 → пропускаем
//   j=2: arr[2]=1 > 0 → пропускаем
//   j=3: arr[3]=7 > 0 → пропускаем
//   После цикла: i = -1 (никто не был меньше 0!)
//   Ставим pivot на i+1=0: swap(arr[0], arr[4])
//   arr = [0, 3, 1, 7, 8]
//   return 0
//
// Теперь 0 на своём месте!
// Рекурсия: quickSort([], -1) и quickSort([3,1,7,8], 1, 4)
```

### Hoare Partition (более эффективная)

Схема Хоара работает иначе: два указателя идут навстречу друг другу от краёв массива, меняя местами "неправильные" элементы.

```kotlin
/**
 * Partition по схеме Хоара — эффективнее Lomuto!
 *
 * Идея: два указателя i и j двигаются навстречу друг другу.
 * - i ищет элемент >= pivot (должен быть справа)
 * - j ищет элемент <= pivot (должен быть слева)
 * Когда оба нашли — меняем местами и продолжаем.
 *
 * Преимущество: в среднем в 3 раза меньше swap-ов чем Lomuto!
 */
fun hoarePartition(arr: IntArray, low: Int, high: Int): Int {
    // Выбираем ПЕРВЫЙ элемент как pivot
    // В схеме Хоара это удобнее — он естественно попадёт в правильную область
    val pivot = arr[low]

    // i начинает ПЕРЕД массивом, j — ПОСЛЕ массива
    // Потому что сначала делаем i++/j-- внутри do-while
    var i = low - 1
    var j = high + 1

    while (true) {
        // ШАГ 1: Двигаем i вправо, пока не найдём элемент >= pivot
        // Этот элемент "слишком большой" для левой части
        do { i++ } while (arr[i] < pivot)

        // ШАГ 2: Двигаем j влево, пока не найдём элемент <= pivot
        // Этот элемент "слишком маленький" для правой части
        do { j-- } while (arr[j] > pivot)

        // ШАГ 3: Если указатели пересеклись или встретились — конец!
        // ВАЖНО: возвращаем j, а не позицию pivot
        // В отличие от Lomuto, pivot НЕ обязательно на своём месте!
        if (i >= j) return j

        // ШАГ 4: Меняем местами "неправильные" элементы
        // arr[i] >= pivot должен быть справа
        // arr[j] <= pivot должен быть слева
        arr[i] = arr[j].also { arr[j] = arr[i] }
    }
}

// ПОШАГОВЫЙ ПРИМЕР для arr = [4, 2, 6, 1, 3], pivot = 4
//
// Начало: i = -1, j = 5
//
// Итерация 1:
//   do i++ while arr[i] < 4:
//     i=0, arr[0]=4, 4 < 4? НЕТ → останавливаемся, i=0
//   do j-- while arr[j] > 4:
//     j=4, arr[4]=3, 3 > 4? НЕТ → останавливаемся, j=4
//   i(0) < j(4)? ДА → swap(arr[0], arr[4])
//   arr = [3, 2, 6, 1, 4]
//
// Итерация 2:
//   do i++: i=1, arr[1]=2 < 4? ДА → i=2, arr[2]=6 < 4? НЕТ → i=2
//   do j--: j=3, arr[3]=1 > 4? НЕТ → j=3
//   i(2) < j(3)? ДА → swap(arr[2], arr[3])
//   arr = [3, 2, 1, 6, 4]
//
// Итерация 3:
//   do i++: i=3, arr[3]=6 < 4? НЕТ → i=3
//   do j--: j=2, arr[2]=1 > 4? НЕТ → j=2
//   i(3) >= j(2)? ДА → return 2
//
// Результат: partition вернула 2
// arr = [3, 2, 1, 6, 4]
// Элементы [0..2] = [3,2,1] — все <= 4
// Элементы [3..4] = [6,4] — все >= 4 (но 4 не на финальном месте!)
//
// ВАЖНО: при использовании Hoare partition в QuickSort:
// quickSort(arr, low, partitionIndex)      // НЕ partitionIndex - 1 !
// quickSort(arr, partitionIndex + 1, high)
```

### Java

```java
public class QuickSort {
    public void quickSort(int[] arr, int low, int high) {
        if (low < high) {
            int pi = partition(arr, low, high);
            quickSort(arr, low, pi - 1);
            quickSort(arr, pi + 1, high);
        }
    }

    private int partition(int[] arr, int low, int high) {
        int pivot = arr[high];
        int i = low - 1;

        for (int j = low; j < high; j++) {
            if (arr[j] <= pivot) {
                i++;
                // Swap
                int temp = arr[i];
                arr[i] = arr[j];
                arr[j] = temp;
            }
        }

        int temp = arr[i + 1];
        arr[i + 1] = arr[high];
        arr[high] = temp;

        return i + 1;
    }
}
```

### Python

```python
def quick_sort(arr: list, low: int = 0, high: int = None) -> None:
    if high is None:
        high = len(arr) - 1

    if low < high:
        pi = partition(arr, low, high)
        quick_sort(arr, low, pi - 1)
        quick_sort(arr, pi + 1, high)

def partition(arr: list, low: int, high: int) -> int:
    pivot = arr[high]
    i = low - 1

    for j in range(low, high):
        if arr[j] <= pivot:
            i += 1
            arr[i], arr[j] = arr[j], arr[i]

    arr[i + 1], arr[high] = arr[high], arr[i + 1]
    return i + 1
```

---

## MergeSort

### Идея

1. **Divide**: Делим массив пополам
2. **Conquer**: Рекурсивно сортируем каждую половину
3. **Combine**: Сливаем две отсортированные половины

### Визуализация

```
         [38, 27, 43, 3, 9, 82, 10]
                    │
         ┌──────────┴──────────┐
         │                     │
    [38, 27, 43, 3]      [9, 82, 10]
         │                     │
    ┌────┴────┐          ┌─────┴─────┐
    │         │          │           │
[38, 27]  [43, 3]     [9, 82]      [10]
    │         │          │           │
  ┌─┴─┐     ┌─┴─┐      ┌─┴─┐         │
[38] [27] [43] [3]   [9] [82]      [10]
  │     │     │   │      │   │        │
  └──┬──┘     └─┬─┘      └─┬─┘        │
 [27, 38]   [3, 43]    [9, 82]      [10]
     │          │          │          │
     └────┬─────┘          └────┬─────┘
    [3, 27, 38, 43]       [9, 10, 82]
           │                   │
           └─────────┬─────────┘
                     │
       [3, 9, 10, 27, 38, 43, 82]
```

### Merge Step (ключевая операция)

```
Merging [3, 27, 38, 43] and [9, 10, 82]:

Left:  [3, 27, 38, 43]    Right: [9, 10, 82]
        ↑                          ↑
        i                          j

Step 1: 3 < 9  → result = [3],         i++
Step 2: 27 > 9 → result = [3, 9],      j++
Step 3: 27 > 10 → result = [3, 9, 10], j++
Step 4: 27 < 82 → result = [3, 9, 10, 27], i++
Step 5: 38 < 82 → result = [3, 9, 10, 27, 38], i++
Step 6: 43 < 82 → result = [3, 9, 10, 27, 38, 43], i++
Step 7: Left exhausted → append remaining: [3, 9, 10, 27, 38, 43, 82]
```

### Реализация (Kotlin) — с подробным объяснением

```kotlin
/**
 * MergeSort — стабильный алгоритм сортировки O(n log n)
 *
 * Принцип работы (Divide and Conquer):
 * 1. ДЕЛИМ массив пополам
 * 2. РЕКУРСИВНО сортируем каждую половину
 * 3. СЛИВАЕМ две отсортированные половины
 *
 * @param arr исходный массив
 * @return новый отсортированный массив (не изменяет исходный!)
 */
fun mergeSort(arr: IntArray): IntArray {
    // БАЗА РЕКУРСИИ: массив из 0 или 1 элемента уже отсортирован
    // Это важно! Без этого условия рекурсия никогда не закончится
    if (arr.size <= 1) return arr

    // Находим середину для деления массива пополам
    val mid = arr.size / 2

    // РЕКУРСИВНЫЙ ШАГ: сортируем левую и правую половины
    // sliceArray создаёт КОПИЮ части массива
    // Левая половина: [0, mid)
    // Правая половина: [mid, size)
    val left = mergeSort(arr.sliceArray(0 until mid))
    val right = mergeSort(arr.sliceArray(mid until arr.size))

    // СЛИЯНИЕ: объединяем две отсортированные половины
    return merge(left, right)
}

/**
 * Функция слияния — сердце MergeSort!
 *
 * Принимает две ОТСОРТИРОВАННЫЕ последовательности,
 * возвращает одну ОТСОРТИРОВАННУЮ.
 *
 * Алгоритм: сравниваем первые элементы обеих половин,
 * меньший кладём в результат, сдвигаем указатель.
 */
fun merge(left: IntArray, right: IntArray): IntArray {
    // Результат будет размером = сумма размеров входных массивов
    val result = IntArray(left.size + right.size)

    // Три указателя:
    var i = 0  // указатель на текущий элемент в LEFT
    var j = 0  // указатель на текущий элемент в RIGHT
    var k = 0  // указатель на следующую свободную позицию в RESULT

    // ГЛАВНЫЙ ЦИКЛ: пока в обоих массивах есть элементы
    while (i < left.size && j < right.size) {
        // Сравниваем текущие элементы обоих массивов
        // ВАЖНО: используем <= (а не <) для СТАБИЛЬНОСТИ!
        // Если left[i] == right[j], берём из LEFT — сохраняем исходный порядок
        if (left[i] <= right[j]) {
            result[k++] = left[i++]  // берём из left, сдвигаем i и k
        } else {
            result[k++] = right[j++]  // берём из right, сдвигаем j и k
        }
    }

    // ДОЗАПИСЬ: один из массивов закончился, копируем остаток другого
    // Максимум ОДИН из этих циклов выполнится
    while (i < left.size) result[k++] = left[i++]  // остаток left
    while (j < right.size) result[k++] = right[j++]  // остаток right

    return result
}

// ПОШАГОВЫЙ ПРИМЕР для arr = [38, 27, 43, 3]
//
// mergeSort([38, 27, 43, 3]):
//   mid = 2
//   left = mergeSort([38, 27])
//     mid = 1
//     left = mergeSort([38]) → [38] (база!)
//     right = mergeSort([27]) → [27] (база!)
//     merge([38], [27]):
//       i=0, j=0: 38 > 27 → result[0] = 27, j=1
//       j >= right.size → копируем остаток left
//       result = [27, 38]
//
//   right = mergeSort([43, 3])
//     mid = 1
//     left = mergeSort([43]) → [43]
//     right = mergeSort([3]) → [3]
//     merge([43], [3]):
//       i=0, j=0: 43 > 3 → result[0] = 3, j=1
//       j >= right.size → копируем остаток left
//       result = [3, 43]
//
//   merge([27, 38], [3, 43]):
//     i=0, j=0: 27 > 3 → result[0] = 3, j=1
//     i=0, j=1: 27 < 43 → result[1] = 27, i=1
//     i=1, j=1: 38 < 43 → result[2] = 38, i=2
//     i >= left.size → копируем остаток right
//     result = [3, 27, 38, 43]
//
// Финальный результат: [3, 27, 38, 43] ✓
```

### In-place MergeSort (экономим память)

Стандартный MergeSort создаёт много копий массивов (O(n) на каждом уровне).
Версия ниже использует ОДИН временный массив, который переиспользуется.

```kotlin
/**
 * In-place MergeSort — версия с одним временным массивом
 *
 * @param arr массив для сортировки (изменяется!)
 * @param temp временный массив (переиспользуется на всех уровнях рекурсии)
 * @param left левая граница сортируемого участка (включительно)
 * @param right правая граница сортируемого участка (включительно)
 */
fun mergeSortInPlace(arr: IntArray, temp: IntArray = IntArray(arr.size),
                     left: Int = 0, right: Int = arr.lastIndex) {
    // База рекурсии: участок из 0 или 1 элемента уже отсортирован
    if (left >= right) return

    // Вычисляем середину БЕЗ РИСКА ПЕРЕПОЛНЕНИЯ!
    // Неправильно: (left + right) / 2 — может переполниться при больших значениях
    // Правильно: left + (right - left) / 2 — сначала вычисляем разницу
    val mid = left + (right - left) / 2

    // Рекурсивно сортируем левую половину [left, mid]
    mergeSortInPlace(arr, temp, left, mid)
    // Рекурсивно сортируем правую половину [mid+1, right]
    mergeSortInPlace(arr, temp, mid + 1, right)
    // Сливаем две отсортированные половины
    mergeInPlace(arr, temp, left, mid, right)
}

/**
 * Слияние с использованием временного массива
 *
 * ВАЖНО: границы ВКЛЮЧИТЕЛЬНЫЕ! [left, mid] и [mid+1, right]
 */
fun mergeInPlace(arr: IntArray, temp: IntArray, left: Int, mid: Int, right: Int) {
    // ОПТИМИЗАЦИЯ: если последний элемент левой половины <= первого правой,
    // то массив уже отсортирован на этом участке! Пропускаем слияние.
    // Это даёт O(n) на почти отсортированных данных.
    if (arr[mid] <= arr[mid + 1]) return

    // Копируем текущий участок во временный массив
    // Потому что мы будем записывать результат обратно в arr
    for (k in left..right) temp[k] = arr[k]

    var i = left      // указатель на текущий элемент левой половины (в temp)
    var j = mid + 1   // указатель на текущий элемент правой половины (в temp)
    var k = left      // указатель на позицию записи в arr

    // Основной цикл слияния
    while (i <= mid && j <= right) {
        if (temp[i] <= temp[j]) {
            arr[k++] = temp[i++]
        } else {
            arr[k++] = temp[j++]
        }
    }

    // Копируем остаток ТОЛЬКО из левой половины!
    // Почему не из правой? Потому что элементы правой половины
    // уже находятся в arr на своих местах (мы их туда скопировали из temp,
    // и они остались там же, т.к. мы не дошли до них в основном цикле)
    while (i <= mid) arr[k++] = temp[i++]
}

// ПРИМЕР: mergeInPlace на [1, 4, 2, 3]
// left=0, mid=1, right=3
// Левая: [1, 4], Правая: [2, 3]
//
// Копируем в temp: temp = [1, 4, 2, 3]
// i=0, j=2, k=0
//
// temp[0]=1 <= temp[2]=2 → arr[0]=1, i=1, k=1
// temp[1]=4 > temp[2]=2 → arr[1]=2, j=3, k=2
// temp[1]=4 > temp[3]=3 → arr[2]=3, j=4, k=3
// j > right → выход из основного цикла
// i=1 <= mid=1 → arr[3]=4
//
// Результат: arr = [1, 2, 3, 4] ✓
```

### Java

```java
public int[] mergeSort(int[] arr) {
    if (arr.length <= 1) return arr;

    int mid = arr.length / 2;
    int[] left = mergeSort(Arrays.copyOfRange(arr, 0, mid));
    int[] right = mergeSort(Arrays.copyOfRange(arr, mid, arr.length));

    return merge(left, right);
}

private int[] merge(int[] left, int[] right) {
    int[] result = new int[left.length + right.length];
    int i = 0, j = 0, k = 0;

    while (i < left.length && j < right.length) {
        if (left[i] <= right[j]) {
            result[k++] = left[i++];
        } else {
            result[k++] = right[j++];
        }
    }

    while (i < left.length) result[k++] = left[i++];
    while (j < right.length) result[k++] = right[j++];

    return result;
}
```

### Python

```python
def merge_sort(arr: list) -> list:
    if len(arr) <= 1:
        return arr

    mid = len(arr) // 2
    left = merge_sort(arr[:mid])
    right = merge_sort(arr[mid:])

    return merge(left, right)

def merge(left: list, right: list) -> list:
    result = []
    i = j = 0

    while i < len(left) and j < len(right):
        if left[i] <= right[j]:
            result.append(left[i])
            i += 1
        else:
            result.append(right[j])
            j += 1

    result.extend(left[i:])
    result.extend(right[j:])
    return result
```

---

## HeapSort

### Идея

1. **Build Max-Heap**: Преобразуем массив в max-heap за O(n)
2. **Extract Max**: Извлекаем максимум (корень), ставим в конец, восстанавливаем heap

### Визуализация

```
Array: [4, 10, 3, 5, 1]

Step 1: Build Max-Heap
        4                    10
       / \                  /  \
     10   3    →          5    3
     / \                 / \
    5   1               4   1

Step 2: Extract Max (10), swap with last
        1                    5
       / \                  / \
      5   3    →          4   3
     /                   /
    4                   1

    Sorted: [10]

Step 3: Extract Max (5), swap with last
        1                    4
       / \      →           / \
      4   3                1   3

    Sorted: [5, 10]

Continue until sorted: [1, 3, 4, 5, 10]
```

### Реализация (Kotlin) — с подробным объяснением

```kotlin
/**
 * HeapSort — сортировка кучей
 *
 * Принцип работы:
 * 1. СТРОИМ max-heap из массива (родитель >= дети)
 * 2. Максимум (корень) переносим в конец массива
 * 3. Уменьшаем кучу на 1, восстанавливаем свойство кучи
 * 4. Повторяем пока куча не пуста
 *
 * Сложность: O(n log n) — всегда!
 * Память: O(1) — in-place, только несколько переменных
 */
fun heapSort(arr: IntArray) {
    val n = arr.size

    // ФАЗ 1: ПОСТРОЕНИЕ MAX-HEAP (heapify снизу вверх)
    //
    // Почему начинаем с n/2 - 1?
    // В массиве-куче:
    // - Элементы [n/2, n-1] — это ЛИСТЬЯ (у них нет детей)
    // - Элементы [0, n/2-1] — это ВНУТРЕННИЕ узлы (есть хотя бы один ребёнок)
    //
    // Листьям не нужна heapify (они уже "кучи" из 1 элемента),
    // поэтому начинаем с последнего внутреннего узла и идём к корню
    for (i in n / 2 - 1 downTo 0) {
        heapify(arr, n, i)
    }

    // ФАЗ 2: ИЗВЛЕЧЕНИЕ ЭЛЕМЕНТОВ
    //
    // После Фазы 1: arr[0] — максимальный элемент!
    // Алгоритм:
    // 1. Меняем arr[0] (макс) с arr[i] (последний в куче)
    // 2. Теперь arr[i] на своём месте, уменьшаем кучу
    // 3. Восстанавливаем свойство кучи для нового корня
    for (i in n - 1 downTo 1) {
        // Шаг 1: Перемещаем текущий максимум (корень) в конец
        // После этого arr[i] — на своём финальном месте!
        arr[0] = arr[i].also { arr[i] = arr[0] }

        // Шаг 2: Восстанавливаем max-heap для оставшихся элементов
        // ВАЖНО: размер кучи теперь i (а не n!)
        // arr[i..n-1] уже отсортированы и НЕ входят в кучу
        heapify(arr, i, 0)
    }
}

/**
 * heapify — восстановление свойства max-heap для поддерева
 *
 * Свойство max-heap: родитель >= детей
 *
 * @param arr массив-куча
 * @param heapSize текущий размер кучи (элементы за heapSize игнорируются!)
 * @param i индекс корня поддерева, которое нужно "исправить"
 */
fun heapify(arr: IntArray, heapSize: Int, i: Int) {
    // Предполагаем, что корень — самый большой
    var largest = i

    // Формулы для индексов детей (для 0-индексации):
    // Левый ребёнок: 2*i + 1
    // Правый ребёнок: 2*i + 2
    // Родитель: (i - 1) / 2
    val left = 2 * i + 1
    val right = 2 * i + 2

    // Проверяем: левый ребёнок больше текущего largest?
    // ВАЖНО: left < heapSize — проверяем, что ребёнок вообще существует!
    if (left < heapSize && arr[left] > arr[largest]) {
        largest = left
    }

    // Проверяем: правый ребёнок больше текущего largest?
    if (right < heapSize && arr[right] > arr[largest]) {
        largest = right
    }

    // Если largest изменился — нужен swap!
    if (largest != i) {
        // Меняем местами корень и наибольший элемент
        arr[i] = arr[largest].also { arr[largest] = arr[i] }

        // РЕКУРСИЯ: swap мог нарушить свойство кучи в поддереве
        // Нужно "протолкнуть" бывший корень вниз, пока он не займёт правильное место
        heapify(arr, heapSize, largest)
    }
    // Если largest == i — всё хорошо, свойство выполняется
}

// ПОШАГОВЫЙ ПРИМЕР для arr = [4, 10, 3, 5, 1]
//
// ФАЗА 1: Построение max-heap
// n = 5, последний внутренний узел = 5/2 - 1 = 1
//
// i = 1: heapify от узла arr[1]=10
//        left = 3 (arr[3]=5), right = 4 (arr[4]=1)
//        10 > 5 и 10 > 1 → largest = 1, ничего не меняем
//
// i = 0: heapify от узла arr[0]=4
//        left = 1 (arr[1]=10), right = 2 (arr[2]=3)
//        10 > 4 → largest = 1
//        swap(arr[0], arr[1]) → arr = [10, 4, 3, 5, 1]
//        heapify(arr, 5, 1):
//          left = 3 (arr[3]=5), right = 4 (arr[4]=1)
//          5 > 4 → largest = 3
//          swap(arr[1], arr[3]) → arr = [10, 5, 3, 4, 1]
//
// Max-heap построен: [10, 5, 3, 4, 1]
//          10
//         /  \
//        5    3
//       / \
//      4   1
//
// ФАЗА 2: Извлечение
//
// i = 4: swap(arr[0], arr[4]) → arr = [1, 5, 3, 4, 10]
//        heapify(arr, 4, 0):
//          5 > 1 → swap → arr = [5, 1, 3, 4, 10]
//          4 > 1 → swap → arr = [5, 4, 3, 1, 10]
//
// i = 3: swap(arr[0], arr[3]) → arr = [1, 4, 3, 5, 10]
//        heapify(arr, 3, 0):
//          4 > 1 → swap → arr = [4, 1, 3, 5, 10]
//
// i = 2: swap(arr[0], arr[2]) → arr = [3, 1, 4, 5, 10]
//        heapify(arr, 2, 0):
//          1 нет детей в куче → ничего
//
// i = 1: swap(arr[0], arr[1]) → arr = [1, 3, 4, 5, 10]
//        heapify(arr, 1, 0): пустая куча
//
// Финал: [1, 3, 4, 5, 10] ✓
```

### Iterative heapify (избегаем stack overflow)

Рекурсивная heapify может переполнить стек на очень больших массивах.
Итеративная версия безопаснее и чуть быстрее (нет overhead на вызов функций).

```kotlin
/**
 * Итеративная версия heapify — без рекурсии
 *
 * Вместо рекурсивных вызовов используем цикл while.
 * Логика та же: находим наибольшего среди узла и детей,
 * если нужен swap — делаем и переходим вниз к поддереву.
 */
fun heapifyIterative(arr: IntArray, heapSize: Int, startIndex: Int) {
    var i = startIndex  // Текущий узел, который "просеиваем" вниз

    while (true) {
        var largest = i
        val left = 2 * i + 1
        val right = 2 * i + 2

        // Находим наибольший среди узла и его детей
        if (left < heapSize && arr[left] > arr[largest]) largest = left
        if (right < heapSize && arr[right] > arr[largest]) largest = right

        // Если узел уже наибольший — свойство max-heap выполняется, выходим!
        if (largest == i) break

        // Иначе меняем местами и продолжаем вниз по дереву
        arr[i] = arr[largest].also { arr[largest] = arr[i] }

        // Переходим к поддереву, куда "упал" бывший корень
        // Это заменяет рекурсивный вызов heapify(arr, heapSize, largest)
        i = largest
    }
}

// Эта версия эквивалентна рекурсивной, но:
// - Не использует стек вызовов (константная память)
// - Чуть быстрее (нет overhead на создание stack frame)
// - Безопаснее на очень глубоких деревьях
```

---

## Non-Comparison Sorting

### Counting Sort

```
Когда использовать: целые числа в небольшом диапазоне [0, k]
Время: O(n + k)
Память: O(k)
```

```kotlin
/**
 * Counting Sort — сортировка подсчётом
 *
 * ИДЕЯ: вместо сравнений СЧИТАЕМ, сколько раз встречается каждое число.
 * Это НЕ comparison-based сортировка, поэтому может быть быстрее O(n log n)!
 *
 * Ограничение: работает только для целых чисел в известном диапазоне.
 *
 * Пример: [4, 2, 2, 8, 3, 3, 1]
 * Диапазон: 1-8, range = 8
 * count = [0, 1, 2, 2, 1, 0, 0, 0, 1]  (индекс = значение)
 *              1  2  3  4  5  6  7  8
 * Результат: читаем count слева направо → [1, 2, 2, 3, 3, 4, 8]
 */
fun countingSort(arr: IntArray): IntArray {
    if (arr.isEmpty()) return arr

    // Находим диапазон значений
    val max = arr.maxOrNull()!!
    val min = arr.minOrNull()!!
    val range = max - min + 1  // Размер массива подсчёта

    // ШАГ 1: Подсчёт — count[i] хранит количество элементов, равных (i + min)
    // Почему (i + min)? Чтобы поддерживать отрицательные числа!
    // Пример: min = -2, max = 2 → range = 5
    //         count[0] = кол-во "-2", count[2] = кол-во "0", count[4] = кол-во "2"
    val count = IntArray(range)
    for (num in arr) {
        count[num - min]++  // num - min преобразует значение в индекс
    }

    // ШАГ 2: Кумулятивная сумма — теперь count[i] хранит ПОЗИЦИЮ
    // count[i] = сколько элементов <= (i + min)
    // Это нужно для размещения элементов на правильные позиции
    for (i in 1 until range) {
        count[i] += count[i - 1]
    }

    // ШАГ 3: Построение результата
    // ВАЖНО: обходим arr СПРАВА НАЛЕВО для стабильности!
    // Элементы с одинаковыми значениями сохраняют относительный порядок.
    val output = IntArray(arr.size)
    for (i in arr.indices.reversed()) {  // от последнего к первому
        val num = arr[i]
        // count[num - min] - 1 = позиция, куда поставить num
        // -1 потому что count хранит "сколько всего", а индексы с 0
        output[count[num - min] - 1] = num
        // Уменьшаем count, чтобы следующий такой же элемент встал левее
        count[num - min]--
    }

    return output
}

// ПОШАГОВЫЙ ПРИМЕР для arr = [4, 2, 2, 1]
// min = 1, max = 4, range = 4
//
// ШАГ 1: Подсчёт
// count = [0, 0, 0, 0]  (индексы 0,1,2,3 = значения 1,2,3,4)
// arr[0]=4: count[4-1]++ → count = [0, 0, 0, 1]
// arr[1]=2: count[2-1]++ → count = [0, 1, 0, 1]
// arr[2]=2: count[2-1]++ → count = [0, 2, 0, 1]
// arr[3]=1: count[1-1]++ → count = [1, 2, 0, 1]
//
// ШАГ 2: Кумулятивная сумма
// count[0] = 1 (осталось 1)
// count[1] = 1 + 2 = 3 (единиц и двоек всего 3)
// count[2] = 3 + 0 = 3 (троек нет)
// count[3] = 3 + 1 = 4 (всего 4 элемента)
// count = [1, 3, 3, 4]
//
// ШАГ 3: Построение (справа налево)
// i=3: num=1, pos=count[0]-1=0, output[0]=1, count=[0,3,3,4]
// i=2: num=2, pos=count[1]-1=2, output[2]=2, count=[0,2,3,4]
// i=1: num=2, pos=count[1]-1=1, output[1]=2, count=[0,1,3,4]
// i=0: num=4, pos=count[3]-1=3, output[3]=4, count=[0,1,3,3]
//
// output = [1, 2, 2, 4] ✓
```

### Radix Sort (LSD — Least Significant Digit)

```kotlin
/**
 * Radix Sort — поразрядная сортировка
 *
 * ИДЕЯ: сортируем числа по одной цифре за раз,
 * начиная с МЛАДШЕГО разряда (единицы → десятки → сотни → ...)
 *
 * Для каждого разряда используем Counting Sort (стабильную сортировку!).
 * Стабильность КРИТИЧНА — иначе сортировка по старшим разрядам
 * испортит результат сортировки по младшим.
 *
 * Сложность: O(d × (n + k)), где d = количество разрядов, k = основание (10)
 * Для 32-битных int: d ≤ 10, k = 10 → O(10 × (n + 10)) = O(n)
 */
fun radixSort(arr: IntArray): IntArray {
    if (arr.isEmpty()) return arr

    val max = arr.maxOrNull()!!
    // exp — текущий "вес" разряда (1, 10, 100, 1000, ...)
    // exp = 1 → единицы
    // exp = 10 → десятки
    // exp = 100 → сотни
    var exp = 1
    var result = arr.copyOf()

    // Обрабатываем каждый разряд от младшего к старшему
    // Остановка: когда exp больше максимального числа (все разряды обработаны)
    while (max / exp > 0) {
        result = countingSortByDigit(result, exp)
        exp *= 10  // Переходим к следующему разряду
    }

    return result
}

/**
 * Counting Sort для одного разряда
 *
 * @param arr массив для сортировки
 * @param exp "вес" текущего разряда (1, 10, 100, ...)
 * @return отсортированный массив по текущему разряду
 */
fun countingSortByDigit(arr: IntArray, exp: Int): IntArray {
    val output = IntArray(arr.size)
    // Массив для подсчёта цифр 0-9
    // В десятичной системе только 10 возможных цифр
    val count = IntArray(10)

    // ШАГ 1: Подсчёт — сколько чисел имеет каждую цифру в текущем разряде
    for (num in arr) {
        // Формула извлечения цифры:
        // (num / exp) — отбрасываем младшие разряды
        // % 10 — берём последнюю цифру
        // Пример: num=123, exp=10 → (123/10) % 10 = 12 % 10 = 2 (десятки)
        val digit = (num / exp) % 10
        count[digit]++
    }

    // ШАГ 2: Кумулятивная сумма (для позиций)
    for (i in 1 until 10) {
        count[i] += count[i - 1]
    }

    // ШАГ 3: Построение результата (СПРАВА НАЛЕВО для стабильности!)
    for (i in arr.indices.reversed()) {
        val digit = (arr[i] / exp) % 10
        output[count[digit] - 1] = arr[i]
        count[digit]--
    }

    return output
}

// ПОШАГОВЫЙ ПРИМЕР для arr = [170, 45, 75, 90, 802, 24, 2, 66]
//
// max = 802, будем обрабатывать разряды: единицы → десятки → сотни
//
// РАУНД 1: exp = 1 (единицы)
// Цифры единиц: [0, 5, 5, 0, 2, 4, 2, 6]
// После сортировки по единицам:
// [170, 90, 802, 2, 24, 45, 75, 66]
//   ↑0  ↑0   ↑2  ↑2  ↑4  ↑5  ↑5  ↑6
//
// РАУНД 2: exp = 10 (десятки)
// Цифры десятков: [7, 9, 0, 0, 2, 4, 7, 6]
// После сортировки по десяткам:
// [802, 2, 24, 45, 66, 170, 75, 90]
//   ↑0  ↑0  ↑2  ↑4  ↑6   ↑7  ↑7  ↑9
//
// РАУНД 3: exp = 100 (сотни)
// Цифры сотен: [8, 0, 0, 0, 0, 1, 0, 0]
// После сортировки по сотням:
// [2, 24, 45, 66, 75, 90, 170, 802]
//  ↑0  ↑0  ↑0  ↑0  ↑0  ↑0   ↑1   ↑8
//
// Готово! [2, 24, 45, 66, 75, 90, 170, 802] ✓
```

---

## Hybrid Algorithms (Production Use)

Реальные библиотеки используют ГИБРИДНЫЕ алгоритмы — комбинации нескольких подходов.

### TimSort (упрощённая идея)

```kotlin
/**
 * TimSort — гибридный алгоритм, используемый в Python и Java
 *
 * ИДЕЯ: реальные данные часто ЧАСТИЧНО отсортированы.
 * TimSort эксплуатирует это:
 * 1. Находит "runs" — уже отсортированные подпоследовательности
 * 2. Маленькие runs сортирует Insertion Sort
 * 3. Большие runs сливает как в MergeSort
 *
 * Сложность:
 * - O(n) на уже отсортированных данных!
 * - O(n log n) в худшем случае
 * - Стабильный
 */
const val MIN_RUN = 32  // Минимальный размер run (эмпирически подобран)

fun timSort(arr: IntArray) {
    val n = arr.size

    // ШАГ 1: Создаём маленькие отсортированные "run" размером MIN_RUN
    // Для маленьких участков Insertion Sort быстрее из-за низкого overhead
    // Insertion Sort хорошо работает на почти отсортированных данных
    for (i in 0 until n step MIN_RUN) {
        // Сортируем участок [i, min(i + MIN_RUN - 1, n - 1)]
        insertionSort(arr, i, minOf(i + MIN_RUN - 1, n - 1))
    }

    // ШАГ 2: Сливаем run-ы, удваивая размер на каждой итерации
    // Размер run: 32 → 64 → 128 → 256 → ... → n
    var size = MIN_RUN
    while (size < n) {
        // На каждой итерации: сливаем соседние пары run-ов
        for (left in 0 until n step 2 * size) {
            val mid = left + size - 1  // Конец первого run
            val right = minOf(left + 2 * size - 1, n - 1)  // Конец второго run

            // Сливаем только если второй run существует
            if (mid < right) {
                mergeInPlace(arr, IntArray(n), left, mid, right)
            }
        }
        size *= 2  // Удваиваем размер для следующей итерации
    }
}

/**
 * Insertion Sort — эффективен для маленьких и почти отсортированных массивов
 *
 * Идея: берём элементы по одному и вставляем на правильное место
 * в уже отсортированную часть слева.
 */
fun insertionSort(arr: IntArray, left: Int, right: Int) {
    for (i in left + 1..right) {
        val key = arr[i]  // Элемент, который нужно вставить
        var j = i - 1

        // Сдвигаем элементы вправо, пока не найдём место для key
        while (j >= left && arr[j] > key) {
            arr[j + 1] = arr[j]  // Сдвигаем вправо
            j--
        }

        arr[j + 1] = key  // Вставляем на правильное место
    }
}

// ПОЧЕМУ TimSort быстр на реальных данных:
//
// 1. Реальные данные часто ЧАСТИЧНО отсортированы:
//    - Логи (по времени)
//    - Транзакции (по дате)
//    - Имена (по алфавиту)
//
// 2. TimSort НАХОДИТ существующие отсортированные участки:
//    [1, 2, 3, 9, 8, 7, 4, 5, 6]
//         ↑run    ↑run     ↑run
//
// 3. И СЛИВАЕТ их эффективно:
//    [1,2,3] + [7,8,9] + [4,5,6] → [1,2,3,4,5,6,7,8,9]
//
// Сложность на отсортированных данных: O(n)!
```

### IntroSort (идея)

```kotlin
/**
 * IntroSort — "интроспективная сортировка"
 *
 * ИДЕЯ: QuickSort быстрый, но может деградировать до O(n²).
 * IntroSort ОТСЛЕЖИВАЕТ глубину рекурсии и при подозрении
 * на плохой случай переключается на HeapSort (гарантированно O(n log n)).
 *
 * Комбинирует:
 * - QuickSort — для общего случая (быстрый)
 * - HeapSort — если QuickSort начал деградировать
 * - Insertion Sort — для маленьких массивов
 *
 * Используется в: C++ STL std::sort, .NET
 */
fun introSort(arr: IntArray, maxDepth: Int = 2 * log2(arr.size.toDouble()).toInt()) {
    introSortHelper(arr, 0, arr.lastIndex, maxDepth)
}

fun introSortHelper(arr: IntArray, low: Int, high: Int, depthLimit: Int) {
    val size = high - low + 1

    when {
        // СЛУЧАЙ 1: Маленький массив — используем Insertion Sort
        // Для массивов <= 16 элементов Insertion Sort быстрее
        // из-за низкого overhead (нет рекурсии, простые операции)
        size <= 16 -> {
            insertionSort(arr, low, high)
        }

        // СЛУЧАЙ 2: Достигли лимита глубины — переключаемся на HeapSort
        // Если QuickSort ушёл слишком глубоко (> 2 * log n уровней),
        // значит мы попали в плохой случай (например, отсортированный массив
        // с плохим выбором pivot). HeapSort гарантирует O(n log n).
        depthLimit == 0 -> {
            heapSortRange(arr, low, high)
        }

        // СЛУЧАЙ 3: Нормальный случай — продолжаем QuickSort
        else -> {
            val pivot = partition(arr, low, high)
            // Уменьшаем depthLimit на 1 при каждом рекурсивном вызове
            introSortHelper(arr, low, pivot - 1, depthLimit - 1)
            introSortHelper(arr, pivot + 1, high, depthLimit - 1)
        }
    }
}

// ПОЧЕМУ maxDepth = 2 * log2(n)?
//
// Для идеального QuickSort глубина рекурсии = log2(n).
// Если глубина превысила 2 * log2(n), значит что-то пошло не так:
// - Плохой выбор pivot
// - Много дубликатов
// - Специально подобранный "killer input"
//
// В таких случаях HeapSort спасает от O(n²).
```

---

## Использование встроенных сортировок

На практике почти ВСЕГДА используйте встроенные сортировки — они оптимизированы и протестированы.

### Kotlin

```kotlin
// ==================== МАССИВЫ ====================

val arr = intArrayOf(5, 2, 8, 1, 9)

// sort() — сортировка in-place (изменяет исходный массив)
// Для примитивов (IntArray, LongArray, ...) использует Dual-Pivot QuickSort
arr.sort()  // arr = [1, 2, 5, 8, 9]

// ==================== СПИСКИ ====================

val list = mutableListOf(5, 2, 8, 1, 9)

// sort() — сортировка in-place (изменяет список)
// Использует TimSort — стабильная сортировка!
list.sort()  // list = [1, 2, 5, 8, 9]

// sorted() — возвращает НОВЫЙ отсортированный список (исходный не меняется)
val original = listOf(5, 2, 8, 1, 9)
val sorted = original.sorted()  // original = [5,2,8,1,9], sorted = [1,2,5,8,9]

// ==================== КАСТОМНАЯ СОРТИРОВКА ====================

data class Person(val name: String, val age: Int)
val people = listOf(Person("Alice", 30), Person("Bob", 25))

// sortedBy — сортировка по одному полю
val byAge = people.sortedBy { it.age }
// Результат: [Person(Bob, 25), Person(Alice, 30)]

// sortedWith + compareBy — сортировка по нескольким критериям
// Сначала по возрасту, при равенстве — по имени
val byAgeThenName = people.sortedWith(compareBy({ it.age }, { it.name }))

// ==================== ПО УБЫВАНИЮ ====================

arr.sortDescending()  // [9, 8, 5, 2, 1]
val desc = list.sortedByDescending { it }  // новый список по убыванию
```

### Java

```java
// ==================== ПРИМИТИВНЫЕ МАССИВЫ ====================

int[] arr = {5, 2, 8, 1, 9};
// Для примитивов — Dual-Pivot QuickSort (НЕ стабильный!)
Arrays.sort(arr);  // arr = [1, 2, 5, 8, 9]

// ==================== МАССИВЫ ОБЪЕКТОВ ====================

Integer[] objArr = {5, 2, 8, 1, 9};
// Для объектов — TimSort (СТАБИЛЬНЫЙ!)
Arrays.sort(objArr);

// ==================== КАСТОМНАЯ СОРТИРОВКА ====================

// По одному полю
Arrays.sort(people, Comparator.comparingInt(Person::getAge));

// По нескольким полям: сначала по возрасту, потом по имени
Arrays.sort(people, Comparator.comparingInt(Person::getAge)
                              .thenComparing(Person::getName));

// ==================== СПИСКИ ====================

List<Integer> list = Arrays.asList(5, 2, 8, 1, 9);
// Collections.sort() использует TimSort (стабильный!)
Collections.sort(list);

// С Java 8+ можно использовать list.sort()
list.sort(Comparator.naturalOrder());
list.sort(Comparator.reverseOrder());
```

### Python

```python
# ==================== СПИСКИ ====================

arr = [5, 2, 8, 1, 9]

# sort() — сортировка in-place (изменяет список)
# Использует TimSort!
arr.sort()  # arr = [1, 2, 5, 8, 9]

# sorted() — возвращает НОВЫЙ отсортированный список
original = [5, 2, 8, 1, 9]
new_list = sorted(original)  # original не изменился!

# ==================== КАСТОМНАЯ СОРТИРОВКА ====================

# Сортировка по ключу
people.sort(key=lambda p: p.age)

# Сортировка по нескольким критериям (кортеж!)
sorted(people, key=lambda p: (p.age, p.name))

# ==================== ПО УБЫВАНИЮ ====================

arr.sort(reverse=True)  # [9, 8, 5, 2, 1]
sorted(arr, reverse=True)

# Для сложных ключей с разным направлением:
# - по возрасту возрастание, при равенстве по имени убывание
sorted(people, key=lambda p: (p.age, p.name), reverse=True)  # оба убывают

# Для разных направлений нужны трюки:
sorted(people, key=lambda p: (p.age, -ord(p.name[0])))  # возраст ↑, имя ↓
```

---

## Сложность операций

### Comparison-Based Sorting

| Algorithm | Best | Average | Worst | Space | Stable |
|-----------|------|---------|-------|-------|--------|
| QuickSort | O(n log n) | O(n log n) | O(n²) | O(log n) | No |
| MergeSort | O(n log n) | O(n log n) | O(n log n) | O(n) | **Yes** |
| HeapSort | O(n log n) | O(n log n) | O(n log n) | O(1) | No |
| TimSort | **O(n)** | O(n log n) | O(n log n) | O(n) | **Yes** |
| IntroSort | O(n log n) | O(n log n) | O(n log n) | O(log n) | No |

### Non-Comparison Sorting

| Algorithm | Time | Space | When to Use |
|-----------|------|-------|-------------|
| Counting Sort | O(n + k) | O(k) | Small range integers |
| Radix Sort | O(d(n + k)) | O(n + k) | Fixed-length integers/strings |
| Bucket Sort | O(n + k) | O(n) | Uniformly distributed floats |

### Почему QuickSort быстрее на практике?

Несмотря на O(n²) worst case:
1. **Cache locality** — последовательный доступ к памяти
2. **In-place** — не требует дополнительной памяти
3. **Small constant factor** — меньше операций на элемент
4. **Modern implementations** — IntroSort избегает worst case

---

## Распространённые ошибки

### 1. Неправильный выбор pivot в QuickSort

```kotlin
// ❌ WRONG: Always picking first/last element
// Worst case O(n²) on sorted/reverse-sorted input
fun badPartition(arr: IntArray, low: Int, high: Int): Int {
    val pivot = arr[low]  // Always first element
    // ...
}

// ✅ CORRECT: Random pivot or median-of-three
fun goodPartition(arr: IntArray, low: Int, high: Int): Int {
    // Random pivot
    val randomIndex = (low..high).random()
    arr[randomIndex] = arr[high].also { arr[high] = arr[randomIndex] }

    // Or median-of-three
    val mid = low + (high - low) / 2
    val pivotIndex = medianOfThree(arr, low, mid, high)
    // ...
}
```

### 2. Нестабильная сортировка когда нужна стабильная

```kotlin
// ❌ WRONG: Using QuickSort for objects where order matters
data class Transaction(val amount: Int, val timestamp: Long)
val transactions = listOf(...)
transactions.sortedBy { it.amount }  // Order of equal amounts is NOT preserved

// ✅ CORRECT: Use stable sort (MergeSort/TimSort)
transactions.sortedWith(compareBy<Transaction> { it.amount }
    .thenBy { it.timestamp })  // Explicit secondary sort
```

### 3. Забыли об overflow при вычислении mid

```kotlin
// ❌ WRONG: Can overflow for large arrays
val mid = (low + high) / 2

// ✅ CORRECT: Safe calculation
val mid = low + (high - low) / 2
```

### 4. Неправильные границы в merge

```kotlin
// ❌ WRONG: Off-by-one error
fun merge(arr: IntArray, left: Int, mid: Int, right: Int) {
    // Copying wrong range
    for (k in left until right) { /* ... */ }  // Should be left..right
}

// ✅ CORRECT: Inclusive bounds
fun merge(arr: IntArray, left: Int, mid: Int, right: Int) {
    for (k in left..right) { /* ... */ }
}
```

### 5. Использование O(n²) алгоритмов для больших данных

```kotlin
// ❌ WRONG: Bubble/Selection/Insertion sort for large data
fun bubbleSort(arr: IntArray) {
    // Fine for n < 100, disaster for n > 10000
}

// ✅ CORRECT: Use efficient algorithms or built-in sort
arr.sort()  // O(n log n) guaranteed
```

### 6. Игнорирование особенностей данных

```kotlin
// ❌ WRONG: Using comparison sort for small range integers
val ages = intArrayOf(25, 30, 22, 28, 30, 25, ...)  // Ages 0-150
ages.sort()  // O(n log n)

// ✅ CORRECT: Use counting sort for O(n)
fun countingSort(ages: IntArray): IntArray {
    val count = IntArray(151)  // 0-150
    for (age in ages) count[age]++
    // ...
}
```

### 7. Бесконечная рекурсия в QuickSort

```kotlin
// ❌ WRONG: Not excluding pivot from recursive calls
fun badQuickSort(arr: IntArray, low: Int, high: Int) {
    if (low < high) {
        val pi = partition(arr, low, high)
        badQuickSort(arr, low, pi)     // Should be pi - 1
        badQuickSort(arr, pi, high)    // Should be pi + 1
    }
}

// ✅ CORRECT: Exclude pivot from both calls
fun quickSort(arr: IntArray, low: Int, high: Int) {
    if (low < high) {
        val pi = partition(arr, low, high)
        quickSort(arr, low, pi - 1)    // Exclude pivot
        quickSort(arr, pi + 1, high)   // Exclude pivot
    }
}
```

---

## Когда какой алгоритм использовать

### Decision Tree

```
                    Need to sort?
                         │
            ┌────────────┴────────────┐
            │                         │
     Small array (n < 50)?      Large array?
            │                         │
            ↓                         │
      Insertion Sort            ┌─────┴─────┐
                                │           │
                         Integers in    General data?
                         small range?        │
                                │           │
                                ↓           │
                          Counting Sort     │
                                      ┌─────┴─────┐
                                      │           │
                               Need stability?    Memory
                                      │         constrained?
                              ┌───────┴──────┐       │
                              │              │       ↓
                             Yes            No    HeapSort
                              │              │
                              ↓              ↓
                         MergeSort     QuickSort
                          (TimSort)   (IntroSort)
```

### Summary Table

| Ситуация | Лучший выбор | Почему |
|----------|--------------|--------|
| Общее назначение | Built-in sort | Оптимизирован для языка |
| Нужна стабильность | MergeSort / TimSort | Сохраняет порядок равных |
| Ограничена память | HeapSort | O(1) space |
| Linked list | MergeSort | Только sequential access |
| Почти отсортировано | TimSort | O(n) для sorted data |
| Integers 0..k (k small) | Counting Sort | O(n + k) |
| Фиксированная длина ключей | Radix Sort | O(d × n) |
| Нужен k-th элемент | QuickSelect | O(n) average |
| Параллельная обработка | MergeSort | Легко распараллелить |

---

## Практика

### Концептуальные вопросы

1. **Почему QuickSort быстрее MergeSort на практике, несмотря на O(n²) worst case?**

   *Ответ:* Cache locality (последовательный доступ к памяти), in-place (нет overhead на allocation), меньший constant factor. Modern implementations используют IntroSort чтобы избежать O(n²).

2. **Когда MergeSort лучше QuickSort?**

   *Ответ:* Когда нужна стабильность, для linked lists (MergeSort не требует random access), для external sorting (данные на диске), для parallel sorting.

3. **Почему TimSort используется в Python и Java?**

   *Ответ:* Real-world данные часто частично отсортированы. TimSort использует это: находит "runs" (отсортированные подпоследовательности) и эффективно их сливает. O(n) на отсортированных данных.

4. **Как сделать QuickSort стабильным?**

   *Ответ:* Использовать дополнительную память для сохранения индексов (как в MergeSort), что делает его похожим на MergeSort. В реальности проще использовать MergeSort.

5. **Когда Counting Sort лучше QuickSort?**

   *Ответ:* Когда сортируем integers в диапазоне [0, k] где k = O(n). Тогда Counting Sort даёт O(n + k) = O(n), что лучше O(n log n).

### LeetCode задачи

#### Easy
- **912. Sort an Array** — базовая сортировка
- **88. Merge Sorted Array** — merge step из MergeSort
- **21. Merge Two Sorted Lists** — merge для linked lists

#### Medium
- **75. Sort Colors** — Dutch National Flag (partition)
- **148. Sort List** — MergeSort для linked list
- **215. Kth Largest Element** — QuickSelect
- **347. Top K Frequent Elements** — sorting + heap
- **56. Merge Intervals** — sorting as preprocessing
- **179. Largest Number** — custom comparator
- **274. H-Index** — counting sort application

#### Hard
- **315. Count of Smaller Numbers After Self** — merge sort + counting
- **493. Reverse Pairs** — merge sort + counting
- **327. Count of Range Sum** — merge sort application

---

## Связанные темы

### Prerequisites (что нужно знать до)
- [Arrays & Basic Operations](../data-structures/arrays.md)
- [Recursion](./recursion.md)
- [Time Complexity Analysis](../overview.md)
- [Heaps](../data-structures/heaps-priority-queues.md) — для HeapSort

### Что открывает (изучить после)
- [Binary Search](./searching-algorithms.md) — требует отсортированный массив
- [Divide and Conquer](./divide-and-conquer.md) — общий паттерн
- [Two Pointers Pattern](../patterns/two-pointers-pattern.md) — часто на отсортированных данных
- [Merge Intervals Pattern](../patterns/intervals-pattern.md) — требует сортировку

---

## Мифы и заблуждения

| Миф | Реальность |
|-----|-----------|
| "QuickSort всегда O(n log n)" | Worst case O(n²) на отсортированных данных. **Randomized pivot** нужен |
| "MergeSort лучше QuickSort" | QuickSort **in-place**, MergeSort требует O(n) памяти. QuickSort часто быстрее на практике |
| "O(n log n) — предел" | Для comparison-based да. **Counting/Radix Sort** дают O(n) для integers |
| "Стабильность не важна" | Стабильность критична для **multi-key sorting**. sort by date, then by name |
| "Arrays.sort = QuickSort" | Java: **Dual-Pivot QuickSort** для primitives, **TimSort** для objects. Разные алгоритмы |

---

## CS-фундамент

| CS-концепция | Применение в Sorting |
|--------------|---------------------|
| **Divide and Conquer** | MergeSort, QuickSort разбивают массив на части, сортируют рекурсивно, сливают |
| **In-place Algorithm** | QuickSort, HeapSort работают с O(1) доп памяти. Важно для больших данных |
| **Stability** | MergeSort стабильна, QuickSort нет. Порядок равных элементов сохраняется |
| **Lower Bound** | Ω(n log n) для comparison-based. Доказательство через decision tree |
| **Adaptive Sorting** | TimSort использует already sorted runs. O(n) на частично отсортированных |

---

## Источники

1. [Wikipedia - Sorting Algorithm](https://en.wikipedia.org/wiki/Sorting_algorithm) — Overview
2. [Tech Interview Handbook - Sorting](https://www.techinterviewhandbook.org/algorithms/sorting-searching/) — Interview tips
3. [GeeksforGeeks - QuickSort](https://www.geeksforgeeks.org/dsa/quick-sort-algorithm/) — Implementation
4. [Wikipedia - TimSort](https://en.wikipedia.org/wiki/Timsort) — Hybrid algorithm
5. [Baeldung - Quicksort vs Heapsort](https://www.baeldung.com/cs/quicksort-vs-heapsort) — Comparison
6. [Princeton - MergeSort](https://algs4.cs.princeton.edu/22mergesort/) — Academic reference
7. [OpenJDK - DualPivotQuicksort.java](https://github.com/openjdk/jdk/blob/master/src/java.base/share/classes/java/util/DualPivotQuicksort.java) — Production code
8. [Kotlin - Ordering](https://kotlinlang.org/docs/collection-ordering.html) — Language docs
9. [VisuAlgo - Sorting](https://visualgo.net/en/sorting) — Interactive visualization
10. [Toptal - Sorting Algorithms Animations](https://www.toptal.com/developers/sorting-algorithms) — Visual comparison
11. [interviewing.io - Sorting Interview Questions](https://interviewing.io/sorting-interview-questions) — Interview tips
12. [AlgoCademy - Mastering Sorting](https://algocademy.com/blog/mastering-sorting-algorithms-for-your-coding-interview/) — Interview prep
13. [Baeldung - Counting vs Bucket vs Radix](https://www.baeldung.com/cs/radix-vs-counting-vs-bucket-sort) — Non-comparison sorts

---

## Навигация

← Предыдущая: [[tries|Tries]]
→ Следующая: [[searching-algorithms|Searching Algorithms]]
↑ Вверх: [[_moc-algorithms|Algorithms MOC]]


---

## Проверь себя

> [!question]- Почему Quick Sort в среднем O(n log n), но в худшем O(n^2)?
> В среднем pivot делит массив примерно пополам, давая log n уровней по O(n) работы каждый. В худшем случае (уже отсортированный массив + плохой выбор pivot) одна часть пустая, другая n-1, что даёт n уровней. Решение: randomized pivot или median-of-three.

> [!question]- Тебе нужно отсортировать 10 миллионов записей по возрасту (0-150). Какой алгоритм выбрать и почему?
> Counting Sort: O(n + k) где k=150 -- линейное время. Не основан на сравнениях, поэтому обходит нижнюю границу O(n log n). Для малого диапазона значений counting sort в разы быстрее comparison-based алгоритмов.

> [!question]- Почему Merge Sort стабилен, а Quick Sort -- нет?
> Merge Sort при слиянии берёт элемент из левой части при равенстве, сохраняя исходный порядок равных элементов. Quick Sort при разбиении может поменять равные элементы местами относительно pivot. Стабильность важна для сортировки по нескольким ключам.

---

## Ключевые карточки

Какова нижняя граница сортировки сравнениями?
?
Omega(n log n) -- доказывается через дерево решений. n! возможных перестановок требуют log(n!) = Theta(n log n) сравнений для различения. Counting Sort и Radix Sort обходят это, не используя сравнения.

Чем отличаются Quick Sort, Merge Sort и Heap Sort?
?
Quick Sort: O(n log n) avg, O(n^2) worst, in-place, не стабильный. Merge Sort: O(n log n) always, O(n) extra memory, стабильный. Heap Sort: O(n log n) always, in-place, не стабильный. Tim Sort (Python/Java): гибрид Merge+Insertion, стабильный.

Что такое Tim Sort?
?
Гибридный алгоритм: использует Insertion Sort для малых подмассивов (runs), затем Merge Sort для объединения. O(n log n) worst, O(n) best (почти отсортированные данные). Стабильный. Используется в Python, Java, Android.

Когда Insertion Sort лучше Quick Sort?
?
Для малых массивов (n < 10-50): меньше overhead, лучше cache locality, меньше branch mispredictions. Поэтому Tim Sort переключается на Insertion Sort для коротких runs.

Что значит стабильность сортировки?
?
Стабильная сортировка сохраняет относительный порядок равных элементов. Важно при сортировке по нескольким ключам: сортируем по фамилии, затем стабильно по имени -- получаем правильный порядок.

---

## Куда дальше

| Направление | Куда | Зачем |
|-------------|------|-------|
| Следующий шаг | [[algorithms/searching-algorithms]] | Алгоритмы поиска в данных |
| Углубиться | [[algorithms/divide-and-conquer]] | Теория Divide and Conquer (Merge Sort) |
| Смежная тема | [[data-structures/heaps-priority-queues]] | Heap Sort и Priority Queue |
| Обзор | [[cs-fundamentals-overview]] | Вернуться к карте раздела |

*Обновлено: 2026-01-06 (добавлены педагогические секции: интуиция, почему сложно, ментальные модели)*
