---
title: "Эволюция HTTP: от 1.0 до QUIC"
created: 2025-12-18
modified: 2026-02-13
type: concept
status: published
confidence: high
sources_verified: true
tags:
  - topic/networking
  - networking/protocols
  - networking/http
  - networking/performance
  - networking/quic
  - type/concept
  - level/intermediate
related:
  - "[[network-transport-layer]]"
  - "[[network-dns-tls]]"
  - "[[networking-overview]]"
prerequisites:
  - "[[network-transport-layer]]"
  - "[[network-dns-tls]]"
reading_time: 116
difficulty: 5
study_status: not_started
mastery: 0
last_reviewed:
next_review:
---

# Эволюция HTTP: от 1.0 до QUIC

## Prerequisites (Что нужно знать перед изучением)

| Тема | Зачем нужна | Где изучить |
|------|-------------|-------------|
| **Основы TCP/IP** | HTTP работает поверх TCP (или UDP для HTTP/3) | [[network-transport-layer]] |
| **DNS** | Как браузер находит IP-адрес сервера | [[network-dns-tls]] |
| **TLS/SSL** | Шифрование для HTTPS | [[network-dns-tls]] |
| **Основы веб** | Как работают веб-серверы и браузеры | Любой курс по веб-разработке |

---

## Аналогия для понимания: HTTP как почта

> **Представьте отправку писем:**
> - **HTTP/1.0** — одно письмо = один почтальон. Хотите отправить 10 писем? 10 почтальонов, каждый едет туда-обратно.
> - **HTTP/1.1** — один почтальон, но ждёт пока вы напишете все письма по очереди. Медленное письмо задерживает все остальные (HOL blocking).
> - **HTTP/2** — один почтальон с большой сумкой. Все письма едут вместе, но если сумка застрянет на переправе (TCP packet loss), все письма ждут.
> - **HTTP/3** — почтальон на квадроцикле (QUIC/UDP). Каждое письмо в отдельном контейнере. Если один контейнер упал — только он задерживается, остальные едут дальше.

---

## Когда какую версию использовать?

| Сценарий | Рекомендация | Почему |
|----------|--------------|--------|
| **Новый веб-сайт** | HTTP/3 + HTTP/2 fallback | Максимальная производительность |
| **API сервер** | HTTP/2 минимум | Multiplexing для параллельных запросов |
| **Mobile приложение** | HTTP/3 + HTTP/2 | Connection migration для Wi-Fi↔4G |
| **Legacy система** | HTTP/1.1 | Если нет возможности обновить инфраструктуру |
| **Высокая потеря пакетов (3G, Wi-Fi)** | HTTP/3 | Per-stream loss recovery |
| **Enterprise (UDP заблокирован)** | HTTP/2 | HTTP/3 требует UDP |
| **Realtime (WebSocket)** | HTTP/2 или HTTP/1.1 | WebSocket over HTTP/3 в развитии |
| **gRPC** | HTTP/2 | gRPC требует HTTP/2 |

---

## Быстрая навигация

**Ищешь конкретную версию HTTP?**
| Версия | Главная фича | Главная проблема | Раздел |
|--------|--------------|------------------|--------|
| HTTP/1.1 | Persistent connections | HOL blocking | [→ HTTP/1.1](#http11-persistent-connections-pipelining) |
| HTTP/2 | Multiplexing, binary | TCP HOL blocking | [→ HTTP/2](#http2-multiplexing-binary-protocol) |
| HTTP/3 | QUIC over UDP | Firewall/middlebox issues | [→ HTTP/3](#http3-quic-over-udp) |

**По задаче:**
- **Оптимизируешь производительность?** → [Performance Best Practices](#performance-best-practices)
- **Внедряешь HTTP/2?** → [HTTP/2 на практике](#http2-на-практике)
- **Мигрируешь на HTTP/3?** → [HTTP/3 на практике](#http3-на-практике)
- **Отлаживаешь проблемы?** → [Подводные камни](#подводные-камни)
- **Нужен быстрый справочник терминов?** → [Терминология](#терминология)

---

## Оглавление
- [Терминология](#терминология)
- [ПОЧЕМУ: История и проблемы](#почему-история-и-проблемы)
- [ЧТО: Эволюция протокола](#что-эволюция-протокола)
- [КАК: Практическая реализация](#как-практическая-реализация)
- [Подводные камни](#подводные-камни)

---

## Терминология

| Термин | Определение |
|--------|-------------|
| **HOL Blocking** | Head-of-Line blocking - блокировка очереди, когда один медленный запрос блокирует все последующие |
| **Multiplexing** | Мультиплексирование - одновременная передача нескольких потоков данных по одному соединению |
| **Binary Framing** | Бинарное кадрирование - разделение данных на бинарные фреймы вместо текстовых строк |
| **Stream** | Поток - независимый двунаправленный канал обмена фреймами внутри HTTP/2 соединения |
| **HPACK** | HTTP/2 header compression - алгоритм сжатия заголовков в HTTP/2 |
| **QPACK** | QUIC header compression - улучшенный алгоритм сжатия заголовков для HTTP/3 |
| **QUIC** | Quick UDP Internet Connections - транспортный протокол поверх UDP для HTTP/3 |
| **0-RTT** | Zero Round-Trip Time - установка соединения без дополнительных задержек при повторном подключении |
| **Server Push** | Проактивная отправка ресурсов сервером без явного запроса клиента |
| **Flow Control** | Управление потоком - механизм предотвращения перегрузки получателя данными |
| **Stream Priority** | Приоритизация потоков - механизм указания важности различных ресурсов |
| **Connection Migration** | Миграция соединения - возможность сохранить соединение при смене сети (Wi-Fi → 4G) |

---

## Часть 1: Интуиция без кода

> 💡 **Цель раздела**: Понять эволюцию HTTP через 5 развёрнутых аналогий из реальной жизни.

### Аналогия 1: HTTP версии как поколения телефонной связи

```
HTTP/1.0 (1996) = Телеграф                HTTP/3 (2022) = 5G + мессенджеры
┌──────────────────────────────────┐      ┌──────────────────────────────────┐
│                                  │      │                                  │
│  • Один провод на одно           │      │  • Мгновенное соединение         │
│    сообщение                     │      │  • Много потоков одновременно    │
│  • Каждый раз заново             │      │  • Работает при переключении     │
│    устанавливать связь           │      │    между WiFi и 4G               │
│  • Медленно и дорого             │      │  • Быстро и надёжно              │
│                                  │      │                                  │
└──────────────────────────────────┘      └──────────────────────────────────┘

HTTP/1.1 = Стационарный телефон        HTTP/2 = VoIP (Skype, Zoom)
┌──────────────────────────────────┐   ┌──────────────────────────────────┐
│                                  │   │                                  │
│  • Линия остаётся открытой       │   │  • Один "провод" для всех        │
│  • Но говорим по очереди         │   │    разговоров                    │
│  • Если один тормозит —          │   │  • Можно говорить параллельно    │
│    все ждут                      │   │  • НО: если интернет "лагает"    │
│                                  │   │    — всё зависает                │
└──────────────────────────────────┘   └──────────────────────────────────┘
```

**Ключевой инсайт:** Каждое поколение HTTP решает главную проблему предыдущего:
- HTTP/1.1 → Keep-alive (не переподключаемся каждый раз)
- HTTP/2 → Multiplexing (параллельные запросы)
- HTTP/3 → QUIC/UDP (независимость потоков при потере пакетов)

---

### Аналогия 2: Multiplexing как несколько кассиров

```
HTTP/1.1 = Один кассир в супермаркете:

┌─────────────────────────────────────────────────────────────────────┐
│  Очередь:                                                           │
│                                                                     │
│  [Клиент 5] ← [Клиент 4] ← [Клиент 3] ← [Клиент 2] ← [КАССА 1]      │
│                                                                     │
│  Клиент 2 забыл взвесить помидоры → ВСЕ ждут                        │
│                                                                     │
│  Workaround браузера: открыть 6 касс (6 TCP connections)            │
│  [КАССА 1] [КАССА 2] [КАССА 3] [КАССА 4] [КАССА 5] [КАССА 6]        │
│                                                                     │
│  Но каждая касса = накладные расходы (TCP handshake, memory)        │
└─────────────────────────────────────────────────────────────────────┘

HTTP/2 = Один супер-кассир, обслуживает всех одновременно:

┌─────────────────────────────────────────────────────────────────────┐
│                                                                     │
│     [СУПЕР-КАССА]                                                   │
│          │                                                          │
│    ┌─────┼─────┐                                                    │
│    ↓     ↓     ↓                                                    │
│  [К1]  [К2]  [К3]   ← Все обслуживаются параллельно                │
│                                                                     │
│  Товары сканируются вперемешку, но каждый получает свой чек         │
│  (каждый stream — независимый)                                      │
│                                                                     │
│  НО: если конвейер сломался (TCP packet loss) — ВСЕ ждут            │
└─────────────────────────────────────────────────────────────────────┘

HTTP/3 = Несколько независимых конвейеров:

┌─────────────────────────────────────────────────────────────────────┐
│                                                                     │
│     [КАССА с 5 конвейерами]                                         │
│          │                                                          │
│    ═════╪═════════════════                                          │
│    ═════╪══════════ ← Конвейер 2 застрял                            │
│    ═════╪═══════════════════                                        │
│    ═════╪═════════════════════                                      │
│    ═════╪═══════════════                                            │
│                                                                     │
│  Конвейер 2 застрял → только клиент 2 ждёт                          │
│  Все остальные продолжают двигаться!                                │
│                                                                     │
└─────────────────────────────────────────────────────────────────────┘
```

---

### Аналогия 3: HOL Blocking как пробка на дороге

```
HTTP/1.1 HOL Blocking (уровень приложения):

┌─────────────────────────────────────────────────────────────────────┐
│                                                                     │
│   Однополосная дорога:                                              │
│                                                                     │
│   [Грузовик    ] [Легковая] [Легковая] [Легковая]                   │
│   (большой     )                                                    │
│    файл CSS)     Все ждут, пока грузовик проедет!                   │
│                                                                     │
│   Решение HTTP/1.1: больше дорог (connections)                      │
│   Дорога 1: [Грузовик]                                              │
│   Дорога 2: [Легковая][Легковая]                                    │
│   Дорога 3: [Легковая][Легковая]                                    │
│                                                                     │
└─────────────────────────────────────────────────────────────────────┘

HTTP/2 решает HOL на уровне приложения... но создаёт на TCP:

┌─────────────────────────────────────────────────────────────────────┐
│                                                                     │
│   Многополосная дорога (multiplexing):                              │
│                                                                     │
│   Полоса 1: [=CSS=]                                                 │
│   Полоса 2: [=JS=]                                                  │
│   Полоса 3: [=Image=]                                               │
│                                                                     │
│   НО! Все полосы на одном мосту (TCP):                              │
│                                                                     │
│   ─────[МОСТ TCP]─────                                              │
│            💥 Авария!                                                │
│                                                                     │
│   Если на мосту авария (потеря TCP пакета) —                        │
│   ВСЕ полосы стоят, пока не разберут!                               │
│                                                                     │
└─────────────────────────────────────────────────────────────────────┘

HTTP/3 решает это через QUIC:

┌─────────────────────────────────────────────────────────────────────┐
│                                                                     │
│   Три независимых моста (QUIC streams):                             │
│                                                                     │
│   Мост 1: [=CSS=══════════════════]  ✓ Проехали                     │
│   Мост 2: [=JS═════💥═════════════]  ⏳ Только этот ждёт            │
│   Мост 3: [=Image═════════════════]  ✓ Проехали                     │
│                                                                     │
│   Авария на мосту 2 не влияет на остальные!                         │
│                                                                     │
└─────────────────────────────────────────────────────────────────────┘
```

---

### Аналогия 4: 0-RTT как VIP-вход для постоянных клиентов

```
Первый визит (1-RTT):

┌─────────────────────────────────────────────────────────────────────┐
│                                                                     │
│  Посетитель                                   Охрана клуба          │
│      │                                             │                │
│      │  "Привет, я хочу войти"                     │                │
│      │ ─────────────────────────────────────────► │                │
│      │                                             │                │
│      │  "Покажи паспорт, вот пропуск"              │                │
│      │ ◄───────────────────────────────────────── │                │
│      │                                             │                │
│      │  "Вот паспорт, сохрани меня в базе"         │                │
│      │ ─────────────────────────────────────────► │  ВОШЁЛ!        │
│      │                                             │                │
│      Получил VIP-карту на будущее                  │                │
│                                                                     │
│  Итого: 1 round-trip до входа в клуб                                │
│                                                                     │
└─────────────────────────────────────────────────────────────────────┘

Повторный визит (0-RTT):

┌─────────────────────────────────────────────────────────────────────┐
│                                                                     │
│  VIP-посетитель                               Охрана клуба          │
│      │                                             │                │
│      │  "Вот моя VIP-карта + хочу столик у окна"   │                │
│      │ ─────────────────────────────────────────► │  СРАЗУ ВОШЁЛ!  │
│      │                                             │                │
│      │  "Добро пожаловать, столик готов"           │                │
│      │ ◄───────────────────────────────────────── │                │
│      │                                             │                │
│  Итого: 0 round-trips до входа (запрос отправлен вместе с картой)  │
│                                                                     │
└─────────────────────────────────────────────────────────────────────┘

Но есть риск! (Replay Attack):

Злоумышленник скопировал вашу VIP-карту и запрос "столик у окна".
Теперь он может повторять этот запрос много раз!

Поэтому 0-RTT только для безопасных запросов:
✅ GET /menu.html (можно повторять)
❌ POST /order (нельзя — закажут 100 обедов!)
```

---

### Аналогия 5: Connection Migration как разговор при смене комнат

```
TCP (HTTP/1.1, HTTP/2) — Стационарный телефон с проводом:

┌─────────────────────────────────────────────────────────────────────┐
│                                                                     │
│  Вы в гостиной                     Друг на том конце                │
│  (WiFi: 192.168.1.5)                                                │
│      │                                                              │
│      │════════════════════════════════════════│                     │
│      │   "Разговор идёт хорошо..."            │                     │
│                                                                     │
│  Переходите на кухню (4G: 10.0.0.123)                               │
│                                                                     │
│      💥 ПРОВОД ОБОРВАЛСЯ!                                           │
│                                                                     │
│  ❌ "Соединение потеряно"                                           │
│  ❌ Нужно перезвонить (новый TCP handshake)                         │
│  ❌ Потеря данных, которые были "в пути"                            │
│                                                                     │
└─────────────────────────────────────────────────────────────────────┘

QUIC (HTTP/3) — Мобильный телефон:

┌─────────────────────────────────────────────────────────────────────┐
│                                                                     │
│  Вы в гостиной                     Друг на том конце                │
│  (WiFi: 192.168.1.5)                                                │
│      │                                                              │
│      │ )))  Connection ID: ABC123  (((  │                           │
│      │   "Разговор идёт хорошо..."      │                           │
│                                                                     │
│  Переходите на кухню (4G: 10.0.0.123)                               │
│                                                                     │
│      │                                                              │
│      │ )))  Connection ID: ABC123  (((  │   ← Тот же ID!            │
│      │   "...и продолжается без перерыва" │                          │
│                                                                     │
│  ✅ IP изменился, но Connection ID тот же                           │
│  ✅ Разговор продолжается без перезвона                             │
│  ✅ Нет потери данных                                               │
│                                                                     │
└─────────────────────────────────────────────────────────────────────┘

Почему это важно для мобильных?
- В метро: WiFi станции → 4G в тоннеле → WiFi следующей станции
- На улице: Переход между вышками сотовой связи
- Дома: WiFi → мобильный интернет при выходе
```

---

## Часть 2: Почему это сложно — 6 типичных ошибок

### Ошибка 1: Думать что HTTP/2 всегда быстрее HTTP/1.1

```
❌ СИМПТОМ:
Включили HTTP/2, а сайт стал МЕДЛЕННЕЕ на мобильных устройствах!
Особенно на 3G/4G с нестабильным соединением.

📋 ПРИЧИНА:
TCP Head-of-Line Blocking хуже при высоком packet loss.

HTTP/1.1 с 6 connections:
┌──────────────────────────────────────────────────────────────────┐
│  Connection 1: [===]💥[===]     ← Потеря, только этот ждёт       │
│  Connection 2: [=======]        ← Этот продолжает                │
│  Connection 3: [=========]      ← И этот продолжает              │
└──────────────────────────────────────────────────────────────────┘

HTTP/2 с 1 connection:
┌──────────────────────────────────────────────────────────────────┐
│  TCP Connection:                                                 │
│  [Stream1][Stream2][💥 TCP loss][Stream3][Stream4]               │
│                        ↑                                         │
│           ВСЕ STREAMS ЖДУТ РЕТРАНСМИТА!                          │
└──────────────────────────────────────────────────────────────────┘

При 1% packet loss: HTTP/2 может быть на 10-20% медленнее!
При 3% packet loss: разница ещё больше!

✅ РЕШЕНИЕ:
1. Мигрируйте на HTTP/3 (per-stream loss recovery)
2. Если нет — тестируйте на реальных мобильных сетях
3. Используйте CDN, который сам выбирает оптимальный протокол
```

---

### Ошибка 2: Domain Sharding с HTTP/2 ломает производительность

```
❌ СИМПТОМ:
Оптимизировали сайт для HTTP/1.1 (domain sharding),
включили HTTP/2 — стало хуже!

📋 ПРИЧИНА:
Domain sharding (static1.cdn.com, static2.cdn.com) работал для HTTP/1.1:
- Обходил лимит 6 connections на домен
- Больше параллельных загрузок

НО с HTTP/2 это ВРЕДИТ:
┌──────────────────────────────────────────────────────────────────┐
│  HTTP/1.1 + Domain Sharding:                                     │
│  static1.cdn.com: 6 connections                                  │
│  static2.cdn.com: 6 connections                                  │
│  static3.cdn.com: 6 connections                                  │
│  = 18 параллельных запросов ✓                                    │
│                                                                  │
│  HTTP/2 + Domain Sharding:                                       │
│  static1.cdn.com: 1 connection (с multiplexing) + DNS + TLS      │
│  static2.cdn.com: 1 connection + DNS + TLS                       │
│  static3.cdn.com: 1 connection + DNS + TLS                       │
│  = 3 отдельных TCP slow start, 3x TLS handshakes ✗               │
│                                                                  │
│  HTTP/2 БЕЗ Domain Sharding:                                     │
│  cdn.example.com: 1 connection с multiplexing                    │
│  = 1 TCP slow start, 1 TLS, unlimited parallel requests ✓        │
└──────────────────────────────────────────────────────────────────┘

✅ РЕШЕНИЕ:
# Для HTTP/2+: используйте один домен для статики
# Убрать:
<img src="https://static1.cdn.com/logo.png">
<img src="https://static2.cdn.com/hero.jpg">

# Оставить:
<img src="https://cdn.example.com/logo.png">
<img src="https://cdn.example.com/hero.jpg">
```

---

### Ошибка 3: Забыть HTTP/2 fallback при включении HTTP/3

```
❌ СИМПТОМ:
Включили HTTP/3, часть пользователей жалуется на недоступность сайта.
В логах — таймауты для 5-10% клиентов.

📋 ПРИЧИНА:
HTTP/3 работает на UDP. Многие корпоративные firewall блокируют UDP:
- "UDP = только DNS и VoIP"
- "Неизвестный UDP трафик = опасно"
- Старые NAT не поддерживают QUIC

┌──────────────────────────────────────────────────────────────────┐
│  Клиент в корпоративной сети:                                    │
│                                                                  │
│  Browser: "HTTP/3 на UDP:443? Пробую..."                         │
│  Firewall: "UDP? BLOCKED!"                                       │
│  Browser: ... ждёт ... timeout ... ждёт ...                      │
│  (30 секунд потеряно!)                                           │
│  Browser: "Ладно, попробую HTTP/2..."                            │
│  Firewall: "TCP:443? Пожалуйста!"                                │
└──────────────────────────────────────────────────────────────────┘

✅ РЕШЕНИЕ:

# Nginx: всегда слушать на обоих протоколах
listen 443 quic reuseport;      # HTTP/3
listen 443 ssl http2;            # HTTP/2 fallback

# Быстрый fallback timeout (1-3 секунды, не 30!)
# Браузеры обычно делают это автоматически

# Добавить Alt-Svc header для discovery
add_header Alt-Svc 'h3=":443"; ma=86400';

# Мониторинг: отслеживать % успешных HTTP/3 подключений
# Если < 80% — есть проблемы с сетью клиентов
```

---

### Ошибка 4: Server Push тратит трафик впустую

```
❌ СИМПТОМ:
Включили Server Push для CSS/JS, а bandwidth выросло на 30%!
Пользователи на мобильном интернете недовольны.

📋 ПРИЧИНА:
Server Push отправляет ресурсы ДО того, как клиент их запросит.
Но если ресурс уже в кэше браузера — трафик потрачен зря!

┌──────────────────────────────────────────────────────────────────┐
│  Первый визит:                                                   │
│  Client: GET /index.html                                         │
│  Server: PUSH_PROMISE /style.css  → 50KB отправлено              │
│          Response /index.html                                    │
│  Client: Сохранил style.css в кэш ✓                              │
│                                                                  │
│  Второй визит:                                                   │
│  Client: GET /index.html                                         │
│  Server: PUSH_PROMISE /style.css  → 50KB отправлено ОПЯТЬ!       │
│          Response /index.html                                    │
│  Client: У меня уже есть style.css! Зачем прислали?! ✗           │
│                                                                  │
│  Результат: 50KB × 1000 повторных визитов = 50MB впустую         │
└──────────────────────────────────────────────────────────────────┘

✅ РЕШЕНИЕ:

1. Используйте 103 Early Hints вместо Push:
   HTTP/1.1 103 Early Hints
   Link: </style.css>; rel=preload; as=style

   # Браузер САМ решает, загружать ли (проверяет кэш)

2. Push только критические ресурсы с версионированием:
   http2_push /style.v1.2.3.css;  # Версия в URL

3. Мониторьте push acceptance rate:
   # Если браузеры отвергают >50% push — отключите

4. Рассмотрите отказ от Push:
   # 2025: <5% сайтов используют Push
   # Большинство отключили из-за проблем с кэшем
```

---

### Ошибка 5: HTTP/2 reverse proxy теряет multiplexing

```
❌ СИМПТОМ:
Клиенты подключаются по HTTP/2, но производительность как у HTTP/1.1!
Нет параллелизма между запросами.

📋 ПРИЧИНА:
Nginx по умолчанию использует HTTP/1.1 для upstream:

┌──────────────────────────────────────────────────────────────────┐
│                                                                  │
│  Client ──HTTP/2──► Nginx ──HTTP/1.1──► Backend                  │
│         (parallel)        (sequential!)                          │
│                                                                  │
│  Nginx получает 10 parallel streams                              │
│  Конвертирует в 10 sequential HTTP/1.1 requests                  │
│  Backend видит: req1 → resp1 → req2 → resp2 → ...                │
│                                                                  │
│  Весь выигрыш от multiplexing потерян!                           │
│                                                                  │
└──────────────────────────────────────────────────────────────────┘

✅ РЕШЕНИЕ:

# Nginx: включить HTTP/2 для upstream
upstream backend {
    server backend.example.com:443;
    keepalive 100;
}

server {
    listen 443 ssl http2;

    location / {
        proxy_pass https://backend;
        proxy_http_version 1.1;  # ← ПЛОХО (по умолчанию!)
    }
}

# Исправленная версия:
location / {
    proxy_pass https://backend;
    # grpc_pass grpcs://backend;  # или gRPC (использует HTTP/2)

    # Для полного HTTP/2 upstream нужен Nginx Plus
    # или использовать Envoy/HAProxy
}

# Альтернатива: Envoy proxy с полным HTTP/2 support
clusters:
  - name: backend
    http2_protocol_options: {}
```

---

### Ошибка 6: Не учитывать 0-RTT replay attacks

```
❌ СИМПТОМ:
Включили 0-RTT для быстрого соединения.
Пользователи жалуются на дублирование заказов/действий!

📋 ПРИЧИНА:
0-RTT данные можно перехватить и воспроизвести (replay attack):

┌──────────────────────────────────────────────────────────────────┐
│                                                                  │
│  Легитимный пользователь:                                        │
│  Client ─────► 0-RTT: "POST /order {product: 'laptop'}"          │
│                                                                  │
│  Злоумышленник перехватил пакет:                                 │
│  Attacker ───► Replay: "POST /order {product: 'laptop'}"         │
│  Attacker ───► Replay: "POST /order {product: 'laptop'}"         │
│  Attacker ───► Replay: "POST /order {product: 'laptop'}"         │
│                                                                  │
│  Результат: 4 одинаковых заказа!                                 │
│                                                                  │
└──────────────────────────────────────────────────────────────────┘

✅ РЕШЕНИЕ:

# Nginx: запретить 0-RTT для non-idempotent запросов
ssl_early_data on;

location /api {
    # Отклонить 0-RTT для API (POST, PUT, DELETE)
    if ($ssl_early_data = 1) {
        return 425;  # Too Early (RFC 8470)
    }
    proxy_pass http://backend;
}

location /static {
    # Разрешить 0-RTT для статики (GET безопасен)
    proxy_pass http://cdn;
}

# На уровне приложения:
# 1. Idempotency keys для POST запросов
# 2. Проверка дубликатов в базе
# 3. Header Early-Data: 1 для идентификации 0-RTT
```

---

## Часть 3: Ментальные модели

### Модель 1: HTTP как язык общения между браузером и сервером

```
┌─────────────────────────────────────────────────────────────────┐
│                    HTTP КАК ЯЗЫК ОБЩЕНИЯ                        │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  Браузер говорит:               Сервер отвечает:                │
│  ─────────────────              ──────────────────              │
│  "GET /page.html"               "200 OK, вот страница"          │
│  "POST /login"                  "302, перенаправляю..."         │
│  "PUT /user/123"                "404, не нашёл"                 │
│  "DELETE /comment/456"          "500, я сломался"               │
│                                                                 │
│  HTTP/1.1 = Разговор по телефону                                │
│  ├─ Говорим по очереди                                          │
│  ├─ Простой текст                                               │
│  └─ Легко подслушать                                            │
│                                                                 │
│  HTTP/2 = Видеоконференция                                      │
│  ├─ Все говорят одновременно                                    │
│  ├─ Эффективно (сжатие)                                         │
│  └─ Всё ещё один канал                                          │
│                                                                 │
│  HTTP/3 = Умный мессенджер                                      │
│  ├─ Сообщения идут независимо                                   │
│  ├─ Работает при смене сети                                     │
│  └─ Встроенное шифрование                                       │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

---

### Модель 2: Версии HTTP как улучшения почтовой системы

```
┌─────────────────────────────────────────────────────────────────┐
│              ЭВОЛЮЦИЯ ПОЧТЫ = ЭВОЛЮЦИЯ HTTP                     │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  HTTP/1.0 = Курьер на лошади                                    │
│  ┌───────────────────────────────┐                              │
│  │  • Каждое письмо = новый курьер                              │
│  │  • Курьер едет туда-обратно                                  │
│  │  • Медленно и дорого                                         │
│  └───────────────────────────────┘                              │
│                                                                 │
│  HTTP/1.1 = Почтовое отделение с одним курьером                 │
│  ┌───────────────────────────────┐                              │
│  │  • Один курьер, много писем                                  │
│  │  • НО: письма идут по очереди                                │
│  │  • Большое письмо = все ждут                                 │
│  └───────────────────────────────┘                              │
│                                                                 │
│  HTTP/2 = Современная почта (один мешок)                        │
│  ┌───────────────────────────────┐                              │
│  │  • Все письма в одном мешке                                  │
│  │  • Сортируются по приоритету                                 │
│  │  • НО: если мешок застрял — все ждут                         │
│  └───────────────────────────────┘                              │
│                                                                 │
│  HTTP/3 = Дроны Amazon                                          │
│  ┌───────────────────────────────┐                              │
│  │  • Каждая посылка летит отдельно                             │
│  │  • Один дрон сломался — остальные летят                      │
│  │  • Работает при смене адреса доставки                        │
│  └───────────────────────────────┘                              │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

---

### Модель 3: Streams как независимые конверты

```
┌─────────────────────────────────────────────────────────────────┐
│                    STREAMS = КОНВЕРТЫ                           │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  HTTP/1.1 = Один конверт за раз:                                │
│  ┌──────┐                                                       │
│  │Конв.1│ ──────► [обработка] ──────► ответ                     │
│  └──────┘                                                       │
│  ┌──────┐                                                       │
│  │Конв.2│ ──────► [ждёт] ──────► [обработка] ──────► ответ      │
│  └──────┘                                                       │
│                                                                 │
│  HTTP/2 = Много конвертов в одной сумке:                        │
│  ┌──────────────────────┐                                       │
│  │ ┌─┐ ┌─┐ ┌─┐ ┌─┐ ┌─┐ │                                       │
│  │ │1│ │2│ │3│ │4│ │5│ │ ──── TCP ────►                         │
│  │ └─┘ └─┘ └─┘ └─┘ └─┘ │                                       │
│  └──────────────────────┘                                       │
│  Конверты перемешаны, но одна сумка                             │
│  Сумка застряла = все конверты ждут                             │
│                                                                 │
│  HTTP/3 = Конверты летят независимо:                            │
│  ┌─┐                                                            │
│  │1│ ═══════════════════════════►  ✓                            │
│  └─┘                                                            │
│  ┌─┐                                                            │
│  │2│ ═══════════ 💥 ═════════════►  ⏳ только этот ждёт        │
│  └─┘                                                            │
│  ┌─┐                                                            │
│  │3│ ═══════════════════════════►  ✓                            │
│  └─┘                                                            │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

---

### Модель 4: Connection setup как знакомство

```
┌─────────────────────────────────────────────────────────────────┐
│                CONNECTION SETUP = ЗНАКОМСТВО                    │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  TCP (HTTP/1.1, HTTP/2) = Формальное знакомство:                │
│  ────────────────────────────────────────────────               │
│  1. "Привет, можно познакомиться?"     → SYN                    │
│  2. "Конечно, я тоже рад!"            → SYN-ACK                 │
│  3. "Отлично, давай общаться!"        → ACK                     │
│  4. "Кстати, давай шифроваться..."    → TLS ClientHello         │
│  5. "Хорошо, вот мои ключи..."        → TLS ServerHello         │
│  6. "Принято, теперь секретно..."     → TLS Finished            │
│  7. НАКОНЕЦ-ТО: "Дай мне /page.html"  → HTTP Request            │
│                                                                 │
│  Итого: 3 round-trips до первого полезного сообщения            │
│                                                                 │
│  QUIC (HTTP/3) = Быстрое знакомство:                            │
│  ────────────────────────────────────                           │
│  1. "Привет + вот мои ключи + дай /page.html" → QUIC Initial    │
│  2. "Привет + мои ключи + вот /page.html"     → Response        │
│                                                                 │
│  Итого: 1 round-trip! (или 0 для повторного визита)             │
│                                                                 │
│  Повторный визит (0-RTT) = Встреча старых друзей:               │
│  ────────────────────────────────────────────────               │
│  1. "Привет! Вот моя карта, сразу дай /page.html"               │
│  2. "О, узнал тебя! Вот /page.html"                             │
│                                                                 │
│  Итого: 0 round-trips до полезных данных!                       │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

---

### Модель 5: Выбор протокола как выбор транспорта

```
┌─────────────────────────────────────────────────────────────────┐
│                    ВЫБОР ПРОТОКОЛА                              │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  Куда едешь?                 Какой транспорт?                   │
│  ────────────                ─────────────────                  │
│                                                                 │
│  🏢 Корпоративная сеть       → HTTP/2                           │
│     (UDP может блокировать)    TCP надёжен везде                │
│                                                                 │
│  📱 Мобильное приложение     → HTTP/3                           │
│     (WiFi↔4G переключения)     Connection migration             │
│                                                                 │
│  🌍 Глобальный веб-сайт      → HTTP/3 + HTTP/2 fallback         │
│     (разные сети)              Автоматический выбор             │
│                                                                 │
│  🔧 Legacy интеграция        → HTTP/1.1                         │
│     (старые системы)           Максимальная совместимость       │
│                                                                 │
│  ⚡ gRPC микросервисы        → HTTP/2                           │
│     (внутренняя сеть)          gRPC требует HTTP/2              │
│                                                                 │
│  🎮 Игровой сервер           → HTTP/3 или UDP напрямую          │
│     (latency критична)         Минимальные задержки             │
│                                                                 │
│  📺 Стриминг видео           → HTTP/3                           │
│     (высокие потери)           Per-stream recovery              │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘

DECISION FLOWCHART:

       Нужна максимальная совместимость?
                    │
              ┌─────┴─────┐
              Да         Нет
              │           │
         HTTP/1.1    UDP блокируется?
                          │
                    ┌─────┴─────┐
                    Да         Нет
                    │           │
                 HTTP/2    Мобильные пользователи?
                                │
                          ┌─────┴─────┐
                          Да         Нет
                          │           │
                       HTTP/3    HTTP/2 или HTTP/3
                                 (зависит от нагрузки)
```

---

## ПОЧЕМУ: История и проблемы

### Краткая история HTTP

**HTTP/0.9 (1991)** - первая версия, один метод GET, только HTML

**HTTP/1.0 (1996, RFC 1945)** - новое соединение для каждого запроса
- Проблема: огромные накладные расходы на установку TCP соединения
- Latency убивает производительность

**HTTP/1.1 (1997, RFC 2068)** - persistent connections, pipelining
- Проблема: HOL blocking в pipelining
- Проблема: один запрос за раз на соединение (в реальности)
- Workaround: браузеры открывают 6-8 параллельных соединений

**HTTP/2 (2015, RFC 7540)** - multiplexing, binary protocol
- Проблема: TCP-level HOL blocking
- Проблема: connection setup latency (TCP + TLS = 2-3 RTT)

**HTTP/3 (2022, RFC 9114)** - QUIC over UDP
- Решает: все проблемы предыдущих версий
- Проблема: новые вызовы для сетевой инфраструктуры

### Какие проблемы решает каждая версия

#### HTTP/1.0 → HTTP/1.1: Connection Reuse
```
HTTP/1.0 (проблема):
Request 1: TCP handshake (1 RTT) → Request → Response → Close
Request 2: TCP handshake (1 RTT) → Request → Response → Close
Request 3: TCP handshake (1 RTT) → Request → Response → Close

HTTP/1.1 (решение):
TCP handshake (1 RTT) → Request 1 → Response 1 → Request 2 → Response 2 → Request 3 → Response 3
Connection: keep-alive
```

**Выигрыш**: Экономия на установке TCP соединения (3-way handshake)

#### HTTP/1.1 → HTTP/2: Multiplexing
```
HTTP/1.1 (проблема - HOL blocking):
Connection 1: [====HTML====][==CSS==][==JS==]
Connection 2: [==IMG1==][==IMG2==]
Connection 3: [==IMG3==][==IMG4==]

Если HTML большой - CSS и JS ждут
Решение: открыть больше соединений (но TCP slow start на каждом)

HTTP/2 (решение - multiplexing):
Single Connection:
Stream 1: [=HTML=]    [=HTML=]    [=HTML=]
Stream 2:      [=CSS=]    [=CSS=]
Stream 3:           [=JS=]     [=JS=]
Stream 4:      [IMG1]
Stream 5:                [IMG2]
```

**Выигрыш**:
- Один TCP connection → один TCP slow start
- Нет искусственного лимита на параллельные запросы
- Header compression (HPACK) - экономия трафика

#### HTTP/2 → HTTP/3: Solving TCP HOL Blocking
```
HTTP/2 (проблема - TCP HOL blocking):
TCP Connection: [Stream1][Stream2][Stream3-LOST][Stream4]
                                   ⬆ потерян пакет
Все потоки ждут ретрансмита Stream3, даже если их данные уже пришли!

HTTP/3 + QUIC (решение):
QUIC Connection (over UDP):
Stream 1: [✓][✓][✓]           → delivered
Stream 2: [✓][✓][✓]           → delivered
Stream 3: [✓][✗][pending]     → только Stream 3 ждёт ретрансмита
Stream 4: [✓][✓][✓]           → delivered
```

**Выигрыш**:
- Потеря пакета влияет только на один stream
- 0-RTT connection resumption (0 задержек при повторном подключении)
- Connection migration (смена IP без разрыва соединения)

### Современное состояние (2025)

По данным W3Techs на декабрь 2025:
- **HTTP/3**: ~31-34% сайтов в топ-10 миллионов
- **Браузеры**: 95%+ современных браузеров поддерживают HTTP/3
- **Трафик**: 30%+ глобального веб-трафика использует HTTP/3
- **Major players**: Google, Facebook, YouTube, Cloudflare, Akamai активно используют HTTP/3

---

## ЧТО: Эволюция протокола

### Сравнительная таблица версий HTTP

| Характеристика | HTTP/1.0 | HTTP/1.1 | HTTP/2 | HTTP/3 |
|----------------|----------|----------|---------|---------|
| **RFC** | 1945 (1996) | 2616 (1999) → 7230-7235 (2014) | 7540 (2015) | 9114 (2022) |
| **Transport** | TCP | TCP | TCP | QUIC (UDP) |
| **Connections** | Новое на каждый запрос | Persistent (keep-alive) | Multiplexed | Multiplexed |
| **Формат** | Текст | Текст | Binary frames | Binary frames |
| **Multiplexing** | Нет | Нет (pipeline не работает) | Да | Да |
| **Header Compression** | Нет | Нет | HPACK | QPACK |
| **Server Push** | Нет | Нет | Да | Да (улучшен) |
| **Prioritization** | Нет | Нет | Stream priority | Stream priority |
| **HOL Blocking** | Да (application) | Да (application) | Нет (application), Да (TCP) | Нет |
| **Connection Setup** | 1 RTT (TCP) | 1 RTT (TCP) | 2-3 RTT (TCP+TLS) | 0-1 RTT (QUIC) |
| **TLS** | Опционально | Опционально | Обязательно (de facto) | Обязательно (встроено) |
| **Connection Migration** | Нет | Нет | Нет | Да |
| **Потери пакетов** | Блокирует connection | Блокирует connection | Блокирует все streams | Блокирует только stream |

### HTTP/1.0 и HTTP/1.1

#### Основные возможности HTTP/1.1

**Persistent Connections (Keep-Alive)**
```http
# HTTP/1.0 - нужно явно запросить
Connection: keep-alive

# HTTP/1.1 - по умолчанию
Connection: keep-alive  # default behaviour
Connection: close       # явно закрыть
```

**Chunked Transfer Encoding**
```http
HTTP/1.1 200 OK
Transfer-Encoding: chunked

5
Hello
6
 World
0
```
Позволяет отправлять данные без знания полного размера заранее.

**Host Header (Virtual Hosting)**
```http
GET /index.html HTTP/1.1
Host: example.com
```
Один IP-адрес → множество сайтов.

**Range Requests (Resume Downloads)**
```http
GET /large-file.zip HTTP/1.1
Range: bytes=1000-1999

HTTP/1.1 206 Partial Content
Content-Range: bytes 1000-1999/5000
Content-Length: 1000
```

**Caching Improvements**
```http
# HTTP/1.0
Expires: Wed, 21 Oct 2025 07:28:00 GMT

# HTTP/1.1 (более мощный)
Cache-Control: max-age=3600, must-revalidate
ETag: "33a64df551425fcc55e4d42a148795d9"
If-None-Match: "33a64df551425fcc55e4d42a148795d9"
```

#### Проблемы HTTP/1.1

**HOL Blocking в Pipelining**
```http
# Клиент отправляет несколько запросов подряд:
GET /style.css
GET /script.js
GET /image.png

# Сервер ДОЛЖЕН отвечать в том же порядке:
Response: style.css (медленный, 10 секунд)
Response: script.js (ждёт, хотя готов через 1 секунду)
Response: image.png (ждёт)
```
**Результат**: Pipelining не используется браузерами в production.

**Workaround: Domain Sharding**
```
static1.example.com  ←┐
static2.example.com  ├─ 6-8 connections per domain
static3.example.com  ├─ хак для обхода лимита браузера
static4.example.com  ┘

Минусы:
- DNS lookup для каждого домена
- TCP slow start для каждого connection
- Увеличенное потребление ресурсов
```

### HTTP/2: Binary Framing Layer

#### Архитектура HTTP/2

```
Application Layer:
┌─────────────────────────────────────────┐
│ Request/Response (as in HTTP/1.1)       │
└─────────────────────────────────────────┘
            ↓
Binary Framing Layer (NEW):
┌─────────────────────────────────────────┐
│ Streams, Frames, Multiplexing           │
│ Stream 1  Stream 3  Stream 5            │
│   ↓         ↓         ↓                 │
│ [Frame][Frame][Frame][Frame][Frame]     │
└─────────────────────────────────────────┘
            ↓
TCP/TLS Layer:
┌─────────────────────────────────────────┐
│ Single TCP Connection                   │
└─────────────────────────────────────────┘
```

#### Frame Types

HTTP/2 определяет несколько типов фреймов:

| Frame Type | Code | Описание |
|------------|------|----------|
| **DATA** | 0x0 | Содержит payload запроса/ответа |
| **HEADERS** | 0x1 | HTTP headers (compressed) |
| **PRIORITY** | 0x2 | Приоритет stream |
| **RST_STREAM** | 0x3 | Немедленная остановка stream |
| **SETTINGS** | 0x4 | Параметры соединения |
| **PUSH_PROMISE** | 0x5 | Уведомление о server push |
| **PING** | 0x6 | Проверка соединения и RTT |
| **GOAWAY** | 0x7 | Graceful shutdown соединения |
| **WINDOW_UPDATE** | 0x8 | Flow control |
| **CONTINUATION** | 0x9 | Продолжение HEADERS |

#### Multiplexing в действии

```
Request 1 (HTML, Priority: High):     [H1][D1-1][D1-2][D1-3]
Request 2 (CSS, Priority: High):      [H2][D2-1][D2-2]
Request 3 (Image, Priority: Low):     [H3][D3-1][D3-2]
Request 4 (JS, Priority: Medium):     [H4][D4-1]

TCP Connection: [H1][H2][D1-1][D2-1][H3][D1-2][D2-2][H4][D1-3][D4-1][D3-1][D3-2]
                 ↑   ↑   ↑                                    ↑
                 Frames перемешиваются по приоритету и flow control
```

**Streams** - независимые логические каналы
- Stream ID - нечётные для клиента (1, 3, 5), чётные для сервера (2, 4, 6)
- Streams могут быть закрыты независимо
- Поддержка приоритизации

#### HPACK Header Compression

**Проблема**: Headers повторяются в каждом запросе
```http
GET /page1 HTTP/1.1
Host: example.com
User-Agent: Mozilla/5.0...
Accept: text/html,application/xhtml+xml...
Accept-Language: en-US,en;q=0.9
Cookie: session=abc123...

GET /page2 HTTP/1.1
Host: example.com                          ← дубликат
User-Agent: Mozilla/5.0...                 ← дубликат
Accept: text/html,application/xhtml+xml... ← дубликат
Accept-Language: en-US,en;q=0.9            ← дубликат
Cookie: session=abc123...                  ← дубликат
```

**HPACK решение**:
1. **Static Table** - предопределённые часто используемые headers
2. **Dynamic Table** - накапливаются headers в рамках соединения
3. **Huffman Encoding** - сжатие значений

```
Request 1:
:method: GET           → index 2 (static table)
:path: /page1          → literal, добавить в dynamic table index 62
host: example.com      → literal, добавить в dynamic table index 63
user-agent: Mozilla... → literal, добавить в dynamic table index 64

Request 2:
:method: GET           → index 2
:path: /page2          → literal (новое значение)
host: example.com      → index 63 (из dynamic table)
user-agent: Mozilla... → index 64 (из dynamic table)

Экономия: ~30-50% размера headers
```

#### Server Push

Сервер проактивно отправляет ресурсы:
```
Client → Server: GET /index.html

Server → Client:
  PUSH_PROMISE (stream 2): /style.css
  PUSH_PROMISE (stream 4): /script.js

Server → Client (stream 1):
  <html>
    <link rel="stylesheet" href="/style.css">
    <script src="/script.js">
  </html>

Server → Client (stream 2): [style.css content]
Server → Client (stream 4): [script.js content]

Client: Парсит HTML и видит, что style.css и script.js уже в кеше!
```

**Преимущества**:
- Устранение round-trip для критических ресурсов
- Faster page load

**Недостатки** (почему мало используется):
- Сложность определения что push'ить
- Риск отправки ненужных ресурсов (если есть в кеше)
- HTTP/3 улучшает механизм

### HTTP/3 и QUIC: Революция транспортного уровня

#### Почему UDP?

**Проблемы TCP**:
1. **Ossification** - TCP встроен в kernel, middleware, NAT'ы - невозможно обновить
2. **HOL Blocking** - потеря одного TCP segment блокирует все данные
3. **Connection Setup** - TCP handshake + TLS handshake = 2-3 RTT
4. **Connection Migration** - смена IP = разрыв соединения

**Почему UDP идеален для QUIC**:
```
UDP - минимальный протокол:
- Только port numbers и checksum
- Нет гарантий доставки
- Нет упорядочивания
- НО: проходит через любые firewalls, NAT, middleboxes

QUIC реализует всё необходимое В user space:
- Reliable delivery
- Ordering (per-stream)
- Congestion control
- Flow control
- Encryption (TLS 1.3 встроен)
```

**Преимущество**: QUIC можно обновлять без изменения ОС/hardware.

#### Архитектура QUIC

```
┌─────────────────────────────────────────────┐
│         HTTP/3 (Application Layer)           │
│  Requests, Responses, Server Push            │
└─────────────────────────────────────────────┘
                   ↓
┌─────────────────────────────────────────────┐
│            QPACK (Header Compression)        │
└─────────────────────────────────────────────┘
                   ↓
┌─────────────────────────────────────────────┐
│                QUIC Transport                │
│  ┌────────────┬──────────────┬────────────┐ │
│  │ Streams    │ Encryption   │ Loss       │ │
│  │ Multiplex  │ (TLS 1.3)    │ Recovery   │ │
│  └────────────┴──────────────┴────────────┘ │
│  ┌────────────┬──────────────────────────┐  │
│  │ Flow       │ Congestion               │  │
│  │ Control    │ Control                  │  │
│  └────────────┴──────────────────────────┘  │
└─────────────────────────────────────────────┘
                   ↓
┌─────────────────────────────────────────────┐
│            UDP (Transport Layer)             │
│  Простая доставка пакетов, нет гарантий     │
└─────────────────────────────────────────────┘
```

#### Key Features QUIC

**1. Connection ID вместо 4-tuple**

```
TCP connection идентифицируется:
(Source IP, Source Port, Dest IP, Dest Port)
Смена IP = новое соединение

QUIC connection идентифицируется:
Connection ID (64-bit random value)
Смена IP = тот же Connection ID = соединение сохраняется!

Use case: Mobile
Wi-Fi (IP: 192.168.1.5) → 4G (IP: 10.0.0.123)
QUIC: Connection ID 0x123456789abcdef остаётся, нет разрыва
```

**2. 0-RTT Connection Resumption**

```
First Connection (1-RTT):
Client → Server: Client Hello (with crypto handshake)
Client ← Server: Server Hello, Certificate, Finished
Client → Server: Finished + Application Data (FIRST REQUEST HERE!)
         ↑ 1 RTT для connection + первый запрос

Subsequent Connections (0-RTT):
Client → Server: 0-RTT Application Data (immediate request!)
         ↑ 0 RTT - запрос отправлен сразу с использованием session ticket

Server → Client: Response
```

**Ограничения 0-RTT**:
- Данные не idempotent-safe (replay attacks возможны)
- Только для GET requests без side effects
- POST, PUT, DELETE требуют 1-RTT

**3. Per-Stream Loss Recovery**

```
TCP (HTTP/2) - все streams блокируются:
┌───────────────────────────────────┐
│ TCP Buffer:                       │
│ [Stream 1][Stream 2-LOST][Stream 3]│
│           ↑ потерян TCP segment   │
│                                   │
│ Stream 1: ждёт Stream 2           │
│ Stream 3: ждёт Stream 2           │
└───────────────────────────────────┘

QUIC - только Stream 2 блокируется:
┌───────────────────────────────────┐
│ QUIC Streams (independent):       │
│ Stream 1: [✓][✓][✓] → delivered  │
│ Stream 2: [✓][✗] → wait retrans  │
│ Stream 3: [✓][✓][✓] → delivered  │
└───────────────────────────────────┘
```

**4. Built-in Encryption**

```
TCP + TLS:
TCP Handshake:  SYN → SYN-ACK → ACK        (1 RTT)
TLS Handshake:  ClientHello → ServerHello  (1-2 RTT)
Application:    HTTP Request → Response
Total: 2-3 RTT до первого байта данных

QUIC:
Combined:       QUIC Initial (crypto + handshake) (1 RTT)
Application:    HTTP Request → Response
Total: 1 RTT до первого байта данных (0-RTT при resumption)
```

**Encryption всегда**:
- TLS 1.3 встроен в QUIC
- Нет возможности использовать plain text
- Headers и payload зашифрованы

#### QPACK vs HPACK

**HPACK проблема с QUIC**:
```
HPACK требует упорядоченную доставку:
Stream 1: Header "x-custom: value1" → dynamic table[62]
Stream 2: Reference to dynamic table[62] → должен ждать Stream 1!

Если Stream 1 delayed - Stream 2 не может декодировать headers
```

**QPACK решение**:
```
QPACK использует отдельные streams для dynamic table:
- Encoder Stream (unidirectional)
- Decoder Stream (unidirectional)

Stream 1, 2, 3 могут использовать dynamic table без ожидания друг друга
Blocking только если dynamic table не синхронизирована (редко)
```

**Result**: Header compression без HOL blocking.

---

## КАК: Практическая реализация

### HTTP/1.1 Headers Examples

#### Request Headers

```http
GET /api/users/123 HTTP/1.1
Host: api.example.com
User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36
Accept: application/json, text/plain, */*
Accept-Language: en-US,en;q=0.9,ru;q=0.8
Accept-Encoding: gzip, deflate, br
Connection: keep-alive
Cache-Control: no-cache
Pragma: no-cache
Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...
Cookie: session_id=abc123def456; user_pref=dark_mode
If-None-Match: "33a64df551425fcc55e4d42a148795d9"
If-Modified-Since: Wed, 21 Oct 2025 07:28:00 GMT
```

#### Response Headers

```http
HTTP/1.1 200 OK
Date: Thu, 18 Dec 2025 10:30:00 GMT
Server: nginx/1.24.0
Content-Type: application/json; charset=utf-8
Content-Length: 1234
Content-Encoding: gzip
Cache-Control: public, max-age=3600
ETag: "33a64df551425fcc55e4d42a148795d9"
Last-Modified: Wed, 21 Oct 2025 07:28:00 GMT
Vary: Accept-Encoding, Accept-Language
Strict-Transport-Security: max-age=31536000; includeSubDomains; preload
X-Content-Type-Options: nosniff
X-Frame-Options: DENY
X-XSS-Protection: 1; mode=block
Access-Control-Allow-Origin: https://example.com
Access-Control-Allow-Credentials: true
Set-Cookie: session_id=xyz789; HttpOnly; Secure; SameSite=Strict; Max-Age=3600

{"user_id": 123, "name": "John Doe", "email": "john@example.com"}
```

#### Conditional Requests

```http
# Первый запрос
GET /api/data HTTP/1.1
Host: api.example.com

HTTP/1.1 200 OK
ETag: "v1.2.3"
Last-Modified: Wed, 18 Dec 2025 09:00:00 GMT
Cache-Control: max-age=60

{"data": "..."}

# Повторный запрос (через 70 секунд, cache expired)
GET /api/data HTTP/1.1
Host: api.example.com
If-None-Match: "v1.2.3"
If-Modified-Since: Wed, 18 Dec 2025 09:00:00 GMT

HTTP/1.1 304 Not Modified
ETag: "v1.2.3"
Cache-Control: max-age=60
# Нет body - экономия трафика!
```

#### Range Requests (для resume downloads)

```http
# Скачать первые 1000 байт
GET /large-video.mp4 HTTP/1.1
Host: cdn.example.com
Range: bytes=0-999

HTTP/1.1 206 Partial Content
Content-Type: video/mp4
Content-Range: bytes 0-999/1048576
Content-Length: 1000

[1000 bytes of data]

# Соединение оборвалось, resume с 1000 байта
GET /large-video.mp4 HTTP/1.1
Host: cdn.example.com
Range: bytes=1000-

HTTP/1.1 206 Partial Content
Content-Type: video/mp4
Content-Range: bytes 1000-1048575/1048576
Content-Length: 1047576

[remaining bytes]
```

### HTTP/2 Multiplexing Examples

#### Curl с HTTP/2

```bash
# Проверить поддержку HTTP/2
curl -I --http2 https://www.google.com

# Verbose mode для просмотра streams
curl -v --http2 https://www.cloudflare.com

# Пример вывода:
# * Using HTTP2, server supports multi-use
# * Connection state changed (HTTP/2 confirmed)
# * Copying HTTP/2 data in stream buffer to connection buffer after upgrade: len=0
# * Using Stream ID: 1 (easy handle 0x...)
# > GET / HTTP/2
# > Host: www.cloudflare.com
# > user-agent: curl/7.81.0
# > accept: */*
#
# < HTTP/2 200
# < date: Thu, 18 Dec 2025 10:30:00 GMT
# < content-type: text/html; charset=utf-8
```

#### Node.js HTTP/2 Server

```javascript
const http2 = require('http2');
const fs = require('fs');

const server = http2.createSecureServer({
  key: fs.readFileSync('server-key.pem'),
  cert: fs.readFileSync('server-cert.pem')
});

server.on('stream', (stream, headers) => {
  console.log(`Stream ${stream.id}: ${headers[':method']} ${headers[':path']}`);

  // Отправка response
  stream.respond({
    ':status': 200,
    'content-type': 'application/json'
  });

  stream.end(JSON.stringify({ message: 'Hello HTTP/2!' }));
});

// Server Push пример
server.on('stream', (stream, headers) => {
  if (headers[':path'] === '/') {
    // Push CSS before client requests it
    stream.pushStream({ ':path': '/style.css' }, (err, pushStream) => {
      if (err) throw err;

      pushStream.respond({
        ':status': 200,
        'content-type': 'text/css'
      });

      pushStream.end('body { color: blue; }');
    });

    // Send HTML
    stream.respond({
      ':status': 200,
      'content-type': 'text/html'
    });

    stream.end('<html><link rel="stylesheet" href="/style.css"></html>');
  }
});

server.listen(8443);
```

#### Node.js HTTP/2 Client

```javascript
const http2 = require('http2');

const client = http2.connect('https://localhost:8443', {
  rejectUnauthorized: false
});

// Создать несколько streams одновременно
const requests = ['/api/users', '/api/posts', '/api/comments'];

requests.forEach(path => {
  const req = client.request({
    ':path': path,
    ':method': 'GET'
  });

  req.on('response', (headers) => {
    console.log(`Response for ${path}:`, headers[':status']);
  });

  req.setEncoding('utf8');
  let data = '';

  req.on('data', (chunk) => { data += chunk; });
  req.on('end', () => {
    console.log(`Data for ${path}:`, data);
  });

  req.end();
});

// Обработка Server Push
client.on('stream', (pushedStream, headers) => {
  console.log('Server pushed:', headers[':path']);

  pushedStream.on('data', (chunk) => {
    console.log('Pushed data:', chunk.toString());
  });
});
```

#### Nginx HTTP/2 Configuration

```nginx
server {
    listen 443 ssl http2;
    server_name example.com;

    ssl_certificate /path/to/cert.pem;
    ssl_certificate_key /path/to/key.pem;

    # HTTP/2 specific settings
    http2_max_field_size 16k;
    http2_max_header_size 32k;
    http2_max_requests 1000;
    http2_max_concurrent_streams 128;

    # Server Push
    location = /index.html {
        http2_push /style.css;
        http2_push /script.js;
        http2_push /logo.png;
    }

    # Остальная конфигурация
    location / {
        root /var/www/html;
        index index.html;
    }
}
```

### HTTP/3 and QUIC Examples

#### Проверка HTTP/3 поддержки

```bash
# Curl с HTTP/3 (нужна версия с QUIC support)
curl --http3 https://www.cloudflare.com -I

# Пример вывода:
# HTTP/3 200
# date: Thu, 18 Dec 2025 10:30:00 GMT
# content-type: text/html
# alt-svc: h3=":443"; ma=86400

# Chrome DevTools
# Network tab → Protocol column → показывает "h3" для HTTP/3
```

#### Alt-Svc Header (HTTP/3 Discovery)

```http
# Клиент делает HTTP/2 запрос:
GET / HTTP/2
Host: example.com

# Сервер отвечает с Alt-Svc header:
HTTP/2 200 OK
Alt-Svc: h3=":443"; ma=86400
Content-Type: text/html

# Браузер запоминает: example.com поддерживает HTTP/3 на порту 443
# Следующие запросы будут использовать HTTP/3 (QUIC over UDP)

# ma=86400 - max age в секундах (24 часа)
```

#### Nginx HTTP/3 Configuration

```nginx
# Требуется Nginx 1.25.0+ с QUIC support
server {
    # HTTP/3 over QUIC
    listen 443 quic reuseport;

    # HTTP/2 fallback
    listen 443 ssl http2;

    server_name example.com;

    ssl_certificate /path/to/cert.pem;
    ssl_certificate_key /path/to/key.pem;

    # TLS 1.3 для QUIC (обязательно)
    ssl_protocols TLSv1.3;

    # Advertise HTTP/3 availability
    add_header Alt-Svc 'h3=":443"; ma=86400';

    # QUIC-specific settings
    quic_retry on;
    quic_gso on;

    location / {
        root /var/www/html;
    }
}
```

#### Cloudflare Workers HTTP/3

```javascript
// Cloudflare automatically handles HTTP/3
// Request object показывает версию протокола

addEventListener('fetch', event => {
  event.respondWith(handleRequest(event.request))
})

async function handleRequest(request) {
  // Получить версию HTTP
  const httpVersion = request.cf?.httpProtocol || 'unknown'

  // httpVersion может быть: "HTTP/1.0", "HTTP/1.1", "HTTP/2", "HTTP/3"

  return new Response(JSON.stringify({
    protocol: httpVersion,
    url: request.url,
    headers: Object.fromEntries(request.headers)
  }), {
    headers: {
      'Content-Type': 'application/json',
      // Cloudflare автоматически добавляет Alt-Svc для HTTP/3
    }
  })
}
```

#### Go HTTP/3 Server (quic-go)

```go
package main

import (
    "fmt"
    "log"
    "net/http"

    "github.com/quic-go/quic-go/http3"
)

func main() {
    mux := http.NewServeMux()

    mux.HandleFunc("/", func(w http.ResponseWriter, r *http.Request) {
        fmt.Fprintf(w, "Hello from HTTP/3! Protocol: %s\n", r.Proto)
    })

    // HTTP/3 Server
    server := http3.Server{
        Addr:    ":443",
        Handler: mux,
    }

    log.Println("Starting HTTP/3 server on :443")
    err := server.ListenAndServeTLS("cert.pem", "key.pem")
    if err != nil {
        log.Fatal(err)
    }
}
```

#### Go HTTP/3 Client

```go
package main

import (
    "crypto/tls"
    "fmt"
    "io"
    "log"
    "net/http"

    "github.com/quic-go/quic-go/http3"
)

func main() {
    // HTTP/3 RoundTripper
    roundTripper := &http3.RoundTripper{
        TLSClientConfig: &tls.Config{
            InsecureSkipVerify: true, // только для тестирования!
        },
    }
    defer roundTripper.Close()

    client := &http.Client{
        Transport: roundTripper,
    }

    // Множественные параллельные запросы (multiplexing)
    urls := []string{
        "https://localhost:443/api/users",
        "https://localhost:443/api/posts",
        "https://localhost:443/api/comments",
    }

    for _, url := range urls {
        go func(u string) {
            resp, err := client.Get(u)
            if err != nil {
                log.Printf("Error fetching %s: %v", u, err)
                return
            }
            defer resp.Body.Close()

            body, _ := io.ReadAll(resp.Body)
            fmt.Printf("Response from %s (Protocol: %s):\n%s\n\n",
                u, resp.Proto, body)
        }(url)
    }

    // Ждём завершения
    select {}
}
```

### Performance Testing

#### Apache Bench (HTTP/1.1)

```bash
# 1000 requests, 10 concurrent connections
ab -n 1000 -c 10 https://example.com/

# Results:
# Requests per second:    150.23 [#/sec] (mean)
# Time per request:       66.566 [ms] (mean)
# Connection Times (ms)
#               min  mean[+/-sd] median   max
# Connect:       10   15   3.2     14      45
# Processing:    30   50  12.5     48     120
# Waiting:       28   48  12.1     46     118
# Total:         40   65  13.8     62     145
```

#### h2load (HTTP/2)

```bash
# Инструмент от nghttp2 для тестирования HTTP/2
h2load -n 1000 -c 10 https://example.com/

# Results:
# finished in 4.50s, 222.22 req/s, 1.8MB/s
# requests: 1000 total, 1000 started, 1000 done, 1000 succeeded
# traffic: 8.1MB (8500000) total, 500KB (512000) headers
#
# min         max         mean         sd        +/- sd
# time for request:   10ms       150ms       45ms      12ms    68.5%
```

#### Real-world performance improvements

**Case Study: E-commerce site (2025)**

```
Migration: HTTP/1.1 → HTTP/2
Page load time: 3.2s → 1.9s (40% faster)
Time to Interactive: 4.5s → 2.7s (40% faster)
Number of connections: 48 → 1 (98% reduction)

Migration: HTTP/2 → HTTP/3
Page load time: 1.9s → 1.6s (16% faster)
Time to first byte: 180ms → 80ms (55% faster on mobile)
Packet loss resilience: significantly better (no connection stall)
Mobile performance: 2.1s → 1.4s (33% faster)
```

### Developer Tools

#### Chrome DevTools

```
1. Open DevTools (F12)
2. Network tab
3. Right-click columns → add "Protocol" column
4. Reload page

Protocol values:
- "http/1.1" - HTTP/1.1
- "h2" - HTTP/2
- "h3" or "http/3" - HTTP/3

Timing breakdown:
- Queueing: ожидание доступного соединения
- Stalled: ожидание в очереди (HOL blocking в HTTP/1.1)
- DNS Lookup: разрешение DNS
- Initial connection: TCP handshake
- SSL: TLS handshake
- Request sent: отправка запроса
- Waiting (TTFB): время до первого байта
- Content Download: загрузка контента

HTTP/2: Initial connection + SSL происходит один раз
HTTP/3: Initial connection + SSL быстрее (1 RTT или 0-RTT)
```

#### Firefox Developer Tools

```
Network Monitor → Headers → HTTP Version
- "HTTP/1.1"
- "HTTP/2"
- "HTTP/3"

Waterfall показывает:
- Зелёная линия: waiting time
- Синяя линия: content download
- HTTP/2: меньше gaps, больше параллелизма
- HTTP/3: меньше initial latency
```

---

## Подводные камни

### HTTP/1.1 Issues

#### 1. Connection Limits

```
Проблема:
Браузеры ограничивают connections per domain (обычно 6-8)

Симптомы:
- Ресурсы загружаются последовательно группами
- Long waterfalls в DevTools
- Stalled time в тайминге

Workarounds (не рекомендуются для HTTP/2+):
- Domain sharding: static1.example.com, static2.example.com
- Inline критические ресурсы (CSS, small JS)
- Использовать sprites для изображений

Правильное решение:
Migrate to HTTP/2 или HTTP/3
```

#### 2. Header Overhead

```
Каждый request отправляет полные headers:
Request: 800 bytes headers + 0 bytes body (для GET)
Response: 600 bytes headers + 1000 bytes body

100 requests:
Headers overhead: 100 * (800 + 600) = 140KB
Actual data: 100 * 1000 = 100KB

Headers > Data!

Solution: HTTP/2 HPACK сжимает headers на 30-50%
```

#### 3. No Prioritization

```
Все requests имеют одинаковый priority:
- Critical CSS блокируется некритичными images
- JavaScript блокируется fonts
- Above-the-fold content ждёт below-the-fold

Workaround:
<link rel="preload" href="critical.css" as="style">
<link rel="preload" href="critical.js" as="script">

Better solution: HTTP/2 stream priorities
```

### HTTP/2 Pitfalls

#### 1. TCP Head-of-Line Blocking (главная проблема!)

```
Scenario:
Stream 1: [packet1][packet2][packet3][packet4]
Stream 2: [packet1-LOST][packet2][packet3]
Stream 3: [packet1][packet2]

TCP видит: [...][...][LOST][...][...][...][...][...]

TCP behaviour:
1. Обнаруживает потерю пакета
2. Буферизует ВСЕ последующие пакеты
3. Ждёт ретрансмита потерянного пакета
4. Только после получения - отдаёт в application layer

Result: Все streams (1, 2, 3) блокируются, хотя проблема только в Stream 2!

Impact:
На стабильных сетях (Ethernet, fiber): минимальный
На нестабильных (Wi-Fi, 4G, lossy networks): критический

Real numbers:
1% packet loss: HTTP/2 может быть медленнее HTTP/1.1!
5% packet loss: HTTP/2 значительно медленнее

Solution: HTTP/3 with QUIC - per-stream loss recovery
```

#### 2. Server Push Может Навредить

```
Проблема 1: Cache invalidation
Server push: /style.css (200 OK, 50KB)
Client: У меня уже есть /style.css в cache!
Result: 50KB потрачено впустую

Проблема 2: Bandwidth waste
Server push: 10 resources (500KB total)
Client: На медленном 3G, нужен только HTML
Result: 500KB блокируют критический content

Проблема 3: Browser limits
Browsers ограничивают pushed resources
Chrome: max 1000 pushed resources per page
Превышение = reject push

Best practices:
1. Push только критические ресурсы (CSS, small JS)
2. Используйте Cache-Digest header (draft RFC)
3. Monitor push acceptance rate
4. Consider 103 Early Hints вместо push

Statistics (2025):
- <5% сайтов используют server push
- Большинство отключили из-за проблем с cache
- HTTP/3 улучшает механизм
```

#### 3. Connection Coalescing Issues

```
HTTP/2 позволяет coalescing connections:
request to a.example.com + b.example.com → same connection
если они указывают на тот же IP и имеют валидный wildcard cert

Проблема:
cdn1.example.com → 1.2.3.4
cdn2.example.com → 1.2.3.4
Certificate: *.example.com

Браузер coalesces → один connection

Если cdn1 slow → весь traffic slow (HOL blocking at TCP level)

Solution:
- Используйте разные IP для разных CDN endpoints
- Или используйте HTTP/3 (per-stream recovery)
```

#### 4. Reverse Proxy Configuration

```
Common mistake:
Client → HTTP/2 → Nginx → HTTP/1.1 → Backend

Nginx конвертирует HTTP/2 streams в последовательные HTTP/1.1 requests!

Result:
- Теряется multiplexing benefit
- Backend видит serial requests
- Bottleneck на Nginx ↔ Backend link

Solution:
Client → HTTP/2 → Nginx → HTTP/2 → Backend
или
Client → HTTP/2 → Nginx → gRPC (HTTP/2-based) → Backend

Nginx config:
upstream backend {
    server backend.example.com:443;
}

server {
    listen 443 ssl http2;

    location / {
        # Включить HTTP/2 upstream
        proxy_pass https://backend;
        proxy_http_version 2.0;  # ← важно!
    }
}
```

#### 5. Debugging Complexity

```
HTTP/1.1 debugging:
tcpdump -A port 80  # читаемый текст

HTTP/2 debugging:
tcpdump port 443  # бинарные зашифрованные фреймы
нужны специальные инструменты:
- Wireshark с TLS key logging
- Chrome DevTools (Protocol: h2)
- nghttp2 trace tools

TLS key logging (для development):
export SSLKEYLOGFILE=/tmp/sslkeys.log
chrome --ssl-key-log-file=/tmp/sslkeys.log
wireshark → preferences → TLS → Pre-Master-Secret log
```

### HTTP/3 and QUIC Challenges

#### 1. UDP Blocking

```
Проблема:
Многие enterprise firewalls/NAT блокируют UDP:
- "UDP = опасно" (старое мышление)
- "UDP = только DNS и VoIP"
- QUIC на порту 443 UDP может быть заблокирован

Statistics (2025):
~5-10% users не могут использовать QUIC из-за network blocks

Symptoms:
- Alt-Svc header получен
- Browser пытается HTTP/3
- Timeout
- Fallback to HTTP/2

Solution:
1. Всегда поддерживать HTTP/2 fallback
2. Быстрый fallback (timeout 1-3 seconds)
3. Retry HTTP/3 периодически

Nginx config:
listen 443 quic reuseport;
listen 443 ssl http2;  # fallback

Client behaviour:
1. Try HTTP/3 (QUIC over UDP)
2. If timeout → fallback to HTTP/2 (TCP)
3. Remember failure for this network
4. Retry HTTP/3 on network change
```

#### 2. NAT Rebinding

```
Проблема:
UDP packets могут менять NAT binding:
Client (192.168.1.5:54321) → NAT (203.0.113.1:12345) → Server

NAT timeout (обычно 30-120 секунд для UDP):
NAT closes binding 203.0.113.1:12345

Client отправляет packet:
Client → NAT (новый порт: 203.0.113.1:54321) → Server

Server видит новый source port → не может match Connection ID!

QUIC Solution:
- Connection ID независим от 4-tuple
- PATH_CHALLENGE / PATH_RESPONSE frames
- Connection migration protocol

Client:
1. Обнаруживает новый path
2. Отправляет PATH_CHALLENGE
3. Получает PATH_RESPONSE
4. Продолжает использовать тот же Connection ID
```

#### 3. CPU Overhead

```
QUIC требует больше CPU чем TCP+TLS:

Причины:
1. User-space implementation (не kernel)
2. Crypto operations per packet
3. Loss recovery logic
4. Congestion control в user space

Benchmarks:
TCP+TLS: 10 Gbps на 1 CPU core
QUIC: 5-7 Gbps на 1 CPU core

Impact:
- High-traffic servers нужно больше CPU
- Cloud costs могут увеличиться

Mitigations:
1. Hardware offload (NIC поддержка QUIC появляется)
2. eBPF acceleration
3. Kernel QUIC implementations (в разработке)
4. GSO/GRO optimizations

Future:
Kernel QUIC implementations появятся в 2025-2026
Expected: 90% performance of kernel TCP
```

#### 4. 0-RTT Replay Attacks

```
Проблема:
0-RTT data отправляется БЕЗ криптографического подтверждения
Attacker может перехватить и replay packet

Scenario:
Client → Server: 0-RTT request "DELETE /user/123"
Attacker перехватывает packet
Attacker → Server: replay packet 100 раз
Result: 100 DELETE requests executed!

Protection:
1. Server ДОЛЖЕН отклонять non-idempotent operations в 0-RTT
   - GET: OK
   - POST/PUT/DELETE: reject, требовать 1-RTT

2. Anti-replay mechanisms:
   - Single-use ticket
   - Timestamp validation
   - Nonce tracking

3. Application layer validation:
   - Idempotency keys
   - Duplicate detection

Implementation (Nginx):
ssl_early_data on;

location /api {
    # Reject 0-RTT for non-idempotent
    if ($ssl_early_data = 1) {
        return 425 Too Early;  # RFC 8470
    }
}

location /static {
    # Allow 0-RTT для static resources
    # GET requests безопасны
}
```

#### 5. Packet Amplification

```
Проблема:
UDP позволяет spoofing source IP → amplification attacks

Attack scenario:
1. Attacker отправляет small QUIC Initial packet (200 bytes)
   Source IP: victim's IP (spoofed)
2. Server отправляет large response (1200 bytes)
   Destination: victim's IP
3. Amplification factor: 6x

QUIC Protection:
Anti-amplification limit: 3x

Server behaviour:
До получения valid address validation token:
- Max response size: 3 * received packet size
- If client sent 200 bytes → max respond 600 bytes

After address validation:
- Full response size allowed

Address validation:
1. Retry packet with token
2. Client must prove it can receive at its IP
3. Then full communication allowed

Result: Amplification ограничен до validation
```

#### 6. Middlebox Interference

```
Проблема:
Middleboxes (proxies, DPI, firewalls) могут:
1. Блокировать QUIC packets
2. Модифицировать packet contents
3. Вносить latency inspection

Examples:
- Enterprise proxy пытается inspect QUIC → breaks encryption
- DPI system блокирует "unknown protocol"
- NAT не понимает Connection ID → breaks connection migration

QUIC Protection:
1. Encryption всего кроме minimal header
   - Connection ID
   - Packet number (частично)
   - Version
   - Все остальное encrypted

2. Version negotiation
   - Client tries latest version
   - Server может negotiate older version
   - Prevents ossification

3. Greasing (запись random values)
   - Prevents middleboxes от assuming fixed format
   - Ensures extensibility

Monitoring:
- Track HTTP/3 success rate
- Alert если <80% success
- Может означать middlebox interference

Fallback strategy:
1. Attempt HTTP/3 (QUIC)
2. If fails → HTTP/2 (TCP)
3. If fails → HTTP/1.1
4. Track which networks block QUIC
```

### Operational Challenges

#### 1. Monitoring and Observability

```
HTTP/1.1: Легко
- tcpdump, access logs, grep
- Каждый request = отдельный text

HTTP/2: Средне
- Binary protocol
- Нужен protocol-aware monitoring
- Streams мультиплексированы

HTTP/3: Сложно
- UDP-based, нет kernel visibility
- Encrypted metadata
- Connection ID вместо 5-tuple

Solutions:
1. Application-level logging
   - Log HTTP version per request
   - Stream IDs, timing, priority

2. eBPF tracing
   - Kernel-level QUIC tracking
   - Low overhead monitoring

3. SSLKEYLOGFILE для debugging (dev only!)

4. Structured logging
{
  "timestamp": "2025-12-18T10:30:00Z",
  "protocol": "h3",
  "connection_id": "0x1234567890abcdef",
  "stream_id": 4,
  "method": "GET",
  "path": "/api/users",
  "status": 200,
  "bytes_sent": 1500,
  "ttfb_ms": 45,
  "duration_ms": 120,
  "packet_loss": 0,
  "rtt_ms": 25
}
```

#### 2. Load Balancer Configuration

```
HTTP/1.1 / HTTP/2:
Load balancer работает на connection level
Connection = long-lived
Traffic distribution = по connections

Проблема с HTTP/2:
- Один connection → тысячи requests
- Один backend может получить весь traffic!

Example:
LB: 3 backend servers
Connection 1 → Backend A (1000 req/s)
Connection 2 → Backend B (10 req/s)
Connection 3 → Backend C (10 req/s)

Unbalanced!

Solutions:
1. Layer 7 load balancing (parse HTTP/2 streams)
   - HAProxy, Envoy, Nginx Plus
   - Distribute по requests, не connections

2. Периодически rotate connections
   - GOAWAY frames
   - Force new connection → новый backend

3. HTTP/3: проще
   - Connection migration
   - Можно менять backend без reconnect

Envoy config:
clusters:
  - name: backend
    type: STRICT_DNS
    lb_policy: ROUND_ROBIN  # per-request, не per-connection
    http2_protocol_options:
      max_concurrent_streams: 100
```

#### 3. Cache Invalidation

```
HTTP/2 Server Push проблема:
- Server pushed /style.css
- Client cached it
- Server updates /style.css
- Client uses stale cached version!

Cache-Digest (draft RFC 8942):
Client → Server: Cache-Digest: /style.css;etag="v1"
Server: Видит что client has v1, current is v2 → pushes v2

Но: низкий adoption

Practical solution:
1. Versioned URLs
   /static/style.v123.css
   /static/style.v124.css

2. Short cache TTL for pushed resources
   Cache-Control: max-age=300

3. 103 Early Hints вместо push
   HTTP/1.1 103 Early Hints
   Link: </style.css>; rel=preload; as=style

   Client решает сам загружать или нет
```

---

## Performance Best Practices

### HTTP/2 Optimization

```
✅ DO:
├─ Enable HTTP/2 (или HTTP/3 если возможно)
├─ Use CDN for static assets
├─ Implement proper caching headers
├─ Compress responses (gzip, brotli)
├─ Use connection pooling
├─ Implement retry logic with backoff
└─ Monitor HTTP metrics (TTFB, latency)

❌ DON'T:
├─ Open new connection per request
├─ Ignore HTTP status codes
├─ Disable keep-alive
├─ Use synchronous HTTP on main thread
└─ Ignore cache headers
```

### HTTP/3 Optimization

```
1. Включить 0-RTT для idempotent requests
   ssl_early_data on;

   но reject для POST/PUT/DELETE

2. Connection migration
   - Критично для mobile users
   - Seamless Wi-Fi → 4G transition

3. Правильный fallback
   - Быстрый timeout (1-3s)
   - Graceful fallback to HTTP/2
   - Retry HTTP/3 on network change

4. UDP optimization
   - Increase UDP buffer sizes
     sysctl -w net.core.rmem_max=2500000
     sysctl -w net.core.wmem_max=2500000

   - Enable UDP GSO/GRO (Generic Segmentation/Receive Offload)

5. Monitor key metrics
   - HTTP/3 adoption rate
   - Fallback rate
   - Performance improvement vs HTTP/2
   - Packet loss impact

6. CDN configuration
   - Используйте CDN с HTTP/3 support
   - Cloudflare, Fastly, Akamai поддерживают
   - Automatic fallback для non-supporting clients
```

---

## Источники

Материал основан на актуальной информации по состоянию на декабрь 2025:

### Официальные спецификации
- [RFC 1945 - HTTP/1.0](https://www.rfc-editor.org/rfc/rfc1945) (1996)
- [RFC 7230-7235 - HTTP/1.1](https://www.rfc-editor.org/rfc/rfc7230) (2014)
- [RFC 7540 - HTTP/2](https://httpwg.org/specs/rfc7540.html) (2015)
- [RFC 9114 - HTTP/3](https://www.rfc-editor.org/rfc/rfc9114) (2022)
- [RFC 9000 - QUIC: A UDP-Based Multiplexed and Secure Transport](https://www.rfc-editor.org/rfc/rfc9000) (2021)

### Статистика и исследования
- [W3Techs - Usage Statistics of HTTP/3](https://w3techs.com/technologies/details/ce-http3) (December 2025)
- [Internet Society - Why HTTP/3 is Eating the World](https://pulse.internetsociety.org/blog/why-http-3-is-eating-the-world)
- [CellStream - QUIC Adoption and Traffic Levels](https://www.cellstream.com/2025/02/14/an-update-on-quic-adoption-and-traffic-levels/)

### Технические статьи
- [Salesforce Engineering - The Full Picture on HTTP/2 and HOL Blocking](https://engineering.salesforce.com/the-full-picture-on-http-2-and-hol-blocking-7f964b34d205/)
- [MDN - HTTP/2 Documentation](https://developer.mozilla.org/en-US/docs/Glossary/HTTP_2)
- [HTTP/2 Frequently Asked Questions](https://http2.github.io/faq/)
- [Merge Society - HTTP Evolution Complete Breakdown](https://www.mergesociety.com/code-report/http1-http2-http3)
- [BackendBytes - HTTP Protocol Evolution Guide](https://www.backendbytes.com/backendbytes/http-evolution-complete-protocol-comparison/)

### Performance и бенчмарки
- [DebugBear - 2025 in Web Performance](https://www.debugbear.com/blog/2025-in-web-performance)
- [TechEmpower Web Framework Benchmarks](https://www.techempower.com/benchmarks/)
- [Assaptr - The Underrated Power of HTTP/3](https://assaptr.com/assaptr-tech-blogs/the-underrated-power-of-http-3-in-boosting-page-speed/)

### Дата проверки источников
**18 декабря 2025** - все источники проверены и актуальны

---

## Заключение

Эволюция HTTP демонстрирует постоянное стремление к улучшению производительности веб-приложений:

**HTTP/1.1** → решил проблему множественных соединений через keep-alive
**HTTP/2** → устранил application-level HOL blocking через multiplexing
**HTTP/3** → решил TCP-level HOL blocking через QUIC over UDP

**Текущее состояние (2025)**:
- HTTP/3 используется на 31-34% топовых сайтов
- 30%+ глобального трафика идёт через HTTP/3
- Все major tech companies активно внедряют HTTP/3
- Браузеры поддерживают 95%+ users

**Будущее**:
- Kernel QUIC implementations (2025-2026)
- Hardware QUIC offload в NIC
- Дальнейшая оптимизация 0-RTT
- Улучшения congestion control algorithms

**Рекомендации**:
- Используйте HTTP/2 как minimum
- Включайте HTTP/3 с fallback на HTTP/2
- Мониторьте adoption rate и performance
- Тестируйте на реальных сетях (особенно mobile)

---

## Связь с другими темами

[[network-transport-layer]] — эволюция HTTP неразрывно связана с транспортным уровнем: HTTP/1.1 и HTTP/2 работают поверх TCP, а HTTP/3 перешёл на QUIC (поверх UDP). Понимание TCP handshake, HOL blocking на уровне TCP и congestion control объясняет, почему каждое поколение HTTP решало проблемы предыдущего. Рекомендуется изучить транспортный уровень перед эволюцией HTTP.

[[network-dns-tls]] — каждый HTTPS-запрос начинается с DNS-резолвинга и TLS-handshake. TLS 1.3 сократил handshake до 1 RTT, а его интеграция в QUIC — ключевая причина преимущества HTTP/3 по latency. Понимание DNS и TLS критически важно для оптимизации времени до первого байта (TTFB) в HTTP-приложениях.

[[networking-overview]] — обзорный материал, который помещает HTTP в контекст всего сетевого стека. Эволюция HTTP — это прикладной пример того, как ограничения нижних уровней (TCP HOL blocking) приводят к архитектурным изменениям на верхних (переход на QUIC). Обзор рекомендуется как введение перед углублением в HTTP.

[[api-design]] — HTTP является транспортом для REST API, GraphQL и gRPC. Знание различий между HTTP/1.1, HTTP/2 и HTTP/3 влияет на выбор протокола для API: gRPC требует HTTP/2, Server Push доступен в HTTP/2, а multiplexing в HTTP/3 особенно важен для мобильных клиентов с нестабильным соединением.

---

## Источники и дальнейшее чтение

- **Grigorik I. (2013). High Performance Browser Networking.** — Наиболее практичная книга об эволюции HTTP и оптимизации сетевой производительности веб-приложений. Охватывает HTTP/1.1, HTTP/2, TLS и QUIC с точки зрения разработчика. Бесплатно доступна онлайн на hpbn.co.

- **Kurose J., Ross K. (2021). Computer Networking: A Top-Down Approach, 8th Edition.** — Академический учебник, где HTTP рассматривается как главный пример прикладного протокола. Отличные объяснения persistent connections, pipelining и мультиплексирования с визуализациями.

- **Comer D. (2015). Internetworking with TCP/IP, Volume 1, 6th Edition.** — Системный подход к интернет-протоколам, который помогает понять, почему HTTP эволюционировал именно так. Глубокий разбор взаимодействия прикладного и транспортного уровней.

---

---

## Проверь себя

> [!question]- Почему HTTP/2 может быть медленнее HTTP/1.1 при высокой потере пакетов?
> HTTP/2 мультиплексирует все потоки через одно TCP-соединение. При потере пакета TCP останавливает доставку всех данных до повторной передачи (head-of-line blocking на уровне TCP). HTTP/1.1 использует несколько соединений, и потеря в одном не блокирует другие. HTTP/3 решает это, работая на QUIC с независимыми потоками.

> [!question]- Мобильное приложение часто теряет соединение при переключении WiFi/4G. Какая версия HTTP лучше и почему?
> HTTP/3 (QUIC) поддерживает connection migration: соединение идентифицируется Connection ID, а не парой IP:port. При смене сети IP меняется, но Connection ID остаётся --- соединение продолжает работать без переустановки. HTTP/1.1 и HTTP/2 (TCP) требуют полного переподключения.

> [!question]- Компания мигрирует API на HTTP/2. gRPC-сервисы работают, но за корпоративным прокси HTTP/2 не проходит. В чём проблема?
> Многие корпоративные прокси и middleboxes не поддерживают HTTP/2 или активно вмешиваются в TLS (MITM). HTTP/2 требует TLS с ALPN, что может конфликтовать с DPI. Решение: HTTP/2 cleartext (h2c) для внутренних сервисов или HTTP/1.1 fallback для внешних клиентов за прокси.

> [!question]- Почему Server Push в HTTP/2 не получил широкого применения?
> Server Push часто отправляет ресурсы, уже имеющиеся в кэше клиента, тратя bandwidth. Сервер не знает состояние кэша браузера. Сложно предсказать, какие ресурсы нужны. 103 Early Hints --- более практичная альтернатива: сервер подсказывает preload, а браузер решает сам.

---

## Ключевые карточки

В чём главная проблема HTTP/1.1, которую решает HTTP/2?
?
Head-of-line blocking на уровне HTTP: в одном соединении запросы обрабатываются последовательно. Медленный ответ блокирует все последующие. HTTP/2 решает это multiplexing --- параллельные потоки через одно соединение.

Что такое binary framing в HTTP/2?
?
HTTP/2 заменяет текстовый формат HTTP/1.1 на бинарные фреймы. Каждый фрейм содержит stream ID, тип, длину, флаги и payload. Это позволяет мультиплексировать потоки, приоритизировать и сжимать заголовки (HPACK).

Чем QUIC отличается от TCP?
?
QUIC работает поверх UDP, реализует собственный контроль надёжности. Независимые потоки (нет TCP HOL blocking), встроенный TLS 1.3, 0-RTT при повторном подключении, connection migration при смене сети. Основа HTTP/3.

Что такое 0-RTT и какой у него риск?
?
0-RTT позволяет отправлять данные с первым же пакетом при повторном подключении (cached session key). Экономит RTT на handshake. Риск: replay attacks --- атакующий может переиграть перехваченный 0-RTT запрос. Поэтому 0-RTT допустим только для идемпотентных запросов.

Какие проблемы HTTP/3 (QUIC) решает для мобильных приложений?
?
Connection migration (сохранение соединения при WiFi/4G), отсутствие TCP HOL blocking при потере пакетов, более быстрый handshake (1-RTT + 0-RTT). Мобильные сети часто имеют высокий packet loss и смену IP --- именно для этого QUIC оптимален.

Что такое HPACK и QPACK?
?
HPACK (HTTP/2) и QPACK (HTTP/3) --- алгоритмы сжатия HTTP-заголовков. Используют статические и динамические таблицы для замены повторяющихся заголовков на индексы. QPACK адаптирован для QUIC, где порядок доставки не гарантирован.

---

## Куда дальше

| Направление | Куда | Зачем |
|-------------|------|-------|
| Следующий шаг | [[network-realtime-protocols]] | WebSocket, SSE, gRPC поверх HTTP |
| Углубиться | [[network-latency-optimization]] | Оптимизация latency на уровне протоколов |
| Смежная тема | [[api-design]] | Как выбор HTTP-версии влияет на дизайн API |
| Обзор | [[networking-overview]] | Вернуться к карте раздела |

---

*Последнее обновление: 2026-01-09 --- Добавлены педагогические секции: 5 аналогий (HTTP-поколения связи, multiplexing-кассиры, HOL blocking-пробка, 0-RTT VIP-вход, connection migration-смена комнат), 6 типичных ошибок HTTP/2/HTTP/3 с диагностикой, 5 ментальных моделей для понимания эволюции HTTP*
