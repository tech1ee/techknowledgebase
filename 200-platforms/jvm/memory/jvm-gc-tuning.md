---
title: "GC Tuning: выбор и настройка сборщика мусора"
created: 2025-11-25
modified: 2026-02-13
tags:
  - topic/jvm
  - gc
  - performance
  - g1
  - zgc
  - type/deep-dive
  - level/intermediate
type: deep-dive
status: published
area: programming
confidence: high
prerequisites:
  - "[[jvm-memory-model]]"
  - "[[jvm-basics-history]]"
related:
  - "[[jvm-performance-overview]]"
  - "[[jvm-memory-model]]"
  - "[[jvm-profiling]]"
  - "[[jvm-benchmarking-jmh]]"
reading_time: 27
difficulty: 6
study_status: not_started
mastery: 0
last_reviewed:
next_review:
---

# GC Tuning: выбор и настройка сборщика мусора

> **TL;DR:** Выбор GC зависит от требований: **G1** (default) -- баланс пауз/throughput для 90% приложений; **ZGC** -- паузы <10ms даже на TB heap, но -10-15% throughput; **Parallel** -- максимум throughput для batch, паузы 100ms-1s. Правило: heap = 3-4x live data. Netflix перешли на ZGC и снизили ошибки с 2000/сек до 100/сек.

---

## Пререквизиты

| Тема | Зачем нужно | Где изучить |
|------|-------------|-------------|
| Память JVM | Понимать Heap, Stack, Metaspace | [[jvm-memory-model]] |
| Как работает JVM | Общая архитектура | [[jvm-basics-history]] |
| OS память | Виртуальная память, paging | [[os-memory-management]] |

---

## Зачем это знать

Garbage Collector освобождает память от объектов без ссылок. JVM предлагает несколько сборщиков: Parallel GC максимизирует throughput для batch-обработки, G1 балансирует паузы и пропускную способность, ZGC держит паузы под 10ms даже на терабайтных heap.

p99 latency скачет до секунд? CPU 100%, но throughput падает? Full GC на 5 секунд? "Просто увеличить heap" -- не решение. G1 работает для 90% веб-приложений при правильных параметрах: MaxGCPauseMillis, InitiatingHeapOccupancyPercent, размеры регионов. ZGC для low-latency, Parallel для batch.

---

## Терминология для новичков

| Термин | Что это | Аналогия из жизни |
|--------|---------|-------------------|
| **STW (Stop-The-World)** | Пауза, когда все потоки остановлены для GC | Остановка конвейера для уборки |
| **Throughput** | Доля времени на полезную работу (не GC) | КПД = работа / (работа + уборка) |
| **Minor GC** | Сборка только Young Generation | Ежедневная уборка в комнате |
| **Major/Full GC** | Сборка всего heap, включая Old Gen | Генеральная уборка всей квартиры |
| **G1 Region** | Блок памяти в G1 (обычно 1-32MB) | Комната в квартире -- можно убрать отдельно |
| **Humongous** | Объект >50% размера региона в G1 | Огромный шкаф, занимающий несколько комнат |
| **IHOP** | Порог запуска concurrent marking | Когда начинать уборку: при 45% заполнении или раньше |
| **Colored Pointers** | Метаданные в указателях ZGC | Цветные метки на коробках для быстрой сортировки |
| **Live Data** | Объекты, достижимые от GC roots | То, что реально используется и нельзя выбросить |
| **GC Roots** | Стартовые точки для поиска живых объектов | Отправные точки для инвентаризации |

---

## Историческая справка

Сборка мусора -- одна из старейших идей в computer science, и её эволюция объясняет, почему современные сборщики устроены именно так.

**Mark-sweep (John McCarthy, 1960)** -- первый алгоритм GC, созданный для языка Lisp. McCarthy понял, что ручное управление памятью -- источник огромного количества ошибок, и предложил автоматическое решение: пройти по всем достижимым объектам (mark), затем освободить всё остальное (sweep). Алгоритм элегантен, но имеет фундаментальную проблему: он должен остановить программу на время обхода всего heap. Чем больше heap -- тем длиннее пауза. Эта проблема определила следующие 60 лет исследований в области GC.

**Generational hypothesis (David Ungar, 1984)** -- ключевое наблюдение, изменившее GC навсегда. Ungar заметил, что в типичной программе большинство объектов умирают молодыми: создаются, используются в одном вычислении и становятся мусором. Лишь малая часть живёт долго (кэши, конфигурации, синглтоны). Вывод: не нужно каждый раз сканировать весь heap. Разделите память на "молодое" и "старое" поколение, собирайте молодое часто и дёшево (там 90% мусора), а старое -- редко. Все современные JVM GC основаны на этой идее.

**G1 GC (2006 research, 2017 default)** -- разработан в Sun Microsystems (Detlefs et al., 2004). Идея: вместо монолитных поколений разбить heap на множество мелких регионов. Это позволяет собирать не "всё молодое" или "всё старое", а "самые мусорные регионы, которые можно обработать за целевое время паузы". G1 стал default GC в Java 9 (2017), заменив Parallel GC, потому что latency стала важнее throughput в эпоху микросервисов.

**ZGC (2018 experimental, 2023 generational)** -- разработан в Oracle (Per Liden). Цель: sub-millisecond паузы на heap любого размера. ZGC использовал радикально новый подход -- colored pointers и load barriers вместо stop-the-world фаз. Generational ZGC (JDK 21, 2023) добавил поколения, значительно улучшив throughput без потери low-latency характеристик.

**Shenandoah (2014 research, 2019 production)** -- разработан в Red Hat (Christine Flood, Roman Kennke). Альтернативный подход к concurrent GC через Brooks pointers (forwarding pointers на каждом объекте). Shenandoah решает ту же задачу, что и ZGC, но другим способом, и доступен в OpenJDK без привязки к Oracle.

---

## Фундаментальный компромисс GC

Любой сборщик мусора решает одну задачу: найти и освободить память от недостижимых объектов. Но способ решения определяет, что именно вы получите -- и чем заплатите.

> **Аналогия: три стратегии уборки квартиры.** Parallel GC -- это генеральная уборка: все останавливаются, собираются вместе и убирают всю квартиру. Быстро и эффективно, но жить в квартире во время уборки невозможно. G1 -- это уборка по комнатам: убираешь только самые грязные комнаты, выбирая те, что можно успеть за час. Жизнь не останавливается полностью, но время от времени нужно выйти из комнаты, пока её убирают. ZGC -- это робот-пылесос: работает пока ты живёшь, ходишь, готовишь. Ты почти не замечаешь его, но он потребляет электричество (CPU) и иногда ненадолго просит подвинуться (микропаузы).

**Stop-the-world (STW) паузы** -- время, когда все потоки приложения остановлены. Чем короче паузы, тем больше накладных расходов: сборщик тратит CPU на координацию с работающим приложением вместо того, чтобы просто остановить его и собрать мусор.

**Throughput** -- доля времени, которую приложение тратит на полезную работу (а не на GC). Если приложение работает 95 секунд из 100, throughput = 95%.

Эти метрики противоположны. Parallel GC максимизирует throughput за счёт длинных пауз. ZGC минимизирует паузы, но отдаёт 10-15% throughput на накладные расходы concurrent-фазы. G1 -- компромисс посередине.

| Сценарий | GC | Паузы | Throughput | Почему |
|----------|-----|-------|------------|--------|
| **Batch processing** | Parallel GC | 100-1000ms | 95%+ | Паузы не важны, важна скорость |
| **Web API** | G1 GC | 50-200ms | 85-90% | Баланс для p99 latency |
| **Low-latency** | ZGC | <10ms | 80-85% | SLA важнее throughput |
| **Контейнеры <512MB** | Serial GC | Варьируется | OK | Минимум памяти под GC |

```bash
# Batch (максимум throughput)
java -XX:+UseParallelGC -Xms8g -Xmx8g MyApp

# Web API (баланс)
java -XX:+UseG1GC -Xms4g -Xmx4g MyApp

# Low-latency
java -XX:+UseZGC -Xms16g -Xmx16g MyApp
```

---

## G1 GC (default, для большинства)

G1 (Garbage First) стал дефолтным сборщиком в Java 9 не случайно. Он решает главную проблему веб-приложений: непредсказуемые паузы при большом heap.

Традиционные сборщики (Parallel, CMS) работают с монолитными областями памяти. Когда Old Gen занимает 10GB и нужна очистка -- собирается весь Old Gen целиком. Пауза может длиться секунды.

### Идея регионов

G1 разбивает heap на множество небольших регионов (обычно 2048 штук). Каждый регион -- самостоятельная единица, которую можно собрать отдельно. Вместо "собрать весь Old Gen" G1 говорит: "У меня есть 50ms на паузу. Какие регионы содержат больше всего мусора? Соберу сначала их."

Отсюда название: Garbage First -- сначала мусор. G1 ведёт статистику по каждому региону и всегда начинает с самых "мусорных".

```
Heap = регионы разного типа:
+---+---+---+---+---+---+---+---+---+
| E | E | E | S | O | O | O | H | F |
+---+---+---+---+---+---+---+---+---+
  ^       ^   ^       ^   ^   ^
 Eden  Survivor Old  Humongous Free
```

**Типы регионов:**
- **Eden (E)** -- новые объекты. G1 динамически выделяет регионы под Eden по мере необходимости
- **Survivor (S)** -- объекты, пережившие Minor GC. Перемещаются между регионами несколько раз
- **Old (O)** -- долгоживущие объекты после 15 циклов GC
- **Humongous (H)** -- объекты больше 50% размера региона. Занимают несколько смежных регионов
- **Free (F)** -- свободные регионы в пуле

### Mixed Collections: сердце G1

Mixed collection -- уникальная особенность G1, которая отличает его от других сборщиков. Во время mixed collection G1 собирает не только Young Generation (как при обычном Minor GC), но и часть Old Generation -- те регионы, где наибольшее соотношение мусора к живым данным.

Процесс состоит из нескольких фаз. Сначала concurrent marking phase проходит по всему heap параллельно с работающим приложением, отмечая живые объекты. Эта фаза запускается, когда heap заполнен до уровня IHOP (по умолчанию 45%). После завершения marking, G1 знает точное количество мусора в каждом регионе и может рассчитать, какие регионы наиболее "прибыльно" собрать.

Затем следует серия mixed pauses -- STW-пауз, в каждую из которых G1 собирает все Eden-регионы плюс несколько Old-регионов (обычно 10% от общего количества Old-регионов за одну паузу). G1 выбирает регионы так, чтобы уложиться в target pause time (MaxGCPauseMillis). Если целевая пауза -- 100ms, а сборка одного Old-региона занимает ~5ms, G1 включит в mixed collection не более 20 Old-регионов помимо Eden.

Этот механизм делает G1 адаптивным: при низкой allocation rate mixed collections происходят редко и затрагивают много Old-регионов за раз; при высокой -- чаще, но с меньшим объёмом работы за паузу. G1 постоянно корректирует свои prediction models на основе статистики предыдущих сборок.

### Humongous objects: скрытая проблема

**Почему Humongous -- проблема:** Большой массив на 10MB при регионах по 4MB займёт 3 смежных региона. Эти регионы нельзя собрать частично -- только все вместе. И они сразу считаются "старыми", даже если объект живёт миллисекунду. Много humongous-объектов ломают всю идею инкрементальной сборки.

Humongous allocation -- одна из самых частых причин неожиданных Full GC в G1. Если для humongous-объекта не удаётся найти достаточно смежных свободных регионов, G1 вынужден выполнить Full GC для дефрагментации. Диагностировать просто: в GC-логах ищите `[GC pause (G1 Humongous Allocation)]`. Решение -- увеличить размер региона (`-XX:G1HeapRegionSize`), чтобы объект перестал быть humongous, или рефакторить код, чтобы не создавать крупные массивы и буферы.

Начиная с Java 12, G1 научился собирать humongous-объекты во время Young GC (а не только Full GC), что значительно снизило остроту проблемы. Но создание humongous-объектов всё равно дороже обычных аллокаций из-за необходимости поиска смежных регионов.

### Основные параметры

G1 -- adaptive collector. Он сам подстраивает внутренние параметры под ваш target. Ваша задача -- правильно задать цели.

```bash
# Target max pause (default: 200ms)
-XX:MaxGCPauseMillis=100

# Когда запускать concurrent marking (default: 45%)
-XX:InitiatingHeapOccupancyPercent=35

# Размер региона (auto: heap/2048)
-XX:G1HeapRegionSize=8m
```

**MaxGCPauseMillis** -- это не гарантия, а цель. G1 старается уложиться, но если heap переполнен или объектов слишком много -- пауза будет дольше. Слишком агрессивное значение (10ms) приведёт к тому, что G1 будет собирать очень мало за раз и не успеет за allocation rate.

**InitiatingHeapOccupancyPercent (IHOP)** определяет, когда начинать concurrent marking -- фоновую фазу, которая определяет живые объекты. Если IHOP слишком высокий (скажем, 70%), marking может не успеть завершиться до того, как heap переполнится -> Full GC. Начиная с Java 10, G1 поддерживает adaptive IHOP: он сам вычисляет оптимальный порог на основе статистики allocation rate и marking speed. Явное указание IHOP отключает адаптацию.

**G1HeapRegionSize** обычно не трогают. Но если много больших объектов (массивы, буферы), увеличение размера региона уменьшит количество humongous-объектов.

### Частые проблемы и решения

**Проблема: Паузы > 200ms**

```bash
# До: p99 pause = 400ms
java -Xms4g -Xmx4g -XX:+UseG1GC MyApp

# После: агрессивный target + раньше запускать marking
java -Xms4g -Xmx4g -XX:+UseG1GC \
     -XX:MaxGCPauseMillis=100 \
     -XX:InitiatingHeapOccupancyPercent=35 \
     MyApp

# Результат: p99 pause = 120ms (throughput -5%)
```

**Проблема: Full GC (паузы 1-10 секунд)**

```
# В логах
[Full GC (Allocation Failure) 3950M->1234M(4096M), 3.456s]
                                                   ^
                                            3.5 секунды!
```

Причины и решения:
```bash
# 1. Heap переполнился -> увеличить
-Xms8g -Xmx8g  # было 4g

# 2. GC не успевает -> запускать marking раньше
-XX:InitiatingHeapOccupancyPercent=30  # было 45

# 3. Humongous объекты -> увеличить размер региона
-XX:G1HeapRegionSize=16m  # было 2m
```

**Проблема: Premature promotion (объекты уходят в Old Gen слишком рано)**

```bash
# Симптом: Old Gen растёт быстро, частые Mixed GC

# Решение: увеличить Young Gen
-XX:G1NewSizePercent=30     # min Young Gen (default: 5%)
-XX:G1MaxNewSizePercent=60  # max Young Gen (default: 60%)
```

---

## ZGC (low-latency)

ZGC делает то, что раньше считалось невозможным: паузы меньше 10 миллисекунд на heap размером в терабайты. Это не маркетинг -- это реальные цифры в production.

### Как это возможно: colored pointers

Традиционные сборщики останавливают приложение, чтобы безопасно перемещать объекты. Пока GC двигает объект, никто не должен читать старый адрес.

ZGC использует **colored pointers** -- метаданные, встроенные прямо в указатель на объект. На 64-bit системах адресное пространство избыточно: реальные адреса используют 44-48 бит из 64 доступных. ZGC использует свободные биты для хранения информации о состоянии объекта: перемещён ли он, в какой фазе GC был последний раз обработан, нужно ли обновить ссылку на него.

Когда приложение читает указатель на объект, **load barrier** (специальный код, вставленный JIT-компилятором перед каждым чтением объекта) проверяет цвет указателя. Если цвет "неправильный" (объект был перемещён, но ссылка ещё не обновлена), load barrier обновляет указатель на лету, указывая на новый адрес объекта. Это называется **self-healing**: ссылка "лечит" себя при первом доступе.

Благодаря этому механизму ZGC может перемещать объекты *параллельно* с работающим приложением -- **concurrent compaction**. Ни один другой GC до ZGC не мог делать compaction без STW-паузы. Stop-the-world паузы нужны только для начальной синхронизации (root scanning) -- это десятки микросекунд, не миллисекунды. И эти паузы не зависят от размера heap -- будь у вас 1GB или 16TB, STW-пауза одинаково мала.

### Generational ZGC (JDK 21)

До JDK 21 ZGC был non-generational: он обрабатывал весь heap одинаково, не разделяя объекты на молодые и старые. Это работало, но было неэффективно: ZGC тратил ресурсы на сканирование долгоживущих объектов, которые не изменились с прошлой сборки.

Generational ZGC (JEP 439) добавил поколения, сохранив все преимущества concurrent operation. Молодые объекты собираются отдельно и чаще, старые -- реже. Результаты впечатляющие: Netflix сообщил о снижении CPU overhead на 5-10% при переходе на Generational ZGC по сравнению с non-generational версией. Allocation stalls (ситуации, когда приложение ждёт GC) стали практически невозможны.

### Цена low-latency

- **CPU overhead 10-15%** -- load barriers выполняются при каждом чтении объекта. JIT-компилятор оптимизирует барьеры (объединяет, удаляет лишние), но overhead неизбежен
- **Memory overhead** -- ZGC требует больше памяти для своих структур: colored pointers, forwarding tables, remembered sets для generational mode
- **Throughput ниже** -- concurrent GC тратит CPU, который мог бы делать полезную работу. Несколько GC-потоков работают параллельно с приложением, отнимая ядра

Для batch processing, где пауза в 500ms раз в минуту никому не мешает, ZGC -- плохой выбор. Вы платите 15% throughput за ненужную вам low-latency.

### Базовая настройка

```bash
java -XX:+UseZGC \
     -Xms16g -Xmx16g \
     -XX:SoftMaxHeapSize=14g \
     MyApp
```

**SoftMaxHeapSize** -- мягкий лимит. ZGC старается не превышать его, но может при необходимости. Полезно для контейнеров с memory limits: устанавливается на 80-90% от -Xmx, чтобы у ZGC был запас для пиковых нагрузок.

Одно из ключевых преимуществ ZGC -- операционная простота. В отличие от G1, где можно часами подбирать IHOP, region size и pause target, ZGC требует минимальной настройки. В большинстве случаев достаточно `-Xmx` и `-XX:+UseZGC`. ZGC сам адаптирует количество GC-потоков, частоту сборок и порог запуска.

### Реальные результаты

```
До (G1):   p99 pause = 150ms, p99.9 = 300ms
После (ZGC): p99 pause = 2ms, p99.9 = 5ms

Tradeoff: throughput -10%, CPU +15%
```

### Когда ZGC не подходит

- **Heap < 4GB** -- overhead не оправдан, G1 справится лучше
- **Batch processing** -- платите за low-latency, которая не нужна
- **Java < 15** -- ZGC был experimental до Java 15
- **32-bit JVM** -- colored pointers требуют 64-bit

---

## Shenandoah GC (альтернативный low-latency)

Shenandoah -- concurrent GC, разработанный Red Hat, решающий ту же задачу, что и ZGC: sub-millisecond паузы. Но использующий принципиально другой механизм -- **Brooks pointers** (forwarding pointers).

### Brooks pointers vs colored pointers

В ZGC метаданные о перемещении объекта хранятся в самом указателе (colored pointers). В Shenandoah каждый объект содержит дополнительное поле -- forwarding pointer (Brooks pointer), который изначально указывает на сам объект. Когда GC перемещает объект, он обновляет forwarding pointer на новый адрес. Все обращения к объекту проходят через этот pointer.

Преимущество подхода Shenandoah: не требует специальных битов в указателе, поэтому теоретически может работать на 32-bit системах (хотя практически это не реализовано). Недостаток: каждый объект "толще" на одно машинное слово (8 байт на 64-bit), что увеличивает потребление памяти. Кроме того, одна дополнительная indirection при каждом доступе к объекту создаёт overhead на уровне кэша процессора.

### Concurrent copying

Shenandoah выполняет копирование живых объектов (evacuation) параллельно с приложением -- concurrent copying. Это ключевая операция, требующая координации с приложением: пока GC копирует объект, приложение может пытаться его прочитать или изменить.

Shenandoah решает это через **CAS (Compare-And-Swap) операции** на forwarding pointer. Когда GC копирует объект, он атомарно обновляет forwarding pointer. Если приложение успело прочитать старый pointer -- оно увидит старую копию (которая ещё valid). При следующем доступе barrier перенаправит на новую. Это обеспечивает correctness без STW-паузы.

### Когда выбрать Shenandoah вместо ZGC

Shenandoah доступен в OpenJDK builds от Red Hat, Amazon (Corretto) и других вендоров. Основные случаи выбора Shenandoah:

- Вы используете OpenJDK builds без Oracle-патчей, и ZGC не доступен или недостаточно стабилен в вашей версии
- Ваше приложение чувствительно к memory overhead (Shenandoah может быть эффективнее ZGC при определённых allocation patterns)
- Вам нужен concurrent GC на Java 11 LTS (Shenandoah был backported раньше ZGC)

На практике в 2024-2025 ZGC Generational считается предпочтительным выбором для low-latency на JDK 21+, но Shenandoah остаётся viable альтернативой, особенно в экосистеме Red Hat.

---

## Parallel GC (максимум throughput)

Parallel GC -- самый "тупой" и самый быстрый сборщик. Он не пытается минимизировать паузы. Он просто останавливает приложение и собирает мусор максимально эффективно, используя все доступные ядра.

> **Аналогия:** Parallel GC -- это генеральная уборка. Все жители квартиры (потоки приложения) прекращают свои дела и вместе убирают всю квартиру. Никто не работает, все убирают. Это максимально эффективно: нет необходимости координироваться с людьми, которые продолжают пользоваться комнатами (concurrent access). Нет risk "убрать то, что кто-то ещё использует". Просто тотальная уборка -- быстро, грубо, эффективно.

### Почему он быстрее

G1 и ZGC тратят ресурсы на:
- Отслеживание ссылок между регионами (remembered sets)
- Concurrent phases (фоновое сканирование параллельно с приложением)
- Write/load barriers (перехват записей и чтений)

Parallel GC ничего этого не делает. Он работает по простой схеме:
1. Остановить всё
2. Просканировать heap всеми ядрами параллельно
3. Скопировать живые объекты
4. Продолжить

Меньше overhead = больше времени на полезную работу.

### Когда Parallel GC -- лучший выбор

Parallel GC часто считают "устаревшим", но это заблуждение. Для определённых workload он остаётся оптимальным:

- **Batch processing** -- обработка данных без interactive latency требований. Apache Spark, Hadoop, ETL pipelines -- пауза в 500ms раз в минуту не влияет на итоговое время обработки миллиарда записей
- **ML training** -- пауза в секунду раз в минуту не влияет на итоговое время обучения, а 10% дополнительного throughput сокращает время тренировки на часы
- **Ночные задачи** -- cron jobs, report generation, data migration -- никто не ждёт response time, важна только общая скорость
- **Short-lived приложения** -- CLI-утилиты, скрипты, одноразовые вычисления, где GC происходит 0-2 раза за время работы

```bash
java -XX:+UseParallelGC \
     -Xms8g -Xmx8g \
     -XX:ParallelGCThreads=8 \
     MyApp
```

**ParallelGCThreads** -- количество потоков для GC. По умолчанию равно количеству CPU. На серверах с 64+ ядрами имеет смысл ограничить до 8-16, иначе coordination overhead съедает выигрыш. Причина: потоки GC должны синхронизироваться при обработке общих структур (worklists, copy queues), и при 64 потоках contention на этих структурах становится значительным.

Паузы 100-1000ms, но throughput 95%+ (vs 85-90% у G1). Для batch job на час пауза в секунду раз в минуту -- это 60 секунд overhead из 3600. Незаметно.

---

## Диагностика GC

GC tuning без данных -- гадание. Прежде чем крутить параметры, нужно понять текущее поведение.

### Включить GC логи

GC логи -- единственный достоверный источник информации о поведении сборщика. Включайте их всегда, даже в production. Overhead минимален.

```bash
# Java 9+
java -Xlog:gc*:file=gc.log:time,level,tags MyApp

# Java 8
java -XX:+PrintGCDetails -XX:+PrintGCDateStamps -Xloggc:gc.log MyApp
```

Логи ротируются, можно настроить размер и количество файлов:

```bash
java -Xlog:gc*:file=gc.log:time,level,tags:filecount=5,filesize=10m MyApp
```

### Что смотреть в логах

```
[GC pause (G1 Evacuation Pause) (young) 512M->156M(4096M), 25.4 ms]
          ^                      ^       ^      ^    ^       ^
          |                      |    Before  After Total  Pause
          |                      |
          |                      +-- (young) = Young Gen только
          |                         (mixed) = Young + часть Old
          |
          +-- Evacuation Pause = копирование живых объектов
             в свободные регионы (основная работа G1)
```

**Ключевые метрики:**
- **Pause time** -- время stop-the-world. Главная метрика для latency-sensitive приложений
- **Before/After** -- сколько памяти было и стало. Если After растёт со временем -- утечка
- **Frequency** -- как часто происходят GC. Если Young GC каждые 100ms -- слишком много аллокаций

**Красные флаги:**
- `[Full GC` -- любой Full GC в production требует расследования
- Паузы растут со временем -- вероятно memory leak
- `(Allocation Failure)` -- heap не успевает освобождаться
- `(to-space exhausted)` -- G1 не успел освободить место для копирования объектов

### Инструменты

- **GCViewer** -- визуализация GC логов, графики пауз и heap usage
- **GCEasy.io** -- онлайн анализ с рекомендациями (загружаешь gc.log, получаешь отчёт)
- **async-profiler** -- allocation profiling:

```bash
# Показывает какой код создаёт больше всего объектов
# Flame graph: чем шире полоса -- тем больше аллокаций
./profiler.sh -e alloc -d 30 -f alloc.html <pid>

# Результат: "метод parseJson() аллоцирует 80% объектов"
# -> Оптимизируй parseJson() или используй object pool
```

---

## Sizing: сколько памяти выделять

Правильный размер heap -- ключевой фактор производительности GC. Слишком мало -- частые сборки. Слишком много -- долгие паузы и waste ресурсов.

### Принцип: GC нужно место для работы

Сборщики мусора копируют живые объекты из одной области в другую. Если живых данных 4GB, а heap всего 5GB, то после копирования остаётся только 1GB свободного места. Следующая сборка начнётся очень скоро.

**Правило 3-4x:** Heap должен быть в 3-4 раза больше размера живых данных после Full GC. Это даёт достаточно пространства для аллокаций между сборками.

### Определение live data

**Live data** -- объекты, которые реально используются приложением (достижимы от GC roots: static поля, стек потоков, JNI references). Всё остальное -- мусор.

Запустите приложение под нагрузкой и посмотрите heap usage после Full GC:

```bash
# jcmd -- CLI утилита для диагностики JVM (входит в JDK)
# <pid> -- process ID вашего Java-процесса (узнать: jps или ps aux | grep java)

# Принудительно вызвать Full GC
jcmd <pid> GC.run

# Посмотреть heap usage
jcmd <pid> GC.heap_info
```

Или в GC логах найдите `Full GC` и посмотрите на "after":

```
[Full GC ... 3950M->1234M(4096M), 3.456s]
                  ^
             Live data = 1234MB
```

### Практические правила

1. **-Xms = -Xmx** -- фиксированный размер heap. Resize во время работы вызывает паузы и фрагментацию
2. **Heap = 3-4x live data** -- достаточно места для работы GC
3. **Не больше 75% RAM** -- остальное нужно для:
   - **OS cache** -- файловый кэш ускоряет I/O
   - **Metaspace** -- память под классы, методы, constant pool (вне heap!)
   - **Direct ByteBuffers** -- off-heap память для NIO (сетевые буферы, mapped files)

### Пример расчёта

```
Live data после Full GC: 2GB
-> Оптимальный heap: 6-8GB
-> Если сервер 12GB RAM: -Xms8g -Xmx8g (OK, остаётся 4GB для OS)
-> Если контейнер 4GB RAM: -Xms3g -Xmx3g (tight! рассмотрите уменьшение cache sizes)
```

**Контейнеры:** JVM видит cgroup limits начиная с Java 10 (до этого JVM видела всю RAM хоста, а не лимит контейнера!).

```bash
# Вместо абсолютных -Xmx -- процент от доступной памяти
# JVM сама вычислит heap на основе cgroup limit
java -XX:MaxRAMPercentage=75.0 -XX:InitialRAMPercentage=75.0 MyApp

# В контейнере с memory: 4Gi -> heap = 3GB
```

---

## Чеклист GC Tuning

```
- Выбрал правильный GC для use case
- Heap size = 3-4x live data
- -Xms = -Xmx (фиксированный размер)
- Включил GC логи
- Нет Full GC в production
- Паузы в рамках SLA
- Throughput приемлемый
```

---

## Quick Reference: флаги

| Задача | Флаг |
|--------|------|
| Выбрать G1 | `-XX:+UseG1GC` |
| Выбрать ZGC | `-XX:+UseZGC` |
| Выбрать Shenandoah | `-XX:+UseShenandoahGC` |
| Target pause | `-XX:MaxGCPauseMillis=100` |
| Начать marking раньше | `-XX:InitiatingHeapOccupancyPercent=35` |
| Больше Young Gen | `-XX:G1NewSizePercent=30` |
| Размер региона | `-XX:G1HeapRegionSize=8m` |
| GC логи | `-Xlog:gc*:file=gc.log:time,level,tags` |
| Heap dump при OOM | `-XX:+HeapDumpOnOutOfMemoryError` |
| ZGC мягкий лимит | `-XX:SoftMaxHeapSize=14g` |

---

## Кто использует и реальные примеры

| Компания | GC выбор | Результаты |
|----------|----------|------------|
| **Netflix** | Перешли с G1 на ZGC (JDK 21) | Ошибки 2000/сек -> 100/сек, batch на 6-8% быстрее |
| **LinkedIn** | G1 для большинства сервисов | Стабильные паузы ~100ms |
| **Alibaba** | Dragonwell с улучшенным G1 | Оптимизации под их workload |
| **Discord** | ZGC для real-time messaging | Паузы <10ms обязательны для UX |
| **Cassandra** | G1 или ZGC в зависимости от SLA | Latency-sensitive database |

### Netflix Case Study (2024)

```
До (G1):
- p99 pause: 150ms
- p99.9 pause: 300ms
- Peak errors: 2000/sec (из-за timeouts)

После (Generational ZGC, JDK 21):
- p99 pause: 2ms
- p99.9 pause: 5ms
- Peak errors: ~100/sec

Ключевые наблюдения:
- Операционная простота: ZGC работает без тюнинга
- Allocation stalls редки и короткие
- Некоторые workloads всё ещё лучше на G1
```

### Когда какой GC

```
Вопрос: Какой GC выбрать?

if heap < 4GB && latency не критична:
    return G1  # default, просто работает

elif latency SLA < 10ms:
    return ZGC  # готовы платить throughput

elif batch processing (Spark, ETL):
    return Parallel  # максимум throughput

elif контейнер < 512MB:
    return Serial  # минимум overhead

else:
    return G1  # safe default
```

---

## Распространённые заблуждения

| Заблуждение | Почему это неверно |
|-------------|-------------------|
| "Чем больше heap, тем лучше" | Большой heap = **длинные паузы GC**. 64GB heap с G1 может иметь паузы по секундам. ZGC/Shenandoah нужны для больших heap'ов |
| "System.gc() очищает память" | System.gc() -- **hint**, не команда. JVM может проигнорировать. В production вызов System.gc() -- обычно ошибка. `-XX:+DisableExplicitGC` отключает |
| "GC tuning -- первый шаг оптимизации" | **Allocation rate** -- главная метрика. Если создаёте много мусора, никакой GC не поможет. Сначала профилируйте allocations, потом GC |
| "G1 всегда лучше Parallel GC" | Для **batch processing** (Spark, ETL) Parallel GC может дать лучший throughput. G1 оптимизирован для latency, не throughput |
| "ZGC = серебряная пуля" | ZGC жертвует ~15% throughput ради low latency. Для batch jobs Parallel лучше. ZGC = trade-off, не universal solution |
| "Generational hypothesis не работает для моего приложения" | 95%+ приложений следуют паттерну: большинство объектов живут недолго. Если не так -- проблема в архитектуре приложения, не в hypothesis |
| "Нужно тюнить все GC параметры" | Современные GC (G1, ZGC) **самотюнящиеся**. Обычно достаточно `-Xmx` и выбора GC. Over-tuning часто вредит: фиксированные параметры мешают адаптивным алгоритмам GC подстраиваться под меняющуюся нагрузку |
| "Full GC = катастрофа" | Periodic full GC -- нормально. **Проблема** -- частые Full GC из-за нехватки памяти. Occasional full GC в off-peak часы -- приемлемо |
| "Metaspace unlimited = хорошо" | Unlimited Metaspace может привести к **OOM при class leak** (hot deploy). Лимит Metaspace помогает детектировать утечки раньше |
| "Логи GC нужны только при проблемах" | GC логи нужны **всегда в production**. `-Xlog:gc*` почти бесплатны, но бесценны для post-mortem анализа |

---

## CS-фундамент

| CS-концепция | Применение в GC Tuning |
|--------------|----------------------|
| **Generational Hypothesis** | "Большинство объектов умирают молодыми". Young Gen собирается часто и дёшево, Old Gen -- редко. Основа всех generational collectors |
| **Mark-and-Sweep Algorithm** | Базовый алгоритм GC: отмечаем reachable объекты, удаляем остальные. Варианты: mark-compact (дефрагментация), mark-copy (copying collector) |
| **Stop-The-World (STW)** | Пауза всех application threads во время GC. G1 минимизирует STW, ZGC делает concurrent marking и relocation |
| **Concurrent vs Parallel** | Parallel = несколько GC threads одновременно. Concurrent = GC работает параллельно с приложением. ZGC -- mostly concurrent |
| **Write Barrier** | Инструментация записей в heap для отслеживания изменений. G1/ZGC используют write barriers для concurrent marking. Небольшой overhead |
| **Tri-color Marking** | Алгоритм concurrent marking: white (не посещён), gray (посещён, дети не все), black (посещён полностью). Позволяет concurrent traversal |
| **Reference Counting vs Tracing** | JVM использует tracing (reachability). Reference counting не справляется с циклами. Tracing находит все unreachable объекты |
| **Compaction** | Перемещение живых объектов для устранения фрагментации. G1 делает compaction per-region. Необходим для долгоживущих приложений |
| **Safepoints** | Точки в коде где JVM может безопасно приостановить thread для GC. Loop safepoint polling, call safepoints. Time-to-safepoint влияет на паузы |
| **Colored Pointers (ZGC)** | ZGC хранит metadata в указателях (unused bits). Позволяет concurrent relocation без STW. Load barrier декодирует pointer color |

---

## Связь с другими темами

**[[jvm-performance-overview]]** -- GC tuning -- один из ключевых элементов оптимизации JVM-приложений, но не единственный. Performance overview показывает полную картину: JIT compilation, lock contention, I/O -- всё это влияет на latency наряду с GC паузами. Без общего контекста есть риск over-tune GC, когда реальная проблема в другом месте. Начните с performance overview для стратегии, затем погружайтесь в GC tuning для конкретных проблем с паузами.

**[[jvm-profiling]]** -- allocation profiling через async-profiler -- первый шаг перед GC tuning: нет смысла настраивать сборщик, если код создаёт гигабайты мусора в секунду. Profiling находит allocation hotspots (какой код создаёт объекты), а GC tuning настраивает JVM для эффективной обработки оставшегося мусора. Правило: сначала уменьшите allocation rate через profiling, затем tune GC для оставшейся нагрузки.

**[[jvm-memory-model]]** -- GC работает с heap, а memory model объясняет его структуру: Young/Old Generation, Metaspace, TLAB. Без понимания, как объекты размещаются и перемещаются между поколениями, невозможно осмысленно настраивать G1 regions, IHOP threshold или ZGC. Memory model -- теоретический фундамент, GC tuning -- практическое применение этих знаний.

**[[jvm-benchmarking-jmh]]** -- после изменения GC параметров необходимо измерить эффект: уменьшились ли паузы, не упал ли throughput. JMH позволяет изолировать влияние GC от других факторов и получить статистически достоверные результаты. Без бенчмарков GC tuning превращается в гадание -- особенно для тонких настроек вроде MaxGCPauseMillis и InitiatingHeapOccupancyPercent.

---

## Источники и дальнейшее чтение

- Jones R., Hosking A., Moss E. (2011). *The Garbage Collection Handbook: The Art of Automatic Memory Management.* -- Фундаментальная книга по всем алгоритмам GC: от mark-sweep до concurrent collectors. Описывает теоретическую базу, на которой построены все JVM сборщики. Незаменима для глубокого понимания ПОЧЕМУ G1 использует регионы, ПОЧЕМУ ZGC использует colored pointers и ПОЧЕМУ generational hypothesis работает.
- Oaks S. (2020). *Java Performance: In-Depth Advice for Tuning and Programming Java 8, 11, and Beyond, 2nd ed.* -- Практическое руководство по GC tuning: выбор сборщика, sizing, интерпретация GC логов, оптимизация allocation rate. Главы 5-7 -- лучший источник для JVM-специфичного GC tuning с реальными примерами и benchmarks.
- Tene G. (2019). *Understanding Java Garbage Collection (talk).* -- Доклад Gil Tene (создателя Azul Zing/C4 GC) с визуальным объяснением работы различных GC алгоритмов. Отлично объясняет компромиссы между throughput и latency, concurrent vs parallel phases, и почему "pauseless" GC -- не совсем pauseless. Доступен на YouTube.

---

---

## Проверь себя

> [!question]- Почему перед настройкой GC нужно сначала профилировать allocation rate?
> Если код создаёт гигабайты мусора в секунду, никакой GC не справится эффективно. Уменьшение allocation rate (устранение лишних string конкатенаций, autoboxing, временных DTO) напрямую снижает частоту и длительность GC пауз. Аналогия: не имеет смысла настраивать подвеску, если колесо пробито. Сначала async-profiler -e alloc, потом GC tuning.

> [!question]- У вас G1 с heap 4GB, и в GC логах появились Full GC с паузами 3-5 секунд. Назовите три вероятных причины и решения.
> (1) Heap переполнился -- увеличить -Xmx или уменьшить live data. (2) Concurrent marking не успевает -- снизить IHOP (InitiatingHeapOccupancyPercent) с 45% до 30-35%, чтобы marking начинался раньше. (3) Humongous объекты ломают инкрементальную сборку -- увеличить G1HeapRegionSize, чтобы объекты перестали быть humongous, или рефакторить код.

> [!question]- В каком сценарии ZGC -- плохой выбор, несмотря на его рекордно низкие паузы?
> Для batch processing (Spark, ETL, ML training), где паузы не критичны, а важен throughput. ZGC жертвует 10-15% throughput ради low-latency из-за load barriers, concurrent GC threads и memory overhead. Parallel GC даёт 95%+ throughput с паузами 100-1000ms, которые для batch-задач несущественны.

> [!question]- Почему правило "heap = 3-4x live data" важно для производительности GC?
> GC копирует живые объекты из одной области в другую. Если live data 4GB, а heap 5GB, после копирования остаётся 1GB свободного пространства -- следующая сборка начнётся очень быстро. При heap 16GB (4x) между сборками достаточно пространства для аллокаций, и GC запускается редко. Правило обеспечивает баланс между расходом памяти и частотой GC.

---

## Ключевые карточки

Какие три основных GC доступны в Java 21 и для чего каждый?
?
G1GC (default, баланс пауз 50-200ms и throughput для 90% приложений), ZGC Generational (паузы <10ms, heap до 16TB, для low-latency), Parallel GC (максимум throughput 95%+, для batch processing). Для контейнеров <512MB -- Serial GC.

Что такое G1 regions и почему G1 называется "Garbage First"?
?
G1 разбивает heap на ~2048 небольших регионов (1-32MB). Каждый регион -- независимая единица сборки. G1 ведёт статистику мусора по каждому региону и собирает сначала самые "мусорные" (garbage first), чтобы уложиться в target pause time.

Что такое colored pointers в ZGC?
?
Метаданные о состоянии объекта, встроенные в свободные биты 64-bit указателя. Load barrier при каждом чтении проверяет "цвет" указателя: если объект перемещён, ссылка обновляется на лету (self-healing). Это позволяет ZGC делать concurrent compaction без stop-the-world.

Что такое Humongous objects в G1 и почему они проблематичны?
?
Объекты больше 50% размера региона. Занимают несколько смежных регионов, которые нельзя собрать частично. Сразу считаются "старыми". Если не удаётся найти смежные свободные регионы -- Full GC для дефрагментации. Решение: увеличить G1HeapRegionSize или рефакторить код.

Что такое SoftMaxHeapSize в ZGC и зачем он нужен?
?
Мягкий лимит heap для ZGC. ZGC старается не превышать его, но может при необходимости. Полезен для контейнеров: устанавливается на 80-90% от -Xmx, чтобы у ZGC был запас для пиковых нагрузок без OOM.

---

## Куда дальше

| Направление | Куда | Зачем |
|-------------|------|-------|
| Следующий шаг | [[jvm-profiling]] | Allocation profiling -- первый шаг перед GC tuning |
| Углубиться | [[jvm-benchmarking-jmh]] | Измерить эффект изменения GC параметров |
| Связанная тема | [[jvm-memory-model]] | Теоретический фундамент: heap structure, поколения, TLAB |
| Смежная область | [[garbage-collection-explained]] | GC в других языках и VM -- сравнение алгоритмов |
| Обзор | [[jvm-overview]] | Вернуться к карте раздела |

---

*Проверено: 2026-02-11 | Источники: Jones et al. (2011), Oaks (2020), Tene (2019), Netflix Tech Blog -- Педагогический контент проверен*
