# –õ–∞–Ω–¥—à–∞—Ñ—Ç LLM –º–æ–¥–µ–ª–µ–π 2025

> –ü–æ—Å–ª–µ–¥–Ω–µ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ: –î–µ–∫–∞–±—Ä—å 2024
> –ê–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö: Q4 2024 - Q1 2025

---

## Prerequisites

| –¢–µ–º–∞ | –ó–∞—á–µ–º –Ω—É–∂–Ω–æ | –ì–¥–µ –∏–∑—É—á–∏—Ç—å |
|------|-------------|-------------|
| **–ë–∞–∑–æ–≤–æ–µ –ø–æ–Ω–∏–º–∞–Ω–∏–µ LLM** | –ß—Ç–æ —Ç–∞–∫–æ–µ —Ç–æ–∫–µ–Ω—ã, –∫–æ–Ω—Ç–µ–∫—Å—Ç, inference | [[llm-fundamentals]] |
| **–¢–µ—Ä–º–∏–Ω–æ–ª–æ–≥–∏—è AI** | –ü–æ–Ω–∏–º–∞–Ω–∏–µ benchmark'–æ–≤, –º–µ—Ç—Ä–∏–∫ | [[ai-ml-overview-v2]] |

### –î–ª—è –∫–æ–≥–æ —ç—Ç–æ—Ç –º–∞—Ç–µ—Ä–∏–∞–ª

| –£—Ä–æ–≤–µ–Ω—å | –ü–æ–¥—Ö–æ–¥–∏—Ç? | –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è |
|---------|-----------|--------------|
| **–ù–æ–≤–∏—á–æ–∫ –≤ AI** | ‚úÖ –î–∞ | –û—Ç–ª–∏—á–Ω—ã–π –æ–±–∑–æ—Ä –¥–ª—è –ø–æ–Ω–∏–º–∞–Ω–∏—è —Ä—ã–Ω–∫–∞ |
| **AI Engineer** | ‚úÖ –î–∞ | –í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏ –ø–æ–¥ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –∑–∞–¥–∞—á–∏ |
| **Tech Lead** | ‚úÖ –î–∞ | –°—Ç—Ä–∞—Ç–µ–≥–∏—á–µ—Å–∫–æ–µ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ |
| **Product Manager** | ‚úÖ –î–∞ | –ü–æ–Ω–∏–º–∞–Ω–∏–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π –∏ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π |

### –¢–µ—Ä–º–∏–Ω–æ–ª–æ–≥–∏—è –¥–ª—è –Ω–æ–≤–∏—á–∫–æ–≤

> üí° **LLM Landscape** = –æ–±–∑–æ—Ä –≤—Å–µ—Ö –¥–æ—Å—Ç—É–ø–Ω—ã—Ö AI-–º–æ–¥–µ–ª–µ–π –∏ –∏—Ö –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π

| –¢–µ—Ä–º–∏–Ω | –ó–Ω–∞—á–µ–Ω–∏–µ | –ê–Ω–∞–ª–æ–≥–∏—è –¥–ª—è –Ω–æ–≤–∏—á–∫–∞ |
|--------|----------|---------------------|
| **Closed-source** | –ú–æ–¥–µ–ª—å –¥–æ—Å—Ç—É–ø–Ω–∞ —Ç–æ–ª—å–∫–æ —á–µ—Ä–µ–∑ API | **–ê—Ä–µ–Ω–¥–∞** ‚Äî –ø–æ–ª—å–∑—É–µ—à—å—Å—è, –Ω–æ –Ω–µ –≤–ª–∞–¥–µ–µ—à—å |
| **Open-weight** | –í–µ—Å–∞ –º–æ–¥–µ–ª–∏ –æ—Ç–∫—Ä—ã—Ç—ã –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è | **–ü–æ–∫—É–ø–∫–∞** ‚Äî –º–æ–∂–µ—à—å –∑–∞–ø—É—Å—Ç–∏—Ç—å —Å–∞–º |
| **Benchmark** | –¢–µ—Å—Ç –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π | **–≠–∫–∑–∞–º–µ–Ω** ‚Äî –∫—Ç–æ –ª—É—á—à–µ —Å–ø—Ä–∞–≤–ª—è–µ—Ç—Å—è —Å –∑–∞–¥–∞—á–∞–º–∏ |
| **Context Window** | –°–∫–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç–∞ –º–æ–¥–µ–ª—å "–≤–∏–¥–∏—Ç" | **–†–∞–±–æ—á–∞—è –ø–∞–º—è—Ç—å** ‚Äî —á–µ–º –±–æ–ª—å—à–µ, —Ç–µ–º –±–æ–ª—å—à–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ |
| **MMLU** | Massive Multitask Language Understanding | **–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π —Ç–µ—Å—Ç –∑–Ω–∞–Ω–∏–π** ‚Äî –æ—Ç –º–∞—Ç–µ–º–∞—Ç–∏–∫–∏ –¥–æ –∏—Å—Ç–æ—Ä–∏–∏ |
| **SWE-bench** | Benchmark –ø–æ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—é | **–≠–∫–∑–∞–º–µ–Ω –¥–ª—è –ø—Ä–æ–≥—Ä–∞–º–º–∏—Å—Ç–æ–≤** ‚Äî —Ä–µ—à–µ–Ω–∏–µ —Ä–µ–∞–ª—å–Ω—ã—Ö issue |
| **MoE** | Mixture of Experts | **–ö–æ–Ω—Å–∏–ª–∏—É–º** ‚Äî —Ä–∞–∑–Ω—ã–µ —ç–∫—Å–ø–µ—Ä—Ç—ã –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –∑–∞–¥–∞—á |
| **tok/s** | –¢–æ–∫–µ–Ω–æ–≤ –≤ —Å–µ–∫—É–Ω–¥—É | **–°–∫–æ—Ä–æ—Å—Ç—å –ø–µ—á–∞—Ç–∏** ‚Äî —Å–∫–æ–ª—å–∫–æ —Å–ª–æ–≤ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∑–∞ —Å–µ–∫—É–Ω–¥—É |
| **Input/Output pricing** | –¶–µ–Ω–∞ –∑–∞ –≤—Ö–æ–¥—è—â–∏–µ/–∏—Å—Ö–æ–¥—è—â–∏–µ —Ç–æ–∫–µ–Ω—ã | **–¢–∞—Ä–∏—Ñ** ‚Äî –ø–ª–∞—Ç–∏—à—å –∑–∞ –≤–æ–ø—Ä–æ—Å—ã –∏ –æ—Ç–≤–µ—Ç—ã –æ—Ç–¥–µ–ª—å–Ω–æ |

---

## –ó–∞—á–µ–º —ç—Ç–æ –Ω—É–∂–Ω–æ

### –ü—Ä–æ–±–ª–µ–º–∞: –≤—ã–±–æ—Ä –º–æ–¥–µ–ª–∏ –∫—Ä–∏—Ç–∏—á–µ–Ω –¥–ª—è —É—Å–ø–µ—Ö–∞ –ø—Ä–æ–µ–∫—Ç–∞

| –°–∏–º–ø—Ç–æ–º | –ü—Ä–∏—á–∏–Ω–∞ | –ü–æ—Å–ª–µ–¥—Å—Ç–≤–∏—è |
|---------|---------|-------------|
| –†–∞—Å—Ö–æ–¥—ã –Ω–∞ API –≤ 10x –≤—ã—à–µ —á–µ–º –Ω—É–∂–Ω–æ | –ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –≤—ã–±–æ—Ä –º–æ–¥–µ–ª–∏ –¥–ª—è –∑–∞–¥–∞—á–∏ | –ü—Ä–æ–µ–∫—Ç –Ω–µ—Ä–µ–Ω—Ç–∞–±–µ–ª–µ–Ω |
| –ö–∞—á–µ—Å—Ç–≤–æ –æ—Ç–≤–µ—Ç–æ–≤ –Ω–µ—É–¥–æ–≤–ª–µ—Ç–≤–æ—Ä–∏—Ç–µ–ª—å–Ω–æ–µ | –ú–æ–¥–µ–ª—å –Ω–µ –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è use case | –ü–ª–æ—Ö–æ–π UX, –∂–∞–ª–æ–±—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π |
| Latency >5 —Å–µ–∫—É–Ω–¥ | Overkill reasoning model –¥–ª—è –ø—Ä–æ—Å—Ç–æ–π –∑–∞–¥–∞—á–∏ | –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏ —É—Ö–æ–¥—è—Ç |
| –ö–æ–¥ —Å –±–∞–≥–∞–º–∏, –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–∏ | –£—Å—Ç–∞—Ä–µ–≤—à–∞—è –∏–ª–∏ —Å–ª–∞–±–∞—è –º–æ–¥–µ–ª—å | Technical debt, –ø–æ—Ç–µ—Ä—è –¥–æ–≤–µ—Ä–∏—è |

### –ö–∞–∫ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –≤—ã–±–æ—Ä –º–æ–¥–µ–ª–∏ —Ä–µ—à–∞–µ—Ç –ø—Ä–æ–±–ª–µ–º—ã

| –°—Ü–µ–Ω–∞—Ä–∏–π | –ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –≤—ã–±–æ—Ä | –ü—Ä–∞–≤–∏–ª—å–Ω—ã–π –≤—ã–±–æ—Ä |
|----------|-------------------|------------------|
| **–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —á–∞—Ç–∞** | GPT-4o ($2.50/M) | GPT-4o mini ($0.15/M) ‚Äî 16x —ç–∫–æ–Ω–æ–º–∏—è |
| **–°–ª–æ–∂–Ω—ã–π coding** | Claude Haiku | Claude Sonnet ‚Äî 77% SWE-bench |
| **–ú–∞—Ç–µ–º–∞—Ç–∏–∫–∞/reasoning** | GPT-4o | o1/o3 –∏–ª–∏ DeepSeek R1 |
| **–î–ª–∏–Ω–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã** | –ú–æ–¥–µ–ª—å —Å 8K context | Gemini/Claude —Å 1M+ context |
| **Budget-sensitive** | –ó–∞–∫—Ä—ã—Ç—ã–µ API | Llama/Qwen self-hosted ‚Äî 86% —ç–∫–æ–Ω–æ–º–∏—è |

---

## –û–≥–ª–∞–≤–ª–µ–Ω–∏–µ

1. [–í–≤–µ–¥–µ–Ω–∏–µ](#–≤–≤–µ–¥–µ–Ω–∏–µ)
2. [OpenAI](#openai)
3. [Anthropic](#anthropic)
4. [Google DeepMind](#google-deepmind)
5. [Meta AI](#meta-ai)
6. [DeepSeek](#deepseek)
7. [Mistral AI](#mistral-ai)
8. [Alibaba Qwen](#alibaba-qwen)
9. [–°—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ç–∞–±–ª–∏—Ü—ã](#—Å—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω—ã–µ-—Ç–∞–±–ª–∏—Ü—ã)
10. [–ö–æ–≥–¥–∞ –∫–∞–∫—É—é –º–æ–¥–µ–ª—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å](#–∫–æ–≥–¥–∞-–∫–∞–∫—É—é-–º–æ–¥–µ–ª—å-–∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å)
11. [–ò—Å—Ç–æ—á–Ω–∏–∫–∏](#–∏—Å—Ç–æ—á–Ω–∏–∫–∏)

---

## –í–≤–µ–¥–µ–Ω–∏–µ

2024-2025 –≥–æ–¥—ã —Å—Ç–∞–ª–∏ –ø–µ—Ä–µ–ª–æ–º–Ω—ã–º–∏ –¥–ª—è –∏–Ω–¥—É—Å—Ç—Ä–∏–∏ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π. –ú—ã –Ω–∞–±–ª—é–¥–∞–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ –∫–ª—é—á–µ–≤—ã—Ö —Ç—Ä–µ–Ω–¥–æ–≤:

**–ö–æ–Ω–≤–µ—Ä–≥–µ–Ω—Ü–∏—è –∫–∞—á–µ—Å—Ç–≤–∞**: –†–∞–∑—Ä—ã–≤ –º–µ–∂–¥—É –ª–∏–¥–µ—Ä–∞–º–∏ —Ä—ã–Ω–∫–∞ —Å—Ç—Ä–µ–º–∏—Ç–µ–ª—å–Ω–æ —Å–æ–∫—Ä–∞—â–∞–µ—Ç—Å—è. –ü–æ –¥–∞–Ω–Ω—ã–º Chatbot Arena, —Ä–∞–∑–Ω–∏—Ü–∞ –≤ Elo-—Ä–µ–π—Ç–∏–Ω–≥–µ –º–µ–∂–¥—É —Ç–æ–ø-10 –º–æ–¥–µ–ª—è–º–∏ —Å–æ–∫—Ä–∞—Ç–∏–ª–∞—Å—å —Å 11.9% –≤ 2023 –¥–æ 5.4% –≤ –Ω–∞—á–∞–ª–µ 2025 –≥–æ–¥–∞. –ö —Ñ–µ–≤—Ä–∞–ª—é 2025 —Ä–∞–∑—Ä—ã–≤ –º–µ–∂–¥—É –∞–º–µ—Ä–∏–∫–∞–Ω—Å–∫–∏–º–∏ –∏ –∫–∏—Ç–∞–π—Å–∫–∏–º–∏ –º–æ–¥–µ–ª—è–º–∏ —Å–æ–∫—Ä–∞—Ç–∏–ª—Å—è –¥–æ 1.70%.

**Reasoning-–º–æ–¥–µ–ª–∏**: –ü–æ—è–≤–∏–ª—Å—è –Ω–æ–≤—ã–π –∫–ª–∞—Å—Å –º–æ–¥–µ–ª–µ–π —Å "—Ü–µ–ø–æ—á–∫–æ–π —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π" (chain-of-thought) - OpenAI o1/o3, Gemini Flash Thinking, DeepSeek R1. –û–Ω–∏ —Ç—Ä–∞—Ç—è—Ç –±–æ–ª—å—à–µ –≤—Ä–µ–º–µ–Ω–∏ –Ω–∞ "—Ä–∞–∑–º—ã—à–ª–µ–Ω–∏—è" –ø–µ—Ä–µ–¥ –æ—Ç–≤–µ—Ç–æ–º, –∏—Å–ø–æ–ª—å–∑—É—è "simulated reasoning".

**–û—Ç–∫—Ä—ã—Ç—ã–π –∏—Å—Ö–æ–¥–Ω—ã–π –∫–æ–¥ –¥–æ–≥–æ–Ω—è–µ—Ç**: Open-source –º–æ–¥–µ–ª–∏ (DeepSeek, Llama, Qwen) –¥–æ—Å—Ç–∏–≥–ª–∏ –ø–∞—Ä–∏—Ç–µ—Ç–∞ —Å –∑–∞–∫—Ä—ã—Ç—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏ –ø–æ –º–Ω–æ–≥–∏–º –±–µ–Ω—á–º–∞—Ä–∫–∞–º, –ø—Ä–µ–¥–ª–∞–≥–∞—è 86% —ç–∫–æ–Ω–æ–º–∏–∏ –Ω–∞ –∑–∞—Ç—Ä–∞—Ç–∞—Ö –∏ 7.3x –ª—É—á—à—É—é —Ü–µ–Ω–æ–≤—É—é —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å.

**–í–∑—Ä—ã–≤–Ω–æ–π —Ä–æ—Å—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã—Ö –æ–∫–æ–Ω**: –û—Ç 4K —Ç–æ–∫–µ–Ω–æ–≤ ChatGPT –≤ 2022 –¥–æ 10M —Ç–æ–∫–µ–Ω–æ–≤ Llama 4 Scout –≤ 2025. –†–æ—Å—Ç –ø—Ä–∏–º–µ—Ä–Ω–æ 30x –≤ –≥–æ–¥. –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ —É–ª—É—á—à–∏–ª–æ—Å—å –µ—â—ë –±—ã—Å—Ç—Ä–µ–µ - 250x –∑–∞ 9 –º–µ—Å—è—Ü–µ–≤.

---

## OpenAI

### –ò—Å—Ç–æ—Ä–∏—è –∫–æ–º–ø–∞–Ω–∏–∏

OpenAI –±—ã–ª–∞ –æ—Å–Ω–æ–≤–∞–Ω–∞ –≤ 2015 –≥–æ–¥—É –∫–∞–∫ –Ω–µ–∫–æ–º–º–µ—Ä—á–µ—Å–∫–∞—è –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å—Å–∫–∞—è –ª–∞–±–æ—Ä–∞—Ç–æ—Ä–∏—è –°—ç–º–æ–º –ê–ª—å—Ç–º–∞–Ω–æ–º, –ò–ª–æ–Ω–æ–º –ú–∞—Å–∫–æ–º –∏ –¥—Ä—É–≥–∏–º–∏. –ü–µ—Ä–≤–æ–Ω–∞—á–∞–ª—å–Ω–∞—è –º–∏—Å—Å–∏—è - –æ–±–µ—Å–ø–µ—á–∏—Ç—å, —á—Ç–æ–±—ã AGI –ø—Ä–∏–Ω–æ—Å–∏–ª–∞ –ø–æ–ª—å–∑—É –≤—Å–µ–º—É —á–µ–ª–æ–≤–µ—á–µ—Å—Ç–≤—É.

**–ö–ª—é—á–µ–≤—ã–µ –≤–µ—Ö–∏:**
- **2018**: GPT-1 - –ø–µ—Ä–≤–∞—è –º–æ–¥–µ–ª—å —Å–µ—Ä–∏–∏
- **2020**: GPT-3 —Å 175B –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –ø—Ä–æ–∏–∑–≤–µ–ª —Ñ—É—Ä–æ—Ä
- **2022**: ChatGPT - —Å–∞–º–æ–µ –±—ã—Å—Ç—Ä–æ—Ä–∞—Å—Ç—É—â–µ–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –≤ –∏—Å—Ç–æ—Ä–∏–∏
- **2023**: GPT-4 - –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å
- **2024**: GPT-4o (omni) –≤ –º–∞–µ, o1-preview –≤ —Å–µ–Ω—Ç—è–±—Ä–µ, o3 –≤ –¥–µ–∫–∞–±—Ä–µ
- **2025**: GPT-5, o3, GPT-4.1

### –õ–∏–Ω–µ–π–∫–∞ –º–æ–¥–µ–ª–µ–π

#### GPT-4o ("Omni")

**–†–µ–ª–∏–∑**: –ú–∞–π 2024, –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –¥–µ–∫–∞–±—Ä—å 2024

**–•–∞—Ä–∞–∫—Ç–µ—Ä –º–æ–¥–µ–ª–∏**: –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç. GPT-4o - —ç—Ç–æ "—à–≤–µ–π—Ü–∞—Ä—Å–∫–∏–π –Ω–æ–∂" —Å—Ä–µ–¥–∏ LLM: –ø–æ–Ω–∏–º–∞–µ—Ç —Ç–µ–∫—Å—Ç, –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, –∞—É–¥–∏–æ –∏ –º–æ–∂–µ—Ç –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –æ—Ç–≤–µ—Ç—ã –≤–æ –≤—Å–µ—Ö —ç—Ç–∏—Ö –º–æ–¥–∞–ª—å–Ω–æ—Å—Ç—è—Ö. –û—â—É—â–∞–µ—Ç—Å—è –∫–∞–∫ –±—ã—Å—Ç—Ä—ã–π, —É–≤–µ—Ä–µ–Ω–Ω—ã–π —Å–æ–±–µ—Å–µ–¥–Ω–∏–∫.

**–ö–ª—é—á–µ–≤—ã–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏**:
- Context window: 128K —Ç–æ–∫–µ–Ω–æ–≤
- –°–∫–æ—Ä–æ—Å—Ç—å: ~110 —Ç–æ–∫–µ–Ω–æ–≤/—Å–µ–∫ (–≤ 3x –±—ã—Å—Ç—Ä–µ–µ GPT-4 Turbo)
- –í—Ä–µ–º—è –æ—Ç–∫–ª–∏–∫–∞ –Ω–∞ –∞—É–¥–∏–æ: 232-320 –º—Å (–∫–∞–∫ —É —á–µ–ª–æ–≤–µ–∫–∞)
- Knowledge cutoff: –ò—é–Ω—å 2024

**Benchmark –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è**:
- 88.7% –Ω–∞ MMLU (—É–ª—É—á—à–µ–Ω–∏–µ –Ω–∞ 2.2% vs GPT-4 Turbo)
- –ó–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã–µ —É–ª—É—á—à–µ–Ω–∏—è –Ω–∞ GPQA (–±–∏–æ–ª–æ–≥–∏—è, —Ñ–∏–∑–∏–∫–∞, —Ö–∏–º–∏—è)
- –ü—Ä–µ–≤–æ—Å—Ö–æ–¥–∏—Ç GPT-4 Turbo –Ω–∞ non-English —Ç–µ–∫—Å—Ç–∞—Ö

**–°–∏–ª—å–Ω—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã**:
- –ù–∞—Ç–∏–≤–Ω–∞—è –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–æ—Å—Ç—å (—Ç–µ–∫—Å—Ç + –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è + –∞—É–¥–∏–æ + –≤–∏–¥–µ–æ)
- –û—Ç–ª–∏—á–Ω–æ–µ —Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è–º
- Real-time voice conversations
- –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
- –û—á–∏—â–µ–Ω–Ω—ã–π frontend-–∫–æ–¥

**–°–ª–∞–±—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã**:
- –ù–∞ DROP benchmark (complex reasoning, arithmetic) GPT-4 Turbo –≤—Å—ë –µ—â—ë –ª—É—á—à–µ
- –ù–µ–∫–æ—Ç–æ—Ä—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏ –æ—Ç–º–µ—á–∞—é—Ç –ø—Ä–æ–±–ª–µ–º—ã —Å–æ —Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ–º –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è–º vs GPT-4 Turbo
- –•–∞—Ä–∞–∫—Ç–µ—Ä–Ω—ã–µ —Ñ—Ä–∞–∑—ã-–º–∞—Ä–∫–µ—Ä—ã AI-—Ç–µ–∫—Å—Ç–∞ ("in today's ever-changing landscape", "let's dive in")

**API Pricing (–∑–∞ 1M —Ç–æ–∫–µ–Ω–æ–≤)**:
| –¢–∏–ø | –¶–µ–Ω–∞ |
|-----|------|
| Input | $2.50 |
| Output | $10.00 |
| Cached Input | $1.25 |

#### GPT-4o mini

**–•–∞—Ä–∞–∫—Ç–µ—Ä**: –ë—ã—Å—Ç—Ä–∞—è –∏ –¥–µ—à–µ–≤–∞—è –≤–µ—Ä—Å–∏—è –¥–ª—è –ø—Ä–æ—Å—Ç—ã—Ö –∑–∞–¥–∞—á. –ò–¥–µ–∞–ª—å–Ω–∞ –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏, —á–∞—Ç-–±–æ—Ç–æ–≤ –ø–æ–¥–¥–µ—Ä–∂–∫–∏, –ø—Ä–æ—Å—Ç–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞.

**API Pricing**:
| –¢–∏–ø | –¶–µ–Ω–∞ |
|-----|------|
| Input | $0.15 |
| Output | $0.60 |

#### –°–µ—Ä–∏—è o1/o3 (Reasoning Models)

**–†–µ–ª–∏–∑**: o1-preview —Å–µ–Ω—Ç—è–±—Ä—å 2024, o1 GA –¥–µ–∫–∞–±—Ä—å 2024, o3 preview –¥–µ–∫–∞–±—Ä—å 2024, o3 GA –∞–ø—Ä–µ–ª—å 2025

**–•–∞—Ä–∞–∫—Ç–µ—Ä –º–æ–¥–µ–ª–∏**: "–ú—ã—Å–ª–∏—Ç–µ–ª–∏". –≠—Ç–∏ –º–æ–¥–µ–ª–∏ –Ω–µ —Å–ø–µ—à–∞—Ç —Å –æ—Ç–≤–µ—Ç–æ–º - –æ–Ω–∏ –±—É–∫–≤–∞–ª—å–Ω–æ "–¥—É–º–∞—é—Ç" –æ—Ç 5 —Å–µ–∫—É–Ω–¥ –¥–æ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –º–∏–Ω—É—Ç, —Ä–∞–∑–±–∏–≤–∞—è –∑–∞–¥–∞—á—É –Ω–∞ —à–∞–≥–∏, –ø—Ä–æ–≤–µ—Ä—è—è —Å–µ–±—è, –º–µ–Ω—è—è –ø–æ–¥—Ö–æ–¥—ã. –≠—Ç–æ –Ω–µ –±–∞–≥, –∞ —Ñ–∏—á–∞.

**–ö–∞–∫ —ç—Ç–æ —Ä–∞–±–æ—Ç–∞–µ—Ç**: –ú–æ–¥–µ–ª–∏ –∏—Å–ø–æ–ª—å–∑—É—é—Ç "reasoning tokens" –ø–æ–º–∏–º–æ input/output —Ç–æ–∫–µ–Ω–æ–≤. –ü–æ—Å–ª–µ –ø–æ–ª—É—á–µ–Ω–∏—è –ø—Ä–æ–º–ø—Ç–∞ –º–æ–¥–µ–ª—å –ø–µ—Ä–µ—Å–ø—Ä–∞—à–∏–≤–∞–µ—Ç —Å–µ–±—è, —Ä–∞–∑–±–∏–≤–∞–µ—Ç –ø—Ä–æ–±–ª–µ–º—É –Ω–∞ —à–∞–≥–∏. –≠—Ç–æ—Ç –ø—Ä–æ—Ü–µ—Å—Å –Ω–∞–∑—ã–≤–∞–µ—Ç—Å—è "simulated reasoning" –∏–ª–∏ "chain-of-thought", –Ω–æ –±–æ–ª–µ–µ –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π - —Å self-analysis –∏ reflection.

**–ö–ª—é—á–µ–≤—ã–µ –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è o3**:
- 87.7% –Ω–∞ GPQA Diamond (—ç–∫—Å–ø–µ—Ä—Ç–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã –ø–æ –Ω–∞—É–∫–µ)
- 71.7% –Ω–∞ SWE-bench Verified (—Ä–µ—à–µ–Ω–∏–µ —Ä–µ–∞–ª—å–Ω—ã—Ö GitHub issues) vs 48.9% —É o1
- 2727 Elo –Ω–∞ Codeforces (o1 –∏–º–µ–ª 1891)
- –ü–µ—Ä–≤–∞—è –º–æ–¥–µ–ª—å, –ø—Ä–µ–æ–¥–æ–ª–µ–≤—à–∞—è 85% –Ω–∞ ARC AGI —Ç–µ—Å—Ç–µ

**Deliberative Alignment**: OpenAI –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–∞ –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ - –º–æ–¥–µ–ª–∏ o1 –∏ o3 "–¥—É–º–∞—é—Ç" –æ safety policy OpenAI –≤–æ –≤—Ä–µ–º—è inference.

**–ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å**:
- –°–ª–æ–∂–Ω—ã–µ –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –∑–∞–¥–∞—á–∏
- –ù–∞—É—á–Ω—ã–π –∞–Ω–∞–ª–∏–∑
- Multi-step coding problems
- –ü–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –∞–≥–µ–Ω—Ç–Ω—ã—Ö workflow

**API Pricing (o1)**:
| –¢–∏–ø | –¶–µ–Ω–∞ |
|-----|------|
| Input | $15.00 |
| Output | $60.00 |

#### GPT-5

**–†–µ–ª–∏–∑**: 2025

**–•–∞—Ä–∞–∫—Ç–µ—Ä**: –ù–æ–≤—ã–π —Ñ–ª–∞–≥–º–∞–Ω –¥–ª—è —Å–ª–æ–∂–Ω—ã—Ö reasoning-–∑–∞–¥–∞—á –∏ –∞–≥–µ–Ω—Ç–Ω—ã—Ö workflow. –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –¥–ª—è high-accuracy reasoning, coding, –∏ agentic workflows.

**API Pricing**:
| –¢–∏–ø | –¶–µ–Ω–∞ |
|-----|------|
| Input | $1.25 |
| Output | $10.00 |

### –û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ —ç–∫–æ—Å–∏—Å—Ç–µ–º—ã OpenAI

- **ChatGPT Plus**: $20/–º–µ—Å—è—Ü - –¥–æ—Å—Ç—É–ø –∫ GPT-4o, o1, DALL-E, –±—Ä–∞—É–∑–∏–Ω–≥
- **API**: Pay-as-you-go, Batch API —Å–æ —Å–∫–∏–¥–∫–æ–π 50%
- **Custom GPTs**: –°–æ–∑–¥–∞–Ω–∏–µ —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–æ–≤
- **Assistants API**: Function calling, file search, code interpreter
- **Realtime API**: –î–ª—è –≥–æ–ª–æ—Å–æ–≤—ã—Ö –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π (8 –≥–æ–ª–æ—Å–æ–≤: alloy, ash, ballad, coral, echo, sage, shimmer, verse)
- **Web Search Tool**: –û—Ç–¥–µ–ª—å–Ω–∞—è —Ç–∞—Ä–∏—Ñ–∏–∫–∞—Ü–∏—è per 1000 calls + search content tokens

---

## Anthropic

### –ò—Å—Ç–æ—Ä–∏—è –∫–æ–º–ø–∞–Ω–∏–∏

Anthropic –±—ã–ª–∞ –æ—Å–Ω–æ–≤–∞–Ω–∞ –≤ 2021 –≥–æ–¥—É –±—ã–≤—à–∏–º–∏ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞–º–∏ OpenAI, –≤–∫–ª—é—á–∞—è –î–∞—Ä–∏–æ –∏ –î–∞–Ω–∏—ç–ª—É –ê–º–æ–¥–µ–π. –ö–æ–º–ø–∞–Ω–∏—è –ø–æ–∑–∏—Ü–∏–æ–Ω–∏—Ä—É–µ—Ç —Å–µ–±—è –∫–∞–∫ "AI safety company" - –æ–Ω–∏ –≤–µ—Ä—è—Ç, —á—Ç–æ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –≤—Å—Ç—Ä–æ–µ–Ω–∞ –≤ –º–æ–¥–µ–ª–∏ —Å —Å–∞–º–æ–≥–æ –Ω–∞—á–∞–ª–∞.

–ö–ª—é—á–µ–≤–æ–π –ø–æ–¥—Ö–æ–¥ - Constitutional AI: –º–æ–¥–µ–ª—å –æ–±—É—á–∞–µ—Ç—Å—è —Å–ª–µ–¥–æ–≤–∞—Ç—å –Ω–∞–±–æ—Ä—É –ø—Ä–∏–Ω—Ü–∏–ø–æ–≤ (–∫–æ–Ω—Å—Ç–∏—Ç—É—Ü–∏–∏), —á—Ç–æ —Å–Ω–∏–∂–∞–µ—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç—å –≤ —á–µ–ª–æ–≤–µ—á–µ—Å–∫–æ–π —Ä–∞–∑–º–µ—Ç–∫–µ –∏ –¥–µ–ª–∞–µ—Ç –ø–æ–≤–µ–¥–µ–Ω–∏–µ –±–æ–ª–µ–µ –ø—Ä–µ–¥—Å–∫–∞–∑—É–µ–º—ã–º. –ú–æ–¥–µ–ª–∏ –ø—Ä–æ—Ö–æ–¥—è—Ç –Ω–µ–∑–∞–≤–∏—Å–∏–º—É—é –æ—Ü–µ–Ω–∫—É UK AISI (Artificial Intelligence Safety Institute) –ø–µ—Ä–µ–¥ —Ä–µ–ª–∏–∑–æ–º.

### –õ–∏–Ω–µ–π–∫–∞ –º–æ–¥–µ–ª–µ–π Claude

#### Claude 3.5 Sonnet

**–†–µ–ª–∏–∑**: –ò—é–Ω—å 2024 (–ø–µ—Ä–≤–∞—è –≤–µ—Ä—Å–∏—è), –û–∫—Ç—è–±—Ä—å 2024 (–æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ)

**–•–∞—Ä–∞–∫—Ç–µ—Ä –º–æ–¥–µ–ª–∏**: –ï—Å–ª–∏ GPT-4o - —ç—Ç–æ —ç–Ω–µ—Ä–≥–∏—á–Ω—ã–π —É–Ω–∏–≤–µ—Ä—Å–∞–ª, —Ç–æ Claude 3.5 Sonnet - –≤–¥—É–º—á–∏–≤—ã–π —ç–∫—Å–ø–µ—Ä—Ç. –û–Ω –ø–∏—à–µ—Ç –±–æ–ª–µ–µ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã–º —è–∑—ã–∫–æ–º, –ª—É—á—à–µ –ø–æ–Ω–∏–º–∞–µ—Ç –Ω—é–∞–Ω—Å—ã –∏ —é–º–æ—Ä, —Ä–µ–∂–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –∫–ª–∏—à–µ. –û—Å–æ–±–µ–Ω–Ω–æ —Ö–æ—Ä–æ—à –¥–ª—è –¥–ª–∏–Ω–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤ –∏ –∫–æ–¥–∞.

**–ö–ª—é—á–µ–≤—ã–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏**:
- Context window: 200K —Ç–æ–∫–µ–Ω–æ–≤ (–¥–æ 1M –≤ long-context mode)
- –°–∫–æ—Ä–æ—Å—Ç—å: 2x –±—ã—Å—Ç—Ä–µ–µ Claude 3 Opus
- –õ—É—á—à–∞—è vision-–º–æ–¥–µ–ª—å –≤ –ª–∏–Ω–µ–π–∫–µ

**Benchmark –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è**:
- 64% –Ω–∞ agentic coding evaluation (Opus - 38%)
- 49% –Ω–∞ SWE-bench Verified (–æ–±–Ω–æ–≤–ª–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è, —Ä–∞–Ω–µ–µ 33.4%)
- –ü—Ä–µ–≤–æ—Å—Ö–æ–¥–∏—Ç Claude 3 Opus –Ω–∞ GPQA (graduate-level reasoning)
- –õ–∏–¥–µ—Ä –ø–æ MMLU, HumanEval

**Computer Use (–æ–∫—Ç—è–±—Ä—å 2024)**: –ü–µ—Ä–≤–∞—è frontier-–º–æ–¥–µ–ª—å —Å –ø—É–±–ª–∏—á–Ω—ã–º –±–µ—Ç–∞-–¥–æ—Å—Ç—É–ø–æ–º –∫ "–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é –∫–æ–º–ø—å—é—Ç–µ—Ä–∞" - Claude –º–æ–∂–µ—Ç —Å–º–æ—Ç—Ä–µ—Ç—å –Ω–∞ —ç–∫—Ä–∞–Ω, –¥–≤–∏–≥–∞—Ç—å –∫—É—Ä—Å–æ—Ä, –∫–ª–∏–∫–∞—Ç—å, –ø–µ—á–∞—Ç–∞—Ç—å. –ù–∞–ø—Ä–∞–≤–ª—è—Ç—å –º–æ–¥–µ–ª—å –º–æ–∂–Ω–æ —á–µ—Ä–µ–∑ API.

**Artifacts**: –î–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–µ —Ä–∞–±–æ—á–µ–µ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ –Ω–∞ claude.ai - –∫–æ–¥, –¥–æ–∫—É–º–µ–Ω—Ç—ã, –¥–∏–∑–∞–π–Ω—ã –ø–æ—è–≤–ª—è—é—Ç—Å—è –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –æ–∫–Ω–µ —Ä—è–¥–æ–º —Å —á–∞—Ç–æ–º. –ú–æ–∂–Ω–æ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞—Ç—å –∏ —Ä–∞–∑–≤–∏–≤–∞—Ç—å –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏.

**API Pricing (–∑–∞ 1M —Ç–æ–∫–µ–Ω–æ–≤)**:
| –¢–∏–ø | –¶–µ–Ω–∞ |
|-----|------|
| Input | $3.00 |
| Output | $15.00 |
| Long-context (>200K) Input | $6.00 |
| Long-context Output | $22.50 |

#### Claude Opus 4.5

**–†–µ–ª–∏–∑**: 2025

**–•–∞—Ä–∞–∫—Ç–µ—Ä**: –°–∞–º–∞—è —É–º–Ω–∞—è –º–æ–¥–µ–ª—å Anthropic. –î–ª—è –∑–∞–¥–∞—á, –≥–¥–µ –∫–∞—á–µ—Å—Ç–≤–æ –≤–∞–∂–Ω–µ–µ —Å–∫–æ—Ä–æ—Å—Ç–∏ –∏ —Å—Ç–æ–∏–º–æ—Å—Ç–∏.

**API Pricing**:
| –¢–∏–ø | –¶–µ–Ω–∞ |
|-----|------|
| Input | $5.00 |
| Output | $25.00 |

#### Claude 4.1 Opus (Flagship)

**API Pricing**:
| –¢–∏–ø | –¶–µ–Ω–∞ |
|-----|------|
| Input | $20.00 |
| Output | $80.00 |
| Thinking | $40.00 |

#### Claude Haiku

**–•–∞—Ä–∞–∫—Ç–µ—Ä**: –°–∞–º–∞—è –±—ã—Å—Ç—Ä–∞—è –∏ –¥–µ—à–µ–≤–∞—è. –î–ª—è –≤—ã—Å–æ–∫–æ–Ω–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π, –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏, –ø—Ä–æ—Å—Ç—ã—Ö —á–∞—Ç-–±–æ—Ç–æ–≤.

**API Pricing**:
| –¢–∏–ø | –¶–µ–Ω–∞ |
|-----|------|
| Input | $0.25 |
| Output | $1.25 |

### Extended Thinking

**–ß—Ç–æ —ç—Ç–æ**: –ê–Ω–∞–ª–æ–≥ o1 reasoning –æ—Ç Anthropic, –¥–æ—Å—Ç—É–ø–Ω—ã–π –≤ Claude 3.7 Sonnet –∏ Claude 4.

**–ö–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç**:
- –í–∫–ª—é—á–∞–µ—Ç—Å—è —á–µ—Ä–µ–∑ `thinking` object —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–º `budget_tokens`
- –ú–∏–Ω–∏–º—É–º 1024 —Ç–æ–∫–µ–Ω–æ–≤, —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –Ω–∞—á–∏–Ω–∞—Ç—å —Å –º–∏–Ω–∏–º—É–º–∞ –∏ —É–≤–µ–ª–∏—á–∏–≤–∞—Ç—å
- Claude –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç hidden chain-of-thought (scratchpad), –∑–∞—Ç–µ–º –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –µ–≥–æ –¥–ª—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞
- –≠—Ç–æ –ù–ï –æ—Ç–¥–µ–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å - —Ç–∞ –∂–µ –º–æ–¥–µ–ª—å Claude –ø—Ä–æ—Å—Ç–æ –º–æ–∂–µ—Ç "–¥—É–º–∞—Ç—å –¥–æ–ª—å—à–µ"
- Hybrid —Ä–µ–∂–∏–º: –º–æ–¥–µ–ª—å –º–æ–∂–µ—Ç –ø–µ—Ä–µ–∫–ª—é—á–∞—Ç—å—Å—è –º–µ–∂–¥—É –±—ã—Å—Ç—Ä—ã–º–∏ –æ—Ç–≤–µ—Ç–∞–º–∏ –∏ extended thinking –≤ —Ä–∞–º–∫–∞—Ö –æ–¥–Ω–æ–≥–æ —Ä–∞–∑–≥–æ–≤–æ—Ä–∞

**–†–µ–∑—É–ª—å—Ç–∞—Ç—ã**:
- 80% –Ω–∞ AIME 2024 (–ø—Ä–∏ 64K thinking budget, parallel mode)
- 96.2% –Ω–∞ MATH 500
- 84.8% –Ω–∞ GPQA overall, 96.5% –Ω–∞ GPQA Physics
- –¢–æ—á–Ω–æ—Å—Ç—å —Ä–∞—Å—Ç—ë—Ç –ª–æ–≥–∞—Ä–∏—Ñ–º–∏—á–µ—Å–∫–∏ —Å —É–≤–µ–ª–∏—á–µ–Ω–∏–µ–º thinking budget

**–í–∞–∂–Ω–æ**: Thinking-—Ç–æ–∫–µ–Ω—ã –≤–∏–¥–Ω—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é –≤ —Å—ã—Ä–æ–º –≤–∏–¥–µ - —ç—Ç–æ –ø–æ–≤—ã—à–∞–µ—Ç –¥–æ–≤–µ—Ä–∏–µ –∏ –ø–æ–º–æ–≥–∞–µ—Ç –ø–æ–Ω—è—Ç—å –ª–æ–≥–∏–∫—É –º–æ–¥–µ–ª–∏. –ù–µ summaries, –∞ —Ä–µ–∞–ª—å–Ω—ã–π internal reasoning.

### –û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ Anthropic

- **–ù–µ—Ç –±–µ—Å–ø–ª–∞—Ç–Ω–æ–≥–æ API** - —Ç–æ–ª—å–∫–æ –ø–ª–∞—Ç–Ω—ã–π –¥–æ—Å—Ç—É–ø
- **Batch API**: –°–∫–∏–¥–∫–∞ 50% –¥–ª—è –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
- **Code Execution Tool**: 1,550 –±–µ—Å–ø–ª–∞—Ç–Ω—ã—Ö —á–∞—Å–æ–≤/–º–µ—Å—è—Ü, –∑–∞—Ç–µ–º $0.05/—á–∞—Å
- **–î–æ—Å—Ç—É–ø —á–µ—Ä–µ–∑**: Anthropic API, Amazon Bedrock, Google Vertex AI
- **Claude.ai**: –ë–µ—Å–ø–ª–∞—Ç–Ω—ã–π –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å —Å –ª–∏–º–∏—Ç–∞–º–∏, Claude Pro –∏ Team –¥–ª—è higher rate limits
- **Usage tiers**: Caps –Ω–∞ monthly spend, rate limits –Ω–∞ requests/minute –∏ tokens/day

---

## Google DeepMind

### –ò—Å—Ç–æ—Ä–∏—è

Google DeepMind –æ–±—Ä–∞–∑–æ–≤–∞–ª—Å—è –≤ 2023 –≥–æ–¥—É –∏–∑ —Å–ª–∏—è–Ω–∏—è Google Brain –∏ DeepMind. –ö–æ–º–ø–∞–Ω–∏—è –∏–º–µ–µ—Ç –æ–≥—Ä–æ–º–Ω—ã–µ –≤—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω—ã–µ —Ä–µ—Å—É—Ä—Å—ã –∏ –¥–æ—Å—Ç—É–ø –∫ –¥–∞–Ω–Ω—ã–º –≤—Å–µ–≥–æ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–∞ —á–µ—Ä–µ–∑ –ø–æ–∏—Å–∫ Google. Transformer architecture, –Ω–∞ –∫–æ—Ç–æ—Ä–æ–π –ø–æ—Å—Ç—Ä–æ–µ–Ω—ã –í–°–ï —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ LLM, –±—ã–ª–∞ –∏–∑–æ–±—Ä–µ—Ç–µ–Ω–∞ –≤ Google.

–ü–æ—Å–ª–µ –Ω–µ—É–¥–∞—á–Ω–æ–≥–æ —Å—Ç–∞—Ä—Ç–∞ —Å Bard, Google –Ω–∞–Ω—ë—Å –æ—Ç–≤–µ—Ç–Ω—ã–π —É–¥–∞—Ä —Å Gemini 2.0 –∏ 2.5, –∫–æ—Ç–æ—Ä—ã–µ –≤–æ–∑–≥–ª–∞–≤–∏–ª–∏ LMArena leaderboard.

### –õ–∏–Ω–µ–π–∫–∞ Gemini

#### Gemini 2.0 Flash

**–†–µ–ª–∏–∑**: –î–µ–∫–∞–±—Ä—å 2024 (experimental), –§–µ–≤—Ä–∞–ª—å 2025 (GA)

**–•–∞—Ä–∞–∫—Ç–µ—Ä –º–æ–¥–µ–ª–∏**: –ë—ã—Å—Ç—Ä—ã–π –∏ —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π. Gemini 2.0 Flash —Å–æ–∑–¥–∞–Ω –¥–ª—è "agentic era" - –æ–Ω —É–º–µ–µ—Ç –Ω–µ –ø—Ä–æ—Å—Ç–æ –æ—Ç–≤–µ—á–∞—Ç—å, –∞ –≤—ã–ø–æ–ª–Ω—è—Ç—å multi-step –∑–∞–¥–∞—á–∏ –∞–≤—Ç–æ–Ω–æ–º–Ω–æ.

**–ö–ª—é—á–µ–≤—ã–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏**:
- Context window: 1M —Ç–æ–∫–µ–Ω–æ–≤
- Outperforms Gemini 1.5 Pro –Ω–∞ key benchmarks –ø—Ä–∏ 2x —Å–∫–æ—Ä–æ—Å—Ç–∏
- –ù–∞—Ç–∏–≤–Ω–∞—è –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–æ—Å—Ç—å: —Ç–µ–∫—Å—Ç, –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, –≤–∏–¥–µ–æ, –∞—É–¥–∏–æ –Ω–∞ –≤—Ö–æ–¥–µ –ò –≤—ã—Ö–æ–¥–µ
- –í—Å—Ç—Ä–æ–µ–Ω–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã: Google Search, Maps, code execution

**–£–Ω–∏–∫–∞–ª—å–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏**:
- **Multimodal Live API**: Real-time –∞—É–¥–∏–æ –∏ –≤–∏–¥–µ–æ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–µ
- **Native image generation**: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –ø—Ä—è–º–æ –≤ –æ—Ç–≤–µ—Ç–µ —Å watermarking
- **Text-to-speech**: –ö–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É–µ–º–∞—è –º–Ω–æ–≥–æ—è–∑—ã—á–Ω–∞—è –æ–∑–≤—É—á–∫–∞ (steerable TTS)
- **Deep Research**: AI-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –¥–ª—è –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–π, —Å–æ–∑–¥–∞—é—â–∏–π –æ—Ç—á–µ—Ç—ã –∏—Å–ø–æ–ª—å–∑—É—è advanced reasoning –∏ long context
- **Jules**: –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω—ã–π AI coding agent –¥–ª—è GitHub

#### Gemini 2.0 Flash Thinking

**–†–µ–ª–∏–∑**: –î–µ–∫–∞–±—Ä—å 2024

**–•–∞—Ä–∞–∫—Ç–µ—Ä**: Reasoning-–≤–µ—Ä—Å–∏—è Flash —Å advanced reasoning capabilities. –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∑–∞–¥–∞—á–∏, –¥—É–º–∞–µ—Ç –Ω–∞ –Ω–µ—Å–∫–æ–ª—å–∫–æ —à–∞–≥–æ–≤ –≤–ø–µ—Ä–µ–¥. –ü—Ä–µ–≤–æ—Å—Ö–æ–¥–∏—Ç OpenAI o1 –Ω–∞ –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö –±–µ–Ω—á–º–∞—Ä–∫–∞—Ö –ø—Ä–∏ –º–µ–Ω—å—à–∏—Ö –∑–∞—Ç—Ä–∞—Ç–∞—Ö.

#### Gemini 2.5 Pro

**–†–µ–ª–∏–∑**: 2025

**–•–∞—Ä–∞–∫—Ç–µ—Ä**: Thinking-–º–æ–¥–µ–ª—å —Å –ª—É—á—à–∏–º –±–∞–ª–∞–Ω—Å–æ–º –∫–∞—á–µ—Å—Ç–≤–∞ –∏ —Å—Ç–æ–∏–º–æ—Å—Ç–∏. –ò–∑–Ω–∞—á–∞–ª—å–Ω–æ designed –∫–∞–∫ thinking model.

**–ö–ª—é—á–µ–≤—ã–µ –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è**:
- #1 –Ω–∞ LMArena leaderboard (—Å –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã–º –æ—Ç—Ä—ã–≤–æ–º)
- 18.8% –Ω–∞ Humanity's Last Exam
- 63.8% –Ω–∞ SWE-bench Verified
- Context window: 1M —Ç–æ–∫–µ–Ω–æ–≤ (2M –≤ –ø–ª–∞–Ω–∞—Ö)
- Knowledge cutoff: –Ø–Ω–≤–∞—Ä—å 2025 (–Ω–∞ 7 –º–µ—Å—è—Ü–µ–≤ —Å–≤–µ–∂–µ–µ GPT-4o)

**–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ –Ω–∞–¥ GPT-4o**:
- –õ—É—á—à–µ —Å –≤–∏–¥–µ–æ, –¥–æ–∫—É–º–µ–Ω—Ç–∞–º–∏ –∏ –¥–ª–∏–Ω–Ω—ã–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º
- –ù–∞—Ç–∏–≤–Ω–∞—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å Google Workspace
- –î–µ—à–µ–≤–ª–µ –ø—Ä–∏ —Å—Ä–∞–≤–Ω–∏–º–æ–º –∫–∞—á–µ—Å—Ç–≤–µ

**API Pricing (Gemini 2.5 Pro)**:
| –ö–æ–Ω—Ç–µ–∫—Å—Ç | Input | Output |
|----------|-------|--------|
| –î–æ 128K | $1.25 | $5.00 |
| –ë–æ–ª–µ–µ 128K | $2.50 | $10.00 |

### Google AI Studio

**–ë–µ—Å–ø–ª–∞—Ç–Ω—ã–π tier**: –ü–æ–ª–Ω–æ—Ü–µ–Ω–Ω–∞—è –ø–µ—Å–æ—á–Ω–∏—Ü–∞ –¥–ª—è —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤. –í–∞–∂–Ω–æ: –¥–∞–Ω–Ω—ã–µ –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π –Ω–∞ –±–µ—Å–ø–ª–∞—Ç–Ω–æ–º –ø–ª–∞–Ω–µ.

**Pay-as-you-go**: –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ Cloud Billing –¥–ª—è production-–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è. –î–∞–Ω–Ω—ã–µ –ù–ï –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –¥–ª—è –æ–±—É—á–µ–Ω–∏—è.

**Tiering system**: Free -> Tier 1 -> Tier 2 -> Tier 3 (based on cumulative spending)

**–û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏**:
- Screen sharing —Å AI –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏
- –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –±–µ—Å–ø–ª–∞—Ç–Ω–æ
- –í–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –æ—Ç–∫–ª—é—á–µ–Ω–∏—è safety filters
- Gemini 3 Flash –¥–æ—Å—Ç—É–ø–µ–Ω –¥–ª—è –±–µ—Å–ø–ª–∞—Ç–Ω–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è

**Image Output Pricing**:
- $120 / 1M tokens
- 1024x1024px (1K) to 2048x2048px (2K): ~$0.134/image
- Up to 4096x4096px (4K): ~$0.24/image

**–ü–æ–¥–ø–∏—Å–∫–∏ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π**:
- **Google AI Pro**: –î–æ—Å—Ç—É–ø –∫ 3 Pro, Deep Research, 1M context
- **Google AI Ultra**: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ + Veo 3.1 Fast video

---

## Meta AI

### –ò—Å—Ç–æ—Ä–∏—è –∏ —Ñ–∏–ª–æ—Å–æ—Ñ–∏—è

Meta (–±—ã–≤—à–∏–π Facebook) –≤—ã–±—Ä–∞–ª–∞ —É–Ω–∏–∫–∞–ª—å–Ω—É—é —Å—Ç—Ä–∞—Ç–µ–≥–∏—é - open-source. –ú–∞—Ä–∫ –¶—É–∫–µ—Ä–±–µ—Ä–≥ —Å—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç —ç—Ç–æ —Å —Ç–µ–º, –∫–∞–∫ Linux —Å—Ç–∞–ª —Å—Ç–∞–Ω–¥–∞—Ä—Ç–æ–º –¥–ª—è cloud –∏ mobile.

**–í—ã–≥–æ–¥–∞ –¥–ª—è Meta:**
1. –°–æ–æ–±—â–µ—Å—Ç–≤–æ —É–ª—É—á—à–∞–µ—Ç –º–æ–¥–µ–ª–∏ –±–µ—Å–ø–ª–∞—Ç–Ω–æ
2. –ò–Ω–¥—É—Å—Ç—Ä–∏—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∏—Ä—É–µ—Ç—Å—è –≤–æ–∫—Ä—É–≥ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã Llama
3. –°–Ω–∏–∂–µ–Ω–∏–µ –∑–∞—Ç—Ä–∞—Ç —á–µ—Ä–µ–∑ —ç–∫–æ–Ω–æ–º–∏—é –º–∞—Å—à—Ç–∞–±–∞ - inference –Ω–∞ Llama 3.1 –ø—Ä–∏–º–µ—Ä–Ω–æ 50% –¥–µ—à–µ–≤–ª–µ closed –º–æ–¥–µ–ª–µ–π —Ç–∏–ø–∞ GPT-4o
4. –ü–æ —Å–ª–æ–≤–∞–º –¶—É–∫–µ—Ä–±–µ—Ä–≥–∞, open-source –ø–æ–∑–≤–æ–ª—è–µ—Ç "incorporate improvements back into Llama and products"

**–ú–∞—Å—à—Ç–∞–±**: 650+ –º–∏–ª–ª–∏–æ–Ω–æ–≤ —Å–∫–∞—á–∏–≤–∞–Ω–∏–π Llama, ~1 –º–∏–ª–ª–∏–æ–Ω —Å–∫–∞—á–∏–≤–∞–Ω–∏–π –≤ –¥–µ–Ω—å. Meta AI –Ω–∞ –ø—É—Ç–∏ —Å—Ç–∞—Ç—å —Å–∞–º—ã–º –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–º AI-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–æ–º —Å –ø–æ—á—Ç–∏ 600 –º–∏–ª–ª–∏–æ–Ω–∞–º–∏ MAU –∫ –∫–æ–Ω—Ü—É 2024.

### –õ–∏–Ω–µ–π–∫–∞ Llama

#### Llama 3.3 70B

**–†–µ–ª–∏–∑**: –î–µ–∫–∞–±—Ä—å 2024

**–•–∞—Ä–∞–∫—Ç–µ—Ä –º–æ–¥–µ–ª–∏**: –õ—É—á—à–µ–µ —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞ –∏ —Ä–∞–∑–º–µ—Ä–∞. –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å—Ä–∞–≤–Ω–∏–º–∞—è —Å Llama 3.1 405B –ø—Ä–∏ ~17% –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤.

**–ö–ª—é—á–µ–≤—ã–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏**:
- –ü–∞—Ä–∞–º–µ—Ç—Ä—ã: 70B
- Context window: 128K —Ç–æ–∫–µ–Ω–æ–≤
- –õ–∏—Ü–µ–Ω–∑–∏—è: Llama 3.3 Community License

**Benchmark —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã**:
- 92.1 –Ω–∞ IFEval (—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è–º) - –ª—É—á—à–µ Llama 3.1 405B (88.6), GPT-4o (84.6), –±–ª–∏–∑–∫–æ –∫ Claude 3.5 Sonnet (89.3)
- 86.0 –Ω–∞ MMLU (0-shot, CoT)
- 88.4 –Ω–∞ HumanEval (–∫–æ–¥)
- 77.0 –Ω–∞ MATH (0-shot, CoT) - –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ vs Llama 3.1 70B (67.8)
- 91.1 –Ω–∞ MGSM (–º—É–ª—å—Ç–∏—è–∑—ã—á–Ω–æ—Å—Ç—å) - –±–ª–∏–∑–∫–æ –∫ Claude 3.5 Sonnet (92.8)
- 50.5 –Ω–∞ GPQA Diamond - –Ω–µ–º–Ω–æ–≥–æ –ø–æ–∑–∞–¥–∏ Claude 3.5 Sonnet (65.0)

**–ò–Ω—Ñ–µ—Ä–µ–Ω—Å**: –î–æ 276 —Ç–æ–∫–µ–Ω–æ–≤/—Å–µ–∫ –Ω–∞ Groq - —Å–∞–º—ã–π –±—ã—Å—Ç—Ä—ã–π –ø—Ä–æ–≤–∞–π–¥–µ—Ä.

**–°—Ç–æ–∏–º–æ—Å—Ç—å**: 88% –¥–µ—à–µ–≤–ª–µ –≤ —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–∏ —á–µ–º Llama 3.1 405B.

#### Llama 4 Scout

**–†–µ–ª–∏–∑**: –ê–ø—Ä–µ–ª—å 2025

**–•–∞—Ä–∞–∫—Ç–µ—Ä**: –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞—è –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å –¥–ª—è edge-—Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è. –ü–µ—Ä–≤–∞—è open-weight natively multimodal –º–æ–¥–µ–ª—å.

**–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞**:
- MoE (Mixture of Experts): 109B total / 17B active –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
- 16 —ç–∫—Å–ø–µ—Ä—Ç–æ–≤, 1 —ç–∫—Å–ø–µ—Ä—Ç –∞–∫—Ç–∏–≤–µ–Ω –Ω–∞ —Ç–æ–∫–µ–Ω
- Early fusion multimodality
- Interleaved global attention (–±–µ–∑ RoPE) –∏ chunked local attention (—Å RoPE) –≤ —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–∏ 1:3
- –ó–∞–ø—É—Å–∫–∞–µ—Ç—Å—è –Ω–∞ –æ–¥–Ω–æ–º H100 GPU (Int4)

**–†–µ–≤–æ–ª—é—Ü–∏–æ–Ω–Ω—ã–π context window**: 10 –º–∏–ª–ª–∏–æ–Ω–æ–≤ —Ç–æ–∫–µ–Ω–æ–≤ - industry-leading.

**Training**: –î–æ 40 —Ç—Ä–∏–ª–ª–∏–æ–Ω–æ–≤ —Ç–æ–∫–µ–Ω–æ–≤, 200 —è–∑—ã–∫–æ–≤, fine-tuning –Ω–∞ 12 —è–∑—ã–∫–∞—Ö –≤–∫–ª—é—á–∞—è –∞—Ä–∞–±—Å–∫–∏–π, –∏—Å–ø–∞–Ω—Å–∫–∏–π, –Ω–µ–º–µ—Ü–∫–∏–π, —Ö–∏–Ω–¥–∏.

**–†–µ–∑—É–ª—å—Ç–∞—Ç—ã**: –ü—Ä–µ–≤–æ—Å—Ö–æ–¥–∏—Ç Gemma 3, Gemini 2.0 Flash-Lite, Mistral 3.1.

#### Llama 4 Maverick

**–†–µ–ª–∏–∑**: –ê–ø—Ä–µ–ª—å 2025

**–•–∞—Ä–∞–∫—Ç–µ—Ä**: –§–ª–∞–≥–º–∞–Ω –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏. Generalist –¥–ª—è chat, reasoning, image understanding, code.

**–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞**:
- MoE: 400B total / 17B active –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
- 128 —ç–∫—Å–ø–µ—Ä—Ç–æ–≤, 1 –∞–∫—Ç–∏–≤–µ–Ω –Ω–∞ —Ç–æ–∫–µ–Ω
- Context window: 1M —Ç–æ–∫–µ–Ω–æ–≤

**Benchmark —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã**:
- 80.5% –Ω–∞ MMLU Pro
- 69.8% –Ω–∞ GPQA Diamond
- –ü—Ä–µ–≤–æ—Å—Ö–æ–¥–∏—Ç GPT-4o –∏ Gemini 2.0 Flash
- –°—Ä–∞–≤–Ω–∏–º —Å DeepSeek V3 –Ω–∞ reasoning –∏ coding –ø—Ä–∏ –º–µ–Ω–µ–µ —á–µ–º –ø–æ–ª–æ–≤–∏–Ω–µ –∞–∫—Ç–∏–≤–Ω—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤

**Pricing —á–µ—Ä–µ–∑ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤**: $0.19-0.49 / 1M —Ç–æ–∫–µ–Ω–æ–≤

#### Llama 4 Behemoth (–≤ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ)

**–°—Ç–∞—Ç—É—Å**: –í –ø—Ä–æ—Ü–µ—Å—Å–µ –æ–±—É—á–µ–Ω–∏—è, teacher-–º–æ–¥–µ–ª—å –¥–ª—è Scout –∏ Maverick.

**–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞**:
- ~2 —Ç—Ä–∏–ª–ª–∏–æ–Ω–∞ total –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
- 288B –∞–∫—Ç–∏–≤–Ω—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
- 16 —ç–∫—Å–ø–µ—Ä—Ç–æ–≤

### Llama Impact

Meta –∑–∞–ø—É—Å—Ç–∏–ª–∞ –ø—Ä–æ–≥—Ä–∞–º–º—ã –ø–æ–¥–¥–µ—Ä–∂–∫–∏ —Å–æ—Ü–∏–∞–ª—å–Ω–æ –∑–Ω–∞—á–∏–º—ã—Ö –ø—Ä–æ–µ–∫—Ç–æ–≤:
- **Llama Impact Hackathon (London)**: 200+ —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤, 56 –∫–æ–º–∞–Ω–¥, –∑–¥—Ä–∞–≤–æ–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ, clean energy, social mobility
- **Llama Impact Grants** (—Å–µ–Ω—Ç—è–±—Ä—å 2024): –ì—Ä–∞–Ω—Ç—ã –¥–ª—è healthcare, agriculture, education

### Enterprise Adoption

- **Arcee AI**: 47% —Å–Ω–∏–∂–µ–Ω–∏–µ TCO vs closed LLMs —á–µ—Ä–µ–∑ fine-tuning
- **Block (Cash App)**: –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –≤ customer support —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º data privacy
- **Accenture**: Chatbot –¥–ª—è intergovernmental body –Ω–∞ AWS
- **Spotify**: Contextualized recommendations, artist discovery
- **LinkedIn**: Comparable –∏–ª–∏ –ª—É—á—à–µ –∫–∞—á–µ—Å—Ç–≤–æ vs commercial models –ø—Ä–∏ –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ –º–µ–Ω—å—à–∏—Ö costs –∏ latencies

### –ì–¥–µ –∑–∞–ø—É—Å–∫–∞—Ç—å Llama

- **Hugging Face**: –°–∫–∞—á–∏–≤–∞–Ω–∏–µ –≤–µ—Å–æ–≤
- **Ollama**: –õ–æ–∫–∞–ª—å–Ω—ã–π –∑–∞–ø—É—Å–∫
- **Together AI, Groq, Fireworks**: API-–ø—Ä–æ–≤–∞–π–¥–µ—Ä—ã
- **AWS, Azure, GCP**: –û–±–ª–∞—á–Ω—ã–µ —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è
- **vLLM**: –î–ª—è production inference

---

## DeepSeek

### –ò—Å—Ç–æ—Ä–∏—è –∫–æ–º–ø–∞–Ω–∏–∏

DeepSeek - –∫–∏—Ç–∞–π—Å–∫–∏–π —Å—Ç–∞—Ä—Ç–∞–ø, —Å—Ç–∞–≤—à–∏–π —Å–µ–Ω—Å–∞—Ü–∏–µ–π 2024-2025 –≥–æ–¥–æ–≤. –û—Å–Ω–æ–≤–∞–Ω –≤ 2023, –ø—Ä–∏–≤–ª—ë–∫ –≤–Ω–∏–º–∞–Ω–∏–µ –∫–æ–≥–¥–∞ DeepSeek R1 –ø–æ–∫–∞–∑–∞–ª 96.3% –Ω–∞ AIME (–æ–ª–∏–º–ø–∏–∞–¥–Ω–∞—è –º–∞—Ç–µ–º–∞—Ç–∏–∫–∞) –ø—Ä–æ—Ç–∏–≤ 79.2% —É OpenAI o1.

**–ü—Ä–æ—Ä—ã–≤ –≤ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏**: –ú–æ–¥–µ–ª–∏ –º–∏—Ä–æ–≤–æ–≥–æ —É—Ä–æ–≤–Ω—è –æ–±—É—á–µ–Ω—ã –∑–∞ $5-6 –º–∏–ª–ª–∏–æ–Ω–æ–≤ - –≤ 100 —Ä–∞–∑ –º–µ–Ω—å—à–µ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤. DeepSeek V3 —Ç—Ä–µ–±—É–µ—Ç —Ç–æ–ª—å–∫–æ 2.788M H800 GPU-—á–∞—Å–æ–≤ –¥–ª—è –ø–æ–ª–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è, pre-training –Ω–∞ 1T —Ç–æ–∫–µ–Ω–æ–≤ –∑–∞–Ω–∏–º–∞–µ—Ç –≤—Å–µ–≥–æ 3.7 –¥–Ω—è –Ω–∞ –∫–ª–∞—Å—Ç–µ—Ä–µ –∏–∑ 2048 H800.

### –õ–∏–Ω–µ–π–∫–∞ –º–æ–¥–µ–ª–µ–π

#### DeepSeek-V3

**–†–µ–ª–∏–∑**: –î–µ–∫–∞–±—Ä—å 2024

**–•–∞—Ä–∞–∫—Ç–µ—Ä –º–æ–¥–µ–ª–∏**: –≠–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω–æ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–π —É–Ω–∏–≤–µ—Ä—Å–∞–ª. –î–æ–∫–∞–∑–∞–ª, —á—Ç–æ –º–æ–∂–Ω–æ –¥–æ—Å—Ç–∏—á—å —Ç–æ–ø–æ–≤–æ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞ —Å –º–µ–Ω—å—à–∏–º–∏ —Ä–µ—Å—É—Ä—Å–∞–º–∏.

**–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞**:
- MoE: 671B total / 37B active –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
- Multi-head Latent Attention (MLA)
- DeepSeekMoE architecture
- Context window: 128K —Ç–æ–∫–µ–Ω–æ–≤

**Benchmark —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã**:
- 88.5 –Ω–∞ MMLU (–ª—É—á—à–µ –≤—Å–µ—Ö open-source)
- 75.9 –Ω–∞ MMLU-Pro
- 59.1 –Ω–∞ GPQA
- State-of-the-art –Ω–∞ MATH-500 —Å—Ä–µ–¥–∏ non-long-CoT –º–æ–¥–µ–ª–µ–π, –¥–∞–∂–µ –ø—Ä–µ–≤–æ—Å—Ö–æ–¥–∏—Ç o1-preview
- Top performance –Ω–∞ LiveCodeBench (coding competition)
- –°—Ä–∞–≤–Ω–∏–º —Å GPT-4o –∏ Claude-3.5-Sonnet

**–õ–∏—Ü–µ–Ω–∑–∏—è**: MIT (fully open-source)

#### DeepSeek-R1

**–†–µ–ª–∏–∑**: –Ø–Ω–≤–∞—Ä—å 2025

**–•–∞—Ä–∞–∫—Ç–µ—Ä –º–æ–¥–µ–ª–∏**: Reasoning-–º–æ–¥–µ–ª—å, –æ–±—É—á–µ–Ω–Ω–∞—è –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–µ–Ω–Ω–æ —á–µ—Ä–µ–∑ Reinforcement Learning –±–µ–∑ supervised fine-tuning (–ø–µ—Ä–≤—ã–π —Ç–∞–∫–æ–π –ø–æ–¥—Ö–æ–¥ –≤ –∏–Ω–¥—É—Å—Ç—Ä–∏–∏).

**–ö–ª—é—á–µ–≤–æ–µ –æ—Ç–∫—Ä—ã—Ç–∏–µ**: DeepSeek-R1-Zero –ø–æ–∫–∞–∑–∞–ª, —á—Ç–æ reasoning capabilities (self-verification, reflection, long CoT) –º–æ–≥—É—Ç "—ç–º–µ—Ä–≥–µ–Ω—Ç–Ω–æ" –ø–æ—è–≤–∏—Ç—å—Å—è –∏–∑ pure RL –±–µ–∑ human-labelled reasoning trajectories.

**–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞**:
- 671B total / 37B active –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
- Context window: 164K —Ç–æ–∫–µ–Ω–æ–≤
- –ü—Ä–æ–±–ª–µ–º—ã R1-Zero (endless repetition, poor readability, language mixing) —Ä–µ—à–µ–Ω—ã –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ–º cold-start data

**Training**: GRPO (Group Relative Policy Optimization) –≤–º–µ—Å—Ç–æ —Ç—Ä–∞–¥–∏—Ü–∏–æ–Ω–Ω–æ–≥–æ PPO.

**Benchmark —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã**:
- ~90-91% –Ω–∞ MMLU
- 97.3% –Ω–∞ MATH-500
- ~79.8% –Ω–∞ AIME
- 2029 Elo –Ω–∞ Codeforces

**–î–∏—Å—Ç–∏–ª–ª—è—Ü–∏—è**: –î–æ—Å—Ç—É–ø–Ω—ã distilled-–≤–µ—Ä—Å–∏–∏: 1.5B, 7B, 8B, 14B, 32B, 70B –Ω–∞ –±–∞–∑–µ Qwen2.5 –∏ Llama3. Distilled 14B –ø—Ä–µ–≤–æ—Å—Ö–æ–¥–∏—Ç QwQ-32B-Preview.

**–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ R1-0528** (–º–∞–π 2025):
- Reasoning tokens –≤—ã—Ä–æ—Å–ª–∏ —Å 12K –¥–æ 23K –Ω–∞ –≤–æ–ø—Ä–æ—Å AIME
- –ü—Ä–∏–±–ª–∏–∂–∞–µ—Ç—Å—è –∫ OpenAI o3 –∏ Gemini 2.5 Pro

**DeepSeek-V3.1** (–∞–≤–≥—É—Å—Ç 2025): Hybrid –º–æ–¥–µ–ª—å, –æ–±—ä–µ–¥–∏–Ω—è—é—â–∞—è V3 –∏ R1, 671B –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ (37B active), context –¥–æ 128K.

### –ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–æ –≤ —Å—Ç–æ–∏–º–æ—Å—Ç–∏

| –ú–µ—Ç—Ä–∏–∫–∞ | DeepSeek | OpenAI |
|---------|----------|--------|
| –°—Ç–æ–∏–º–æ—Å—Ç—å 100M —Ç–æ–∫–µ–Ω–æ–≤ | ~$274 | ~$1,300 (GPT-4o) |
| –¢–∞ –∂–µ –Ω–∞–≥—Ä—É–∑–∫–∞ | $10 | $270 |
| –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ | $5-6M | $100M+ |

**27x –¥–µ—à–µ–≤–ª–µ** –ø—Ä–∏ —Å—Ä–∞–≤–Ω–∏–º–æ–º –∫–∞—á–µ—Å—Ç–≤–µ! Processing times 0.5 sec vs 2 sec —É OpenAI, 4x faster.

**Context caching**: –ú–µ—Ö–∞–Ω–∏–∑–º –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è –¥–ª—è –ø–æ–≤—Ç–æ—Ä—è—é—â–∏—Ö—Å—è –∑–∞–ø—Ä–æ—Å–æ–≤ - —É–Ω–∏–∫–∞–ª—å–Ω–∞—è –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç—å, –µ—â–µ –±–æ–ª—å—à–µ —Å–Ω–∏–∂–∞—é—â–∞—è –∑–∞—Ç—Ä–∞—Ç—ã.

### API Pricing

| –ú–æ–¥–µ–ª—å | Input | Output |
|--------|-------|--------|
| DeepSeek V3 | $0.27 | $1.10 |
| DeepSeek R1 | $0.55 | $2.19 |

### –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è

- **Text-only**: –ù–µ—Ç vision, audio, video
- **–ö–∏—Ç–∞–π—Å–∫–∏–µ —Å–µ—Ä–≤–µ—Ä–∞**: –í–æ–∑–º–æ–∂–Ω—ã–µ –∑–∞–¥–µ—Ä–∂–∫–∏, –≥–µ–æ–ø–æ–ª–∏—Ç–∏—á–µ—Å–∫–∏–µ —Ä–∏—Å–∫–∏
- **Alignment**: –ú–µ–Ω–µ–µ "–æ—Å—Ç–æ—Ä–æ–∂–Ω—ã–π" —á–µ–º –∑–∞–ø–∞–¥–Ω—ã–µ –º–æ–¥–µ–ª–∏
- **–¶–µ–Ω–∑—É—Ä–∞**: –û–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω—ã–µ –ø–æ–ª–∏—Ç–∏—á–µ—Å–∫–∏–µ —Ç–µ–º—ã –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç—Å—è –∏–Ω–∞—á–µ

---

## Mistral AI

### –ò—Å—Ç–æ—Ä–∏—è –∫–æ–º–ø–∞–Ω–∏–∏

–§—Ä–∞–Ω—Ü—É–∑—Å–∫–∏–π —Å—Ç–∞—Ä—Ç–∞–ø, –æ—Å–Ω–æ–≤–∞–Ω–Ω—ã–π –≤ 2023 –≥–æ–¥—É –±—ã–≤—à–∏–º–∏ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞–º–∏ Meta –∏ Google DeepMind. –ó–∞ –≥–æ–¥ —Å—Ç–∞–ª —Å–∞–º—ã–º —Ü–µ–Ω–Ω—ã–º AI-—Å—Ç–∞—Ä—Ç–∞–ø–æ–º –ï–≤—Ä–æ–ø—ã. –§–∏–ª–æ—Å–æ—Ñ–∏—è: –≤—ã—Å–æ–∫–æ–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω—ã–µ –º–æ–¥–µ–ª–∏ —Å –æ—Ç–∫—Ä—ã—Ç—ã–º–∏ –≤–µ—Å–∞–º–∏, –æ—Ä–∏–µ–Ω—Ç–∞—Ü–∏—è –Ω–∞ enterprise.

### –õ–∏–Ω–µ–π–∫–∞ –º–æ–¥–µ–ª–µ–π

#### Mistral Large 2

**–†–µ–ª–∏–∑**: –ò—é–ª—å 2024

**–•–∞—Ä–∞–∫—Ç–µ—Ä –º–æ–¥–µ–ª–∏**: Enterprise-–∫–ª–∞—Å—Å –¥–ª—è —Å–ª–æ–∂–Ω—ã—Ö –∑–∞–¥–∞—á. –ü–æ–∑–∏—Ü–∏–æ–Ω–∏—Ä—É–µ—Ç—Å—è –∫–∞–∫ –µ–≤—Ä–æ–ø–µ–π—Å–∫–∞—è –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞ GPT-4.

**–ö–ª—é—á–µ–≤—ã–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏**:
- –ü–∞—Ä–∞–º–µ—Ç—Ä—ã: 123B
- Context window: 128K —Ç–æ–∫–µ–Ω–æ–≤
- Single-node inference

**–í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏**:
- 80+ —è–∑—ã–∫–æ–≤ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è
- –ü–æ–¥–¥–µ—Ä–∂–∫–∞ –¥—é–∂–∏–Ω—ã –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö —è–∑—ã–∫–æ–≤ (—Ñ—Ä–∞–Ω—Ü—É–∑—Å–∫–∏–π, –Ω–µ–º–µ—Ü–∫–∏–π, –∏—Å–ø–∞–Ω—Å–∫–∏–π, –∏—Ç–∞–ª—å—è–Ω—Å–∫–∏–π, –ø–æ—Ä—Ç—É–≥–∞–ª—å—Å–∫–∏–π, –∞—Ä–∞–±—Å–∫–∏–π, —Ö–∏–Ω–¥–∏, —Ä—É—Å—Å–∫–∏–π, –∫–∏—Ç–∞–π—Å–∫–∏–π, —è–ø–æ–Ω—Å–∫–∏–π, –∫–æ—Ä–µ–π—Å–∫–∏–π)
- Advanced function calling
- –ó–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ –ª—É—á—à–µ –≤ code generation, mathematics, reasoning vs predecessor

#### Mistral NeMo

**–†–µ–ª–∏–∑**: –ò—é–ª—å 2024 (—Å–æ–≤–º–µ—Å—Ç–Ω–æ —Å NVIDIA)

**–•–∞—Ä–∞–∫—Ç–µ—Ä –º–æ–¥–µ–ª–∏**: –õ—É—á—à–µ–µ –≤ —Å–≤–æ–µ–º —Ä–∞–∑–º–µ—Ä–µ. Drop-in replacement –¥–ª—è Mistral 7B —Å –∫–∞—Ä–¥–∏–Ω–∞–ª—å–Ω—ã–º–∏ —É–ª—É—á—à–µ–Ω–∏—è–º–∏.

**–ö–ª—é—á–µ–≤—ã–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏**:
- –ü–∞—Ä–∞–º–µ—Ç—Ä—ã: 12B
- Context window: 128K —Ç–æ–∫–µ–Ω–æ–≤
- –õ–∏—Ü–µ–Ω–∑–∏—è: Apache 2.0

**–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞**:
- –û–±—É—á–µ–Ω–∞ —Å quantization awareness - FP8 –±–µ–∑ –ø–æ—Ç–µ—Ä–∏ –∫–∞—á–µ—Å—Ç–≤–∞
- –ù–æ–≤—ã–π —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä Tekken –Ω–∞ –±–∞–∑–µ Tiktoken (100+ —è–∑—ã–∫–æ–≤)
- 30% —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–µ–µ –Ω–∞ —Å–∂–∞—Ç–∏–∏ –∫–æ–¥–∞ –∏ –µ–≤—Ä–æ–ø–µ–π—Å–∫–∏—Ö —è–∑—ã–∫–æ–≤
- SOTA –≤ —Å–≤–æ–µ–º —Ä–∞–∑–º–µ—Ä–Ω–æ–º –∫–ª–∞—Å—Å–µ –ø–æ reasoning, world knowledge, coding accuracy
- –õ—É—á—à–µ –Ω–∞ multi-turn conversations vs Mistral 7B

#### –°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏

- **Codestral** (—è–Ω–≤–∞—Ä—å 2025): –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–∞ –¥–ª—è –∫–æ–¥–∞
- **Pixtral** (—Å–µ–Ω—Ç—è–±—Ä—å 2024): 12B –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å, image understanding + text
- **Codestral Mamba** (–∏—é–ª—å 2024): –ü–µ—Ä–≤–∞—è open-source Mamba 2 architecture
- **Mathstral 7B** (–∏—é–ª—å 2024): –î–ª—è –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö –≤—ã—á–∏—Å–ª–µ–Ω–∏–π
- **Frontier multimodal** (–º–∞–π 2025): –ù–æ–≤–µ–π—à–∞—è frontier-class –º–æ–¥–µ–ª—å

### –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –≤—ã–±–æ—Ä—É –æ—Ç Mistral

| –ó–∞–¥–∞—á–∞ | –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º–∞—è –º–æ–¥–µ–ª—å |
|--------|---------------------|
| –ü—Ä–æ—Å—Ç—ã–µ (–∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è, –ø–æ–¥–¥–µ—Ä–∂–∫–∞, text gen) | Mistral NeMo |
| –°—Ä–µ–¥–Ω–∏–µ (–∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö, —Å–∞–º–º–∞—Ä–∏–∑–∞—Ü–∏—è, emails) | Mistral Small |
| –°–ª–æ–∂–Ω—ã–µ (RAG, –∞–≥–µ–Ω—Ç—ã, code gen, synthetic text) | Mistral Large |

---

## Alibaba Qwen

### –ò—Å—Ç–æ—Ä–∏—è

Qwen (Tongyi Qianwen) - –ª–∏–Ω–µ–π–∫–∞ LLM –æ—Ç Alibaba Cloud. –ê–∫—Ç–∏–≤–Ω–æ –∏–Ω–≤–µ—Å—Ç–∏—Ä—É–µ—Ç –≤ AI, Qwen —Å—Ç–∞–ª –æ–¥–Ω–∏–º –∏–∑ —Å–∏–ª—å–Ω–µ–π—à–∏—Ö open-source —Ä–µ—à–µ–Ω–∏–π —Å 300+ –º–∏–ª–ª–∏–æ–Ω–∞–º–∏ —Å–∫–∞—á–∏–≤–∞–Ω–∏–π.

### –õ–∏–Ω–µ–π–∫–∞ –º–æ–¥–µ–ª–µ–π

#### Qwen 2.5

**–†–µ–ª–∏–∑**: –°–µ–Ω—Ç—è–±—Ä—å 2024

**–•–∞—Ä–∞–∫—Ç–µ—Ä —Å–µ—Ä–∏–∏**: –ö–æ–º–ø–ª–µ–∫—Å–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ –Ω–∞ –ª—é–±–æ–π —Ä–∞–∑–º–µ—Ä. –û—Ç 0.5B –¥–æ 72B –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤, –ø–ª—é—Å —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –≤–µ—Ä—Å–∏–∏ –¥–ª—è –∫–æ–¥–∞ (Qwen2.5-Coder) –∏ –º–∞—Ç–µ–º–∞—Ç–∏–∫–∏ (Qwen2.5-Math).

**–î–∞–Ω–Ω—ã–µ –æ–±—É—á–µ–Ω–∏—è**: 18 —Ç—Ä–∏–ª–ª–∏–æ–Ω–æ–≤ —Ç–æ–∫–µ–Ω–æ–≤.

**–†–∞–∑–º–µ—Ä–Ω—ã–π —Ä—è–¥**: 0.5B, 1.5B, 3B, 7B, 14B, 32B, 72B

**Context window**: 128K —Ç–æ–∫–µ–Ω–æ–≤ (–≥–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–æ 8K)

#### Qwen 2.5-72B-Instruct

**–•–∞—Ä–∞–∫—Ç–µ—Ä**: –§–ª–∞–≥–º–∞–Ω —Å–µ—Ä–∏–∏, –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç GPT-4.

**Benchmark —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã**:
- –ü—Ä–µ–≤–æ—Å—Ö–æ–¥–∏—Ç Llama-3.1-405B –Ω–∞ MMLU-redux, MATH, MBPP, MultiPL-E, LiveCodeBench, Arena-Hard, MTBench
- 5x –º–µ–Ω—å—à–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –ø—Ä–∏ —Å—Ä–∞–≤–Ω–∏–º–æ–º –∫–∞—á–µ—Å—Ç–≤–µ
- 83.1% –Ω–∞ MATH (vs 69% —É Qwen2)
- 81.2 Arena-Hard (vs 48.1 —É Qwen2)
- 9.35 MT-Bench (vs 9.12 —É Qwen2)
- 55.5 –Ω–∞ LiveCodeBench, 75.1 –Ω–∞ MultiPL-E, 88.2 –Ω–∞ MBPP

#### Qwen 2.5 Coder

**–•–∞—Ä–∞–∫—Ç–µ—Ä**: SOTA open-source –º–æ–¥–µ–ª—å –¥–ª—è –∫–æ–¥–∞.

**Qwen 2.5-Coder-32B –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è**:
- –°—Ä–∞–≤–Ω–∏–º —Å GPT-4o –ø–æ –∫–∞—á–µ—Å—Ç–≤—É –∫–æ–¥–∞
- 73.7% –Ω–∞ Aider code editing benchmark (#4 –æ–±—â–∏–π —Ä–µ–π—Ç–∏–Ω–≥, –ø–æ—Å–ª–µ Claude 3.5 Sonnet)
- –õ—É—á—à–∏–π —Å—Ä–µ–¥–∏ open-source –Ω–∞ EvalPlus, LiveCodeBench, BigCodeBench
- –†–∞–±–æ—Ç–∞–µ—Ç –Ω–∞ Mac –ª–æ–∫–∞–ª—å–Ω–æ

#### Qwen 2.5 Max

**–†–µ–ª–∏–∑**: –Ø–Ω–≤–∞—Ä—å 2025

**–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞**: –ú–∞—Å—à—Ç–∞–±–Ω–∞—è MoE –º–æ–¥–µ–ª—å, 20T+ —Ç–æ–∫–µ–Ω–æ–≤ –æ–±—É—á–µ–Ω–∏—è, SFT + RLHF post-training.

**–†–µ–∑—É–ª—å—Ç–∞—Ç—ã**: –ü—Ä–µ–≤–æ—Å—Ö–æ–¥–∏—Ç DeepSeek V3 –Ω–∞ Arena-Hard, LiveBench, LiveCodeBench, GPQA-Diamond. Competitive –Ω–∞ MMLU-Pro.

#### Qwen3

**Qwen3-235B-A22B** (flagship):
- 235B total, 22B active (MoE)
- Apache 2.0 (fully open-weight!)
- –°—Ä–∞–≤–Ω–∏–º —Å GPT-5, DeepSeek-V3, Claude Opus 4

---

## –°—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ç–∞–±–ª–∏—Ü—ã

### –°—Ç–æ–∏–º–æ—Å—Ç—å API (–∑–∞ 1M —Ç–æ–∫–µ–Ω–æ–≤, –¥–µ–∫–∞–±—Ä—å 2024)

| –ú–æ–¥–µ–ª—å | Input | Output | –ü—Ä–∏–º–µ—á–∞–Ω–∏–µ |
|--------|-------|--------|------------|
| **OpenAI** |
| GPT-4o | $2.50 | $10.00 | –£–Ω–∏–≤–µ—Ä—Å–∞–ª |
| GPT-4o mini | $0.15 | $0.60 | –î–ª—è –ø—Ä–æ—Å—Ç—ã—Ö –∑–∞–¥–∞—á |
| o1 | $15.00 | $60.00 | Reasoning |
| GPT-5 | $1.25 | $10.00 | 2025 flagship |
| **Anthropic** |
| Claude Opus 4.5 | $5.00 | $25.00 | –ú–∞–∫—Å–∏–º—É–º –∫–∞—á–µ—Å—Ç–≤–∞ |
| Claude Sonnet 3.5 | $3.00 | $15.00 | –õ—É—á—à–∏–π –±–∞–ª–∞–Ω—Å |
| Claude Haiku | $0.25 | $1.25 | –°–∫–æ—Ä–æ—Å—Ç—å |
| Claude 4.1 Opus | $20.00 | $80.00 | Flagship |
| **Google** |
| Gemini 2.5 Pro (<128K) | $1.25 | $5.00 | –í—ã–≥–æ–¥–Ω—ã–π |
| Gemini 2.5 Pro (>128K) | $2.50 | $10.00 | Long context |
| Gemini Flash-Lite | $0.075 | $0.30 | Ultra-budget |
| **DeepSeek** |
| DeepSeek V3 | $0.27 | $1.10 | Best value |
| DeepSeek R1 | $0.55 | $2.19 | Reasoning |
| **Meta Llama** |
| Llama 4 Maverick | $0.19 | $0.49 | –ß–µ—Ä–µ–∑ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤ |

### Context Window

| –ú–æ–¥–µ–ª—å | Context Window |
|--------|---------------|
| Llama 4 Scout | 10M —Ç–æ–∫–µ–Ω–æ–≤ |
| Magic LTM-2-Mini | 100M —Ç–æ–∫–µ–Ω–æ–≤ |
| Gemini 2.5 Pro | 1M-2M —Ç–æ–∫–µ–Ω–æ–≤ |
| Claude Sonnet (long) | 1M —Ç–æ–∫–µ–Ω–æ–≤ |
| GPT-4.1 | 1M —Ç–æ–∫–µ–Ω–æ–≤ |
| Llama 4 Maverick | 1M —Ç–æ–∫–µ–Ω–æ–≤ |
| GPT-4o | 128K —Ç–æ–∫–µ–Ω–æ–≤ |
| Llama 3.3 70B | 128K —Ç–æ–∫–µ–Ω–æ–≤ |
| DeepSeek V3 | 128K —Ç–æ–∫–µ–Ω–æ–≤ |
| Mistral Large 2 | 128K —Ç–æ–∫–µ–Ω–æ–≤ |
| Qwen 2.5 | 128K —Ç–æ–∫–µ–Ω–æ–≤ |

### Benchmark —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ (–ø—Ä–∏–º–µ—Ä–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è)

| –ú–æ–¥–µ–ª—å | MMLU | GPQA | HumanEval | MATH | SWE-bench |
|--------|------|------|-----------|------|-----------|
| GPT-4o | 88.7 | 53.6 | 90.2 | 76.6 | ~60% |
| o3 | - | 87.7 | - | - | 71.7% |
| Claude 3.5 Sonnet | 88.9 | 65.0 | 92.0 | 78.3 | 49% |
| Gemini 2.5 Pro | 89.2 | 67.0 | 90.0 | 82.0 | 63.8% |
| DeepSeek V3 | 88.5 | 59.1 | 89.0 | 84.0 | ~65% |
| DeepSeek R1 | 90-91 | - | - | 97.3 | - |
| Llama 3.3 70B | 86.0 | 50.5 | 88.4 | 77.0 | - |
| Llama 4 Maverick | 80.5 (Pro) | 69.8 | - | - | ~60% |
| Qwen 2.5-72B | 86.1 | - | 88.0 | 83.1 | - |

**–ü—Ä–∏–º–µ—á–∞–Ω–∏–µ**: MMLU –∏ HumanEval —É–∂–µ —Å—á–∏—Ç–∞—é—Ç—Å—è "saturated" –±–µ–Ω—á–º–∞—Ä–∫–∞–º–∏. –ù–æ–≤—ã–µ –±–µ–Ω—á–º–∞—Ä–∫–∏ (GPQA, SWE-bench, Humanity's Last Exam) –±–æ–ª–µ–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª—å–Ω—ã.

---

## –ö–æ–≥–¥–∞ –∫–∞–∫—É—é –º–æ–¥–µ–ª—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å

### –ü–æ –∑–∞–¥–∞—á–µ

| –ó–∞–¥–∞—á–∞ | –õ—É—á—à–∏–π –≤—ã–±–æ—Ä | –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞ |
|--------|--------------|--------------|
| **–ö–æ–¥–∏–Ω–≥ (—Å–ª–æ–∂–Ω—ã–π)** | Claude 3.5 Sonnet | DeepSeek V3, Qwen Coder |
| **–ö–æ–¥–∏–Ω–≥ (–ø—Ä–æ—Å—Ç–æ–π)** | GPT-4o mini | Claude Haiku |
| **–ú–∞—Ç–µ–º–∞—Ç–∏–∫–∞/–ù–∞—É–∫–∞** | DeepSeek R1, o1/o3 | Gemini 2.5 Pro |
| **–ö—Ä–µ–∞—Ç–∏–≤–Ω–æ–µ –ø–∏—Å—å–º–æ** | Claude Sonnet | GPT-4o |
| **–ê–Ω–∞–ª–∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤** | Gemini 2.5 Pro | Claude Sonnet |
| **–ú—É–ª—å—Ç–∏–º–æ–¥–∞–ª (–≤–∏–¥–µ–æ)** | Gemini 2.0 Flash | Llama 4 Maverick |
| **Real-time voice** | GPT-4o Realtime | Gemini Live API |
| **RAG/Enterprise** | Mistral Large | GPT-4o |
| **Edge/Mobile** | Llama 4 Scout | Qwen 2.5 (small sizes) |
| **–ë—é–¥–∂–µ—Ç–Ω—ã–µ –∑–∞–¥–∞—á–∏** | DeepSeek V3 | Gemini Flash-Lite |
| **Multilingual (119 —è–∑—ã–∫–æ–≤)** | Qwen3 | Llama 4 |

### –ü–æ –±—é–¥–∂–µ—Ç—É

| –ë—é–¥–∂–µ—Ç | –ú–æ–¥–µ–ª–∏ |
|--------|--------|
| **–ú–∏–Ω–∏–º—É–º –∑–∞—Ç—Ä–∞—Ç** | DeepSeek V3, Gemini Flash-Lite, self-hosted Llama |
| **–û–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –±–∞–ª–∞–Ω—Å** | Claude Sonnet, GPT-4o, Gemini 2.5 Pro |
| **–ú–∞–∫—Å–∏–º—É–º –∫–∞—á–µ—Å—Ç–≤–∞** | Claude Opus, o1/o3, Gemini 2.5 Pro |

### –ü–æ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º

| –¢—Ä–µ–±–æ–≤–∞–Ω–∏–µ | –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è |
|------------|--------------|
| **–ü—Ä–∏–≤–∞—Ç–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö** | Self-hosted Llama, DeepSeek, Qwen |
| **–ï–≤—Ä–æ–ø–µ–π—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ** | Mistral (—Ñ—Ä–∞–Ω—Ü—É–∑—Å–∫–∞—è —é—Ä–∏—Å–¥–∏–∫—Ü–∏—è) |
| **–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å Google** | Gemini |
| **–ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç** | Llama 4 Scout (10M), Gemini (2M) |
| **Safety-critical** | Claude (Constitutional AI) |
| **True open-source (Apache 2.0)** | Qwen3, Mistral NeMo |

### –•–∞—Ä–∞–∫—Ç–µ—Ä—ã –º–æ–¥–µ–ª–µ–π (—Å—É–±—ä–µ–∫—Ç–∏–≤–Ω–æ)

| –ú–æ–¥–µ–ª—å | "–õ–∏—á–Ω–æ—Å—Ç—å" |
|--------|------------|
| **GPT-4o** | –≠–Ω–µ—Ä–≥–∏—á–Ω—ã–π —É–Ω–∏–≤–µ—Ä—Å–∞–ª, –ª—é–±–∏—Ç –±—É–ª–ª–µ—Ç-–ø–æ–∏–Ω—Ç—ã, –∏–Ω–æ–≥–¥–∞ overconfident |
| **Claude Sonnet** | –í–¥—É–º—á–∏–≤—ã–π —ç–∫—Å–ø–µ—Ä—Ç, –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã–π —è–∑—ã–∫, –ø—Ä–∏–∑–Ω–∞—ë—Ç –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è |
| **Gemini Pro** | –≠—Ä—É–¥–∏—Ä–æ–≤–∞–Ω–Ω—ã–π, —Ñ–∞–∫—Ç–æ–ª–æ–≥–∏—á–Ω—ã–π, –±–æ–ª–µ–µ "—Å—É—Ö–æ–π" |
| **DeepSeek** | –ü—Ä—è–º–æ–ª–∏–Ω–µ–π–Ω—ã–π, —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–π, –¥–µ—Ä–∑–∫–∏–π –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä |
| **Llama** | –ì–∏–±–∫–∏–π, –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º—ã–π, –¥–µ–º–æ–∫—Ä–∞—Ç–∏–∑–∞—Ç–æ—Ä |

---

## –ü—Ä–æ–≤–µ—Ä—å —Å–µ–±—è

<details>
<summary><strong>1. –ö–∞–∫—É—é –º–æ–¥–µ–ª—å –≤—ã–±—Ä–∞—Ç—å –¥–ª—è —Å–ª–æ–∂–Ω—ã—Ö –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö –∑–∞–¥–∞—á –∏ –ø–æ—á–µ–º—É?</strong></summary>

**–õ—É—á—à–∏–π –≤—ã–±–æ—Ä:** OpenAI o3 –∏–ª–∏ DeepSeek R1

**–ü–æ—á–µ–º—É reasoning-–º–æ–¥–µ–ª–∏:**
- –ò—Å–ø–æ–ª—å–∑—É—é—Ç "chain-of-thought" —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è –ø–µ—Ä–µ–¥ –æ—Ç–≤–µ—Ç–æ–º
- o3 –¥–æ—Å—Ç–∏–≥ 87.7% –Ω–∞ ARC-AGI (vs 42% GPT-4o)
- DeepSeek R1 ‚Äî open-source –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞ —Å MIT –ª–∏—Ü–µ–Ω–∑–∏–µ–π

**–ù–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:** GPT-4o –∏–ª–∏ Claude Sonnet ‚Äî –æ–Ω–∏ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω—ã –¥–ª—è –±—ã—Å—Ç—Ä—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤, –Ω–µ –¥–ª—è –≥–ª—É–±–æ–∫–æ–≥–æ reasoning.

**Trade-off:** Reasoning-–º–æ–¥–µ–ª–∏ –º–µ–¥–ª–µ–Ω–Ω–µ–µ (—Å–µ–∫—É–Ω–¥—ã vs –º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥—ã) –∏ –¥–æ—Ä–æ–∂–µ, –Ω–æ –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ —Ç–æ—á–Ω–µ–µ –Ω–∞ —Å–ª–æ–∂–Ω—ã—Ö –∑–∞–¥–∞—á–∞—Ö.
</details>

<details>
<summary><strong>2. –ö–æ–≥–¥–∞ –≤—ã–±—Ä–∞—Ç—å Claude Sonnet –≤–º–µ—Å—Ç–æ GPT-4o?</strong></summary>

**–í—ã–±–∏—Ä–∞–π—Ç–µ Claude Sonnet –∫–æ–≥–¥–∞:**
- **Coding:** 77.2% SWE-bench vs GPT-4o ‚Äî –ª—É—á—à–∏–π coding model
- **–î–ª–∏–Ω–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã:** 200K –Ω–∞—Ç–∏–≤–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç (1M beta)
- **–ê–≤—Ç–æ–Ω–æ–º–Ω—ã–µ –∞–≥–µ–Ω—Ç—ã:** Computer Use, 30+ —á–∞—Å–æ–≤ –∞–≤—Ç–æ–Ω–æ–º–Ω–æ–π —Ä–∞–±–æ—Ç—ã
- **–ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å –∫—Ä–∏—Ç–∏—á–Ω–∞:** –í—Å—Ç—Ä–æ–µ–Ω–Ω—ã–µ guardrails, –æ—Ç–∫–∞–∑ –æ—Ç harmful content

**–í—ã–±–∏—Ä–∞–π—Ç–µ GPT-4o –∫–æ–≥–¥–∞:**
- **–ú—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–æ—Å—Ç—å:** –ù–∞—Ç–∏–≤–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∞—É–¥–∏–æ, real-time voice
- **–≠–∫–æ—Å–∏—Å—Ç–µ–º–∞:** Plugins, custom GPTs, —à–∏—Ä–æ–∫–∞—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è
- **–°–∫–æ—Ä–æ—Å—Ç—å:** 110 tok/sec vs ~70 tok/sec —É Claude
</details>

<details>
<summary><strong>3. –ß–µ–º DeepSeek R1 –æ—Ç–ª–∏—á–∞–µ—Ç—Å—è –æ—Ç GPT-4o –ø–æ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–µ –∏ —Å—Ç–æ–∏–º–æ—Å—Ç–∏?</strong></summary>

**–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞:**
- **DeepSeek:** Mixture-of-Experts (MoE), 671B –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤, –Ω–æ –∞–∫—Ç–∏–≤–∏—Ä—É–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ 37B
- **GPT-4o:** –ü—Ä–µ–¥–ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–æ dense transformer, ~175B –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤

**–°—Ç–æ–∏–º–æ—Å—Ç—å (per 1M tokens):**
| –ú–æ–¥–µ–ª—å | Input | Output |
|--------|-------|--------|
| GPT-4o | $2.50 | $10.00 |
| DeepSeek R1 | $0.27 | $1.10 |

**–†–∞–∑–Ω–∏—Ü–∞:** DeepSeek –≤ ~10x –¥–µ—à–µ–≤–ª–µ –ø—Ä–∏ —Å–æ–ø–æ—Å—Ç–∞–≤–∏–º–æ–º –∫–∞—á–µ—Å—Ç–≤–µ –Ω–∞ reasoning tasks.

**–õ–∏—Ü–µ–Ω–∑–∏—è:** DeepSeek ‚Äî MIT (–±–µ—Å–ø–ª–∞—Ç–Ω—ã–π self-hosting), GPT-4o ‚Äî –ø—Ä–æ–ø—Ä–∏–µ—Ç–∞—Ä–Ω—ã–π API.
</details>

<details>
<summary><strong>4. –ö–∞–∫–∏–µ open-source –º–æ–¥–µ–ª–∏ –∫–æ–Ω–∫—É—Ä–∏—Ä—É—é—Ç —Å –∑–∞–∫—Ä—ã—Ç—ã–º–∏ –∏ –¥–ª—è –∫–∞–∫–∏—Ö –∑–∞–¥–∞—á?</strong></summary>

| –ó–∞–¥–∞—á–∞ | Open-Source –ú–æ–¥–µ–ª—å | –ö–æ–Ω–∫—É—Ä–∏—Ä—É–µ—Ç —Å |
|--------|-------------------|---------------|
| **General reasoning** | DeepSeek R1 | OpenAI o1 |
| **Coding** | DeepSeek 67B, Qwen 2.5 Coder | GPT-4o |
| **Multilingual** | Llama 3.3 70B, Qwen 2.5 | GPT-4o |
| **–°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç** | Llama 3.3 70B | Claude Sonnet |
| **Research** | Qwen 2.5 72B | GPT-4o |

**–ö–ª—é—á–µ–≤—ã–µ –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ open-source:**
- 86% —ç–∫–æ–Ω–æ–º–∏—è –Ω–∞ –∑–∞—Ç—Ä–∞—Ç–∞—Ö
- Self-hosting (data privacy)
- Fine-tuning –ø–æ–¥ —Å–≤–æ–∏ –∑–∞–¥–∞—á–∏
- –ù–µ—Ç vendor lock-in
</details>

<details>
<summary><strong>5. –ö–∞–∫ –∏–∑–º–µ–Ω–∏–ª—Å—è –ª–∞–Ω–¥—à–∞—Ñ—Ç LLM –≤ 2024-2025?</strong></summary>

**–ö–ª—é—á–µ–≤—ã–µ —Ç—Ä–µ–Ω–¥—ã:**

1. **–ö–æ–Ω–≤–µ—Ä–≥–µ–Ω—Ü–∏—è –∫–∞—á–µ—Å—Ç–≤–∞**
   - –†–∞–∑—Ä—ã–≤ –≤ Elo –º–µ–∂–¥—É —Ç–æ–ø-10 –º–æ–¥–µ–ª—è–º–∏: 11.9% (2023) ‚Üí 5.4% (2025)
   - –†–∞–∑—Ä—ã–≤ US vs China –º–æ–¥–µ–ª–µ–π: —Å–æ–∫—Ä–∞—Ç–∏–ª—Å—è –¥–æ 1.70%

2. **Reasoning-–º–æ–¥–µ–ª–∏** ‚Äî –Ω–æ–≤—ã–π –∫–ª–∞—Å—Å (o1, o3, R1, Flash Thinking)

3. **Open-source –ø–∞—Ä–∏—Ç–µ—Ç** ‚Äî DeepSeek, Llama, Qwen –∫–æ–Ω–∫—É—Ä–∏—Ä—É—é—Ç —Å –∑–∞–∫—Ä—ã—Ç—ã–º–∏

4. **–ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–µ –æ–∫–Ω–∞** ‚Äî —Ä–æ—Å—Ç ~30x –≤ –≥–æ–¥ (4K ‚Üí 10M)

5. **–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å** ‚Äî MoE –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –ø–æ–∑–≤–æ–ª—è—é—Ç 671B params —Å –∞–∫—Ç–∏–≤–∞—Ü–∏–µ–π —Ç–æ–ª—å–∫–æ 37B
</details>

---

## –ò—Å—Ç–æ—á–Ω–∏–∫–∏

| # | –ò—Å—Ç–æ—á–Ω–∏–∫ | –¢–∏–ø | –í–∫–ª–∞–¥ |
|---|----------|-----|-------|
| 1 | [OpenAI Models Docs](https://platform.openai.com/docs/models) | Docs | GPT-4o, o1/o3 specs |
| 2 | [Anthropic Claude 3.5](https://www.anthropic.com/news/claude-3-5-sonnet) | Blog | Sonnet, Computer Use |
| 3 | [Google Gemini 2.0](https://blog.google/technology/google-deepmind/google-gemini-ai-update-december-2024/) | Blog | Flash, Pro specs |
| 4 | [Meta Llama 4](https://ai.meta.com/blog/llama-4-multimodal-intelligence/) | Blog | 10M context, Scout |
| 5 | [DeepSeek R1 Paper](https://arxiv.org/abs/2501.12948) | Paper | Reasoning, MoE |
| 6 | [DeepSeek V3 Report](https://arxiv.org/abs/2412.19437) | Paper | 671B params, efficiency |
| 7 | [Qwen 2.5 Blog](https://qwenlm.github.io/blog/qwen2.5-llm/) | Blog | Multilingual, coding |
| 8 | [Mistral Docs](https://docs.mistral.ai/getting-started/models) | Docs | NeMo, Large 2 |
| 9 | [Artificial Analysis Leaderboard](https://artificialanalysis.ai/leaderboards/models) | Benchmark | Live rankings |
| 10 | [Vellum LLM Leaderboard](https://www.vellum.ai/llm-leaderboard) | Benchmark | Quality comparison |
| 11 | [Stanford HAI 2025 Report](https://hai.stanford.edu/ai-index/2025-ai-index-report/technical-performance) | Report | Industry trends |
| 12 | [HuggingFace Open LLM](https://huggingface.co/spaces/open-llm-leaderboard/open_llm_leaderboard) | Benchmark | Open-source rankings |
| 13 | [OpenAI Pricing](https://platform.openai.com/docs/pricing) | Pricing | Token costs |
| 14 | [Anthropic Pricing](https://www.anthropic.com/pricing) | Pricing | Claude costs |
| 15 | [Price Per Token](https://pricepertoken.com/) | Tool | Cost calculator |

---

*–ü–æ—Å–ª–µ–¥–Ω–µ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ: 2024-12-28*

---

[[ai-engineering-moc|‚Üê AI Engineering MOC]] | [[llm-fundamentals|‚Üê LLM Fundamentals]] | [[prompt-engineering-masterclass|Prompts ‚Üí]]

---

*–ü—Ä–æ–≤–µ—Ä–µ–Ω–æ: 2026-01-09*
