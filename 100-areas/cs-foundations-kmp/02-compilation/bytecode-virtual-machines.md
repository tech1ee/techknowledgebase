---
title: "Bytecode и виртуальные машины: как код исполняется без железа"
created: 2026-01-04
modified: 2026-02-10
type: deep-dive
status: published
tags:
  - topic/cs-foundations
  - type/deep-dive
  - level/intermediate
related:
  - "[[compilation-pipeline]]"
  - "[[native-compilation-llvm]]"
  - "[[interpretation-jit]]"
prerequisites:
  - "[[compilation-pipeline]]"
---

# Bytecode и виртуальные машины: как код исполняется без железа

> **TL;DR:** Bytecode — промежуточный код между исходником и машинным кодом. Виртуальная машина (VM) исполняет bytecode, скрывая детали железа. JVM использует stack-based архитектуру, Dalvik был register-based, WASM — stack-based с sandbox security. Для KMP критично: Kotlin компилирует в JVM bytecode (Android), DEX (через Android toolchain), LLVM IR (iOS), JavaScript и WASM (Web) — все это разные форматы исполнения.

---

## Зачем это знать

Каждое Android-приложение работает внутри виртуальной машины. Каждая Java-программа на сервере — внутри JVM. Каждая веб-страница, использующая WebAssembly — через WASM-runtime. Виртуальные машины и bytecode — невидимая инфраструктура, на которой держится большая часть современного программного обеспечения.

Для разработчика понимание VM — это не академическое знание, а практический инструмент. Когда приложение "тормозит при первом запуске" — это warmup виртуальной машины. Когда stack trace показывает непонятные имена — это внутренние имена bytecode. Когда одно и то же KMP-приложение ведёт себя по-разному на Android и iOS — разница в runtime: ART против native binary.

---

## Prerequisites

| Тема | Зачем нужно | Где изучить |
|------|-------------|-------------|
| **Compilation Pipeline** | Понять откуда берётся bytecode | [[compilation-pipeline]] |
| **Stack vs Heap** | Понять работу operand stack | [[memory-model-fundamentals]] |

---

## Терминология

| Термин | Что это | Аналогия |
|--------|---------|----------|
| **Bytecode** | Инструкции для виртуальной машины | Нотные знаки для музыканта |
| **Virtual Machine** | Программа, исполняющая bytecode | Музыкант, играющий по нотам |
| **Opcode** | Код операции в bytecode | Одна нота |
| **Operand Stack** | Стек для вычислений в VM | Стопка тарелок |
| **Class Loading** | Загрузка кода в JVM | Открыть книгу на нужной странице |
| **JIT** | Just-In-Time компиляция | Перевод на лету |
| **AOT** | Ahead-Of-Time компиляция | Заранее подготовленный перевод |
| **DEX** | Dalvik Executable формат | Android-специфичный bytecode |

---

## ЧТО такое виртуальная машина и ЗАЧЕМ нужен слой абстракции

### Фундаментальная проблема: один код — много платформ

Представь себе писателя, который хочет, чтобы его книгу читали во всём мире. У него два варианта: написать отдельный перевод для каждой страны (100+ переводов!) или создать некий "универсальный язык", который местные переводчики в каждой стране понимают и могут перевести на свой язык. Второй вариант — это идея виртуальной машины.

В начале 90-х каждая программа компилировалась под конкретную платформу. Хочешь поддержать Windows, Mac и UNIX? Компилируй три раза, поддерживай три версии, борись с тремя наборами багов. Каждый процессор (x86, SPARC, PowerPC, MIPS) понимал свой набор инструкций. Программа для одного процессора была бессмыслицей для другого — как текст на китайском для человека, знающего только русский.

### Историческая справка: от p-code до JVM

Идея виртуальной машины старше, чем многие думают. Она не начинается с Java.

**1966: BCPL и O-code.** Мартин Ричардс создал язык BCPL с промежуточным кодом O-code. Компилятор генерировал O-code, который интерпретировался на целевой машине. Идея портативности через промежуточный код была рождена.

**1970: Pascal и P-code.** Никлаус Вирт разработал P-code (pseudo-code) для Pascal. P-code machine — виртуальный компьютер с простым набором инструкций. Компилятор Pascal генерировал P-code, который можно было перенести на любую машину, написав только интерпретатор P-code. Это позволило Pascal распространиться на десятки платформ.

**1983: Smalltalk и высокоуровневый bytecode.** Smalltalk-80 использовал bytecode с виртуальной машиной. Именно здесь появилась идея inline caching для оптимизации dynamic dispatch. Smalltalk VM стала прародительницей многих современных техник.

**1991: Sun Microsystems и проект Green.** Джеймс Гослинг работал над языком Oak для "интерактивного телевидения" — set-top boxes разных производителей. Проблема: каждый box имел свой процессор. Писать отдельный код под каждый — невозможно. Нужен был единый промежуточный формат.

**1995: Java и "Write Once, Run Anywhere".** Проект Oak превратился в Java. Маркетинговый слоган "Write Once, Run Anywhere" описывал суть идеи: компилятор производит bytecode, а JVM на каждой платформе исполняет его. Один .class файл работал на Windows, Mac, Linux, Solaris — без перекомпиляции.

```
┌─────────────────────────────────────────────────────────────────┐
│              ЭВОЛЮЦИЯ ВИРТУАЛЬНЫХ МАШИН                        │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│   1966  BCPL O-code ── первый промежуточный код                │
│   1970  Pascal P-code ── портативность через интерпретацию     │
│   1983  Smalltalk VM ── inline caching, GC                     │
│   1995  Java JVM ── "Write Once, Run Anywhere"                 │
│   2000  .NET CLR ── multi-language VM                          │
│   2008  Dalvik VM ── register-based для мобильных              │
│   2014  ART ── AOT+JIT гибрид для Android                     │
│   2017  WebAssembly ── bytecode для браузера                   │
│                                                                 │
│   Каждое поколение решало проблему предыдущего:                │
│   переносимость → производительность → безопасность            │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

### ПОЧЕМУ промежуточный слой, а не прямая компиляция

Скептики всегда спрашивали: "Зачем промежуточный слой? Он же замедляет!" И скептики были частично правы — ранние VM были медленнее native-кода в 10-50 раз. Но промежуточный слой давал три преимущества, которые перевесили потерю скорости:

**Портативность.** Один bytecode работает везде, где есть VM. Для FORTRAN-программ 1980-х нужна была перекомпиляция для каждого нового сервера. Для Java-программ — только наличие JVM.

**Безопасность.** VM может проверять bytecode перед исполнением: не обращается ли он к запрещённой памяти? Не пытается ли обойти систему типов? Это невозможно с native-кодом — процессор исполняет любые инструкции без проверки.

**Динамическая оптимизация.** Парадоксально, но промежуточный слой может сделать код *быстрее* native-компиляции. JIT-компилятор в VM видит реальные данные и оптимизирует код под них. AOT-компилятор работает "вслепую" — он не знает, какие ветки кода будут выполняться чаще.

```
┌─────────────────────────────────────────────────────────────────┐
│                    "WRITE ONCE, RUN ANYWHERE"                   │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│   БЕЗ BYTECODE:                                                 │
│   Source → Windows .exe                                         │
│   Source → Mac binary                                           │
│   Source → Linux binary                                         │
│   Source → SPARC binary                                         │
│   = 4 компиляции, 4 поддержки                                   │
│                                                                 │
│   С BYTECODE:                                                   │
│   Source → Bytecode (.class)                                    │
│              ↓                                                  │
│         ┌────┴────────────────────────────┐                     │
│         ↓           ↓          ↓          ↓                     │
│     JVM Win    JVM Mac    JVM Linux   JVM SPARC                 │
│   = 1 компиляция, VM на каждой платформе                        │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

Мы поняли, зачем нужна виртуальная машина. Теперь разберёмся, как она устроена внутри — и почему существуют два принципиально разных подхода к её архитектуре.

---

## Stack-based vs Register-based: две архитектуры VM

### Суть различия

Любая VM — это программа, которая притворяется компьютером. У неё есть набор инструкций (opcodes), память для данных, и способ хранить промежуточные результаты вычислений. Разница — в том, *где* хранятся эти промежуточные результаты.

**Stack-based VM** хранит операнды на стеке — воображаемой "стопке тарелок". Каждая операция берёт операнды с вершины стека и кладёт результат обратно. Инструкции не указывают, *откуда* брать данные — всегда с вершины стека.

**Register-based VM** хранит операнды в виртуальных регистрах — пронумерованных "ячейках". Каждая инструкция явно указывает, какие регистры использовать.

### Аналогия: калькулятор vs тетрадка

Представь, что ты вычисляешь `2 + 3 * 4`.

**Stack-based (калькулятор с обратной польской записью):** У тебя есть калькулятор с кнопками PUSH и POP. Ты нажимаешь: PUSH 3, PUSH 4, MUL (калькулятор забирает два верхних числа, умножает, кладёт результат), PUSH 2, ADD. На дисплее — 14. Ты не говоришь калькулятору *где* хранить числа — он сам знает: на стеке.

**Register-based (тетрадка с ячейками):** У тебя тетрадка с пронумерованными ячейками. Ты пишешь: "в ячейку A положить 3, в ячейку B положить 4, в ячейку C записать A * B, в ячейку D записать 2 + C". Каждая инструкция явно говорит, какие ячейки использовать.

### Пошаговое исполнение: как JVM вычисляет `2 + 3 * 4`

Рассмотрим, как стековая JVM выполняет выражение `2 + 3 * 4` пошагово. Bytecode-инструкции берут данные со стека и кладут результат обратно. Стек растёт вверх — последний положенный элемент оказывается на вершине.

```
┌─────────────────────────────────────────────────────────────────┐
│        ПОШАГОВОЕ ИСПОЛНЕНИЕ НА STACK-BASED JVM                 │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│   Выражение: 2 + 3 * 4                                         │
│   Порядок: сначала 3 * 4 = 12, потом 2 + 12 = 14              │
│                                                                 │
│   Шаг 1: iconst_3   "Положить 3 на стек"                      │
│          Стек: [ 3 ]                                            │
│          Стек был пуст. Теперь на вершине — число 3.            │
│                                                                 │
│   Шаг 2: iconst_4   "Положить 4 на стек"                      │
│          Стек: [ 3, 4 ]                                         │
│          Число 4 легло поверх тройки. Вершина = 4.              │
│                                                                 │
│   Шаг 3: imul       "Умножить два верхних элемента"            │
│          VM забирает 4 (вершина) и 3 (под ней).                │
│          Вычисляет: 3 * 4 = 12.                                 │
│          Кладёт 12 на стек.                                     │
│          Стек: [ 12 ]                                           │
│                                                                 │
│   Шаг 4: iconst_2   "Положить 2 на стек"                      │
│          Стек: [ 12, 2 ]                                        │
│                                                                 │
│   Шаг 5: iadd       "Сложить два верхних элемента"             │
│          VM забирает 2 (вершина) и 12 (под ней).               │
│          Вычисляет: 12 + 2 = 14.                                │
│          Кладёт 14 на стек.                                     │
│          Стек: [ 14 ]                                           │
│                                                                 │
│   Результат на вершине стека: 14                                │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

Обрати внимание: ни одна инструкция не указывает *где* хранить данные. Всё идёт через стек. Инструкция `imul` не говорит "умножить регистр R1 на R2" — она говорит "умножить два верхних элемента стека". Это делает каждую инструкцию короткой (1 байт для opcode), но количество инструкций больше (нужны push/pop).

### Как то же выражение работает на register-based VM

На register-based VM (как Dalvik) каждая инструкция явно указывает номера регистров:

```
┌─────────────────────────────────────────────────────────────────┐
│        ПОШАГОВОЕ ИСПОЛНЕНИЕ НА REGISTER-BASED VM               │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│   Выражение: 2 + 3 * 4                                         │
│                                                                 │
│   Шаг 1: const v0, 3     "В регистр v0 записать 3"            │
│          v0 = 3                                                 │
│                                                                 │
│   Шаг 2: const v1, 4     "В регистр v1 записать 4"            │
│          v0 = 3, v1 = 4                                         │
│                                                                 │
│   Шаг 3: mul v2, v0, v1  "v2 = v0 * v1"                       │
│          v0 = 3, v1 = 4, v2 = 12                                │
│                                                                 │
│   Шаг 4: const v3, 2     "В регистр v3 записать 2"            │
│          v0 = 3, v1 = 4, v2 = 12, v3 = 2                       │
│                                                                 │
│   Шаг 5: add v4, v3, v2  "v4 = v3 + v2"                       │
│          v4 = 14                                                │
│                                                                 │
│   Результат в регистре v4: 14                                   │
│                                                                 │
│   5 инструкций, но каждая длиннее (содержит адреса регистров)  │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

### Сравнение подходов

| Критерий | Stack-based (JVM) | Register-based (Dalvik) |
|----------|-------------------|------------------------|
| **Размер bytecode** | Компактный (инструкции 1-3 байта) | Больше (адреса регистров в каждой инструкции) |
| **Количество инструкций** | Больше (нужны push/pop) | Меньше (прямой доступ к регистрам) |
| **Простота реализации** | Проще (не нужен register allocator) | Сложнее (нужно управлять регистрами) |
| **Скорость интерпретации** | Медленнее (dispatch overhead) | Быстрее (меньше инструкций) |
| **После JIT** | Разница минимальна | Разница минимальна |

> **Ключевая идея:** Stack-based VM компактнее, register-based — быстрее при интерпретации. После JIT-компиляции обе архитектуры дают примерно одинаковую производительность, потому что JIT переводит bytecode в native-код, игнорируя виртуальные стеки и регистры.

### ПОЧЕМУ Dalvik выбрал register-based: решение Google

В 2005-2007 годах Дэн Борнштейн в Google проектировал Dalvik VM для Android. Выбор register-based архитектуры был осознанным решением, продиктованным спецификой мобильных устройств того времени.

**Проблема:** мобильные процессоры 2007 года (ARM11, ~400 MHz) были слабы для JIT-компиляции. Dalvik должен был работать преимущественно в режиме интерпретации.

**Решение:** register-based архитектура генерирует меньше инструкций — на 47% меньше, по исследованию Shi et al. (2008). Для интерпретатора каждая инструкция — это dispatch (определение, что делать), а dispatch — самая дорогая операция. Меньше инструкций = меньше dispatch'ей = быстрее.

**Почему не JVM format?** Google не мог просто взять JVM bytecode — Sun (позже Oracle) владела лицензией. Создание собственного формата (DEX) также имело юридические причины. Но техническое обоснование было реальным: DEX лучше подходил для мобильных ограничений.

**Дополнительный аргумент:** register-based bytecode ближе к реальным ARM-регистрам. Маппинг "виртуальный регистр → физический регистр" проще, чем "стековая операция → регистровая инструкция".

С Android 5.0 (2014) Google заменил Dalvik на ART, добавив AOT-компиляцию. С Android 7.0 — гибрид AOT+JIT. Архитектура bytecode (register-based) осталась, но способ исполнения радикально изменился.

Мы разобрались в архитектурах VM. Теперь погрузимся в конкретику — как устроена JVM, главная виртуальная машина экосистемы Kotlin.

---

## КАК работает JVM

### Жизненный цикл класса

Когда программа использует класс, JVM проходит через три этапа:

```
┌─────────────────────────────────────────────────────────────────┐
│                    JVM CLASS LIFECYCLE                          │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│   1. LOADING (загрузка)                                         │
│      ClassLoader находит .class файл                            │
│      Читает bytecode в память                                   │
│      Создаёт объект Class                                       │
│                                                                 │
│   2. LINKING (связывание)                                       │
│      ├── Verification: проверка bytecode на корректность        │
│      ├── Preparation: выделение памяти для static полей         │
│      └── Resolution: разрешение символьных ссылок               │
│                                                                 │
│   3. INITIALIZATION (инициализация)                             │
│      Выполнение static блоков и инициализаторов                 │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

Аналогия: представь библиотеку. Loading — найти книгу на полке и достать её. Linking — проверить, что страницы не повреждены, что все ссылки на другие книги существуют. Initialization — открыть книгу на нужной главе и подготовить закладки.

Важная деталь: JVM загружает классы *лениво* (lazy loading). Класс не загружается, пока он реально не понадобится. Это ускоряет старт приложения — не нужно загружать все 10000 классов при запуске.

### ClassLoader иерархия

JVM имеет три встроенных загрузчика:

**Bootstrap ClassLoader** — загружает java.lang.*, java.util.* и другие core классы. Написан на native коде, не виден из Java. Это "фундамент" — без него JVM не может работать.

**Platform ClassLoader** — загружает расширения платформы. Раньше назывался Extension ClassLoader.

**Application ClassLoader** — загружает классы приложения из classpath. Это "ваш" код.

Загрузчики работают по принципу делегирования: при запросе класса сначала спрашивают родителя. Если родитель не находит — пробуют сами. Это обеспечивает безопасность: никто не может подменить java.lang.String своей версией, потому что Bootstrap ClassLoader всегда загрузит настоящую.

```
                Bootstrap (java.*)
                    ↑
              Platform (extensions)
                    ↑
             Application (your code)
                    ↑
            Custom ClassLoaders
```

Зачем нужны custom ClassLoader'ы? Например, сервер приложений (Tomcat, Jetty) использует отдельный ClassLoader для каждого веб-приложения. Это позволяет двум приложениям использовать разные версии одной библиотеки без конфликта — каждый ClassLoader "видит" только свою версию.

### Bytecode Verification — почему VM не доверяет коду

JVM не доверяет bytecode слепо. Перед исполнением проверяет:

- **Формат корректен** — magic number (`CAFEBABE`), version, structure
- **Типы совместимы** — нельзя сложить int и String
- **Stack не переполняется** — защита от underflow/overflow
- **Доступ легален** — private поля недоступны извне

Зачем это нужно? Bytecode может быть создан вручную, с ошибками или злым умыслом. Компилятор не генерирует плохой код, но hex-редактор — может. Вредоносный bytecode мог бы, например, читать произвольную память или вызывать private-методы — верификатор это предотвращает.

Аналогия: аэропортовый контроль безопасности. Авиакомпания (компилятор) не отправит пассажира с оружием. Но пассажир мог пронести что-то мимо авиакомпании. Поэтому аэропорт (VM) проверяет каждого сам.

Это принципиальное отличие VM от native-исполнения: native binary исполняется процессором без проверок. Процессор не знает, "правильный" это код или нет — он просто выполняет инструкции. VM добавляет слой безопасности.

### Исполнение bytecode

После верификации JVM исполняет код. Два режима:

**Interpretation** — читает и выполняет инструкции по одной. Медленно, но сразу готов. Каждая инструкция: fetch (прочитать), decode (определить тип), execute (выполнить). На каждую операцию — десятки машинных инструкций overhead.

**JIT Compilation** — компилирует bytecode в native код. Быстро после прогрева, но требует время на компиляцию. JIT-компилятор (C1 и C2 в HotSpot) анализирует, какие методы вызываются часто, и компилирует их в native-код.

Современные JVM используют tiered compilation: сначала интерпретируют, затем компилируют "тёплые" методы с базовыми оптимизациями (C1), а "горячие" — с агрессивными оптимизациями (C2). Подробнее об этом — в [[interpretation-jit]].

---

## Android: Dalvik → ART

### DEX формат

Android не использует .class файлы напрямую. Toolchain конвертирует их в DEX (Dalvik Executable):

```
.java → javac → .class → dx/d8 → .dex → APK
```

Почему не использовать .class напрямую? DEX оптимизирован для мобильных устройств:

**Объединение классов.** В JVM каждый класс — отдельный .class файл. В Android приложении тысячи классов — тысячи файлов = тысячи обращений к файловой системе. DEX объединяет классы в один файл, уменьшая overhead.

**Дедупликация констант.** Если 50 классов используют строку "Hello" — в .class файлах она хранится 50 раз. В DEX — один раз в общем constant pool.

**Register-based инструкции.** Меньше инструкций = быстрее интерпретация на слабых мобильных процессорах.

### Dalvik VM (2008-2014)

Первый Android runtime. Register-based VM с JIT компиляцией:

- Trace-based JIT — компилирует горячие участки кода (traces), а не целые методы
- Остальное интерпретирует
- Проблема: JIT при каждом запуске приложения. Выключил телефон — все оптимизации потеряны

Trace-based JIT был хорошим решением для слабых процессоров: он компилировал только самые горячие пути исполнения, экономя память. Но пользователи замечали: приложение "тормозит" первые секунды, потом разгоняется. Каждый запуск — заново.

### ART (Android Runtime): революция Android 5.0

С Android 5.0 (2014) Google заменил Dalvik на ART. Ключевое изменение — AOT-компиляция при установке.

**AOT компиляция (Android 5.0-6.0):** При установке приложения утилита `dex2oat` компилирует весь DEX в native код. Результат сохраняется в .odex/.oat файл. При запуске — никакой компиляции, сразу native-код.

**Преимущества:**
- Быстрый холодный старт (код уже скомпилирован)
- Меньше battery drain (нет JIT при работе)
- Лучшее garbage collection (concurrent GC вместо stop-the-world)

**Проблема:** полная AOT-компиляция увеличивала время установки (минуты для больших приложений) и размер на диске (native-код больше bytecode).

**Гибрид AOT+JIT (Android 7.0+):** Google нашёл баланс. При установке — минимальная AOT-компиляция (или никакая). При работе — JIT компилирует горячие методы. Профиль горячего кода сохраняется. При зарядке ночью — AOT-компиляция по профилю. Каждый следующий запуск — быстрее предыдущего.

```
┌─────────────────────────────────────────────────────────────────┐
│                    DALVIK vs ART                                │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│   DALVIK (до Android 5.0):                                      │
│   ┌───────┐     ┌────────────┐     ┌────────────┐               │
│   │  DEX  │ ──▶ │Interpreter │ ──▶ │ JIT (hot)  │               │
│   └───────┘     └────────────┘     └────────────┘               │
│   При каждом запуске. Оптимизации не сохраняются.               │
│                                                                 │
│   ART (Android 5.0-6.0):                                        │
│   ┌───────┐     ┌────────────┐     ┌────────────┐               │
│   │  DEX  │ ──▶ │  dex2oat   │ ──▶ │ .odex/.oat │               │
│   └───────┘     └────────────┘     └────────────┘               │
│   При установке. Долгая установка, быстрый запуск.             │
│                                                                 │
│   ART (Android 7.0+):                                           │
│   ┌───────┐     ┌────────────┐     ┌────────────┐               │
│   │  DEX  │ ──▶ │JIT + Profile│──▶ │ AOT ночью  │               │
│   └───────┘     └────────────┘     └────────────┘               │
│   Гибрид. Учится при использовании, оптимизирует при зарядке.  │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

Аналогия: Dalvik — повар, который каждое утро заново учит рецепт из книги. ART 5.0 — повар, который заранее выучил все рецепты наизусть (долгая подготовка, но быстрая работа). ART 7.0+ — повар, который учит рецепты по мере готовки, а вечером записывает самые частые в блокнот.

---

## WebAssembly (WASM)

### Зачем нужен WASM

JavaScript был единственным языком в браузере. Он хорош для UI, но медленный для вычислений. Игры, видео-редакторы, CAD — всё тормозило. Предшественник WASM — asm.js — показал, что оптимизированный подмножество JavaScript может быть быстрым, но оставался текстовым форматом с ограничениями.

WebAssembly (2017) — низкоуровневый bytecode для браузера. Это не замена JavaScript, а дополнение: вычислительно тяжёлые задачи на WASM, UI и DOM-манипуляции — на JavaScript.

### Архитектура WASM

Stack-based VM с linear memory. Выбор stack-based был обоснован: компактный bytecode быстрее передаётся по сети (каждый байт на счету в вебе), а JIT-компиляция нивелирует overhead стековых операций.

```
┌─────────────────────────────────────────────────────────────────┐
│                    WASM АРХИТЕКТУРА                             │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│   ┌────────────────────────────────────────────────────┐        │
│   │                    WASM Module                      │        │
│   ├────────────────────────────────────────────────────┤        │
│   │  Functions (code)                                  │        │
│   │  Linear Memory (heap — непрерывный массив байтов)  │        │
│   │  Tables (function pointers)                        │        │
│   │  Globals                                           │        │
│   └────────────────────────────────────────────────────┘        │
│                            ↓                                    │
│   ┌────────────────────────────────────────────────────┐        │
│   │              WASM Runtime (браузер)                 │        │
│   │  ─────────────────────────────────────────────     │        │
│   │  Sandboxed execution                               │        │
│   │  No direct access to DOM/APIs                      │        │
│   │  Memory isolated from host                         │        │
│   └────────────────────────────────────────────────────┘        │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

### Security модель: почему WASM безопаснее

WASM был спроектирован с безопасностью как первоприоритетной целью. В отличие от JVM, которая добавляла безопасность постепенно, WASM строил её с нуля:

- **Memory sandbox** — WASM не может читать память браузера. Linear memory — изолированный массив байтов, WASM видит только его.
- **Нет raw pointers** к host системе. Указатели внутри linear memory — это просто индексы массива, не настоящие адреса памяти.
- **Детерминистичное исполнение** — одинаковый результат везде. Нет undefined behavior, нет uninitialized memory reads.
- **Формальная верификация** спецификации — WASM spec написана на математическом языке и формально доказана корректной.

### WASM 3.0 (2025)

Новая версия добавила критически важные возможности:
- **Garbage Collection** — managed memory для языков с GC (Kotlin, Java, Dart)
- **64-bit memory** — до 16 экзабайт вместо 4GB
- **Tail calls** — для функциональных языков
- **Exception handling** — try/catch на уровне WASM

WasmGC особенно важен для Kotlin: без него Kotlin/Wasm должен был нести свой GC внутри WASM-модуля (увеличивая размер). С WasmGC — GC предоставляется runtime'ом браузера.

### Kotlin/Wasm

С декабря 2024 все major браузеры поддерживают WasmGC. Compose Multiplatform работает на Kotlin/Wasm с производительностью, приближающейся к JVM.

---

## Kotlin и разные bytecode

KMP использует разные backend'ы компилятора. Один и тот же Kotlin-код трансформируется в принципиально разные форматы — каждый оптимизирован под свой runtime.

| Target | Формат | VM/Runtime | Особенности |
|--------|--------|------------|-------------|
| **JVM** | .class (JVM bytecode) | JVM | Полный доступ к Java |
| **Android** | .dex | ART | Через Android toolchain |
| **Native** | Binary (через LLVM) | Нет VM | AOT, прямое исполнение |
| **JS** | .js | JS Engine | Interop с JavaScript |
| **Wasm** | .wasm | WASM Runtime | Browser sandbox |

Это означает, что один и тот же `fun greet() = "Hello"` превращается в stack-based инструкции для JVM, register-based для Android DEX, native-код через LLVM для iOS, и stack-based WASM-инструкции для браузера. Четыре совершенно разных представления одной функции.

### Как смотреть bytecode

Следующие команды позволяют заглянуть "под капот" компилятора и увидеть, что именно генерируется для JVM. Это полезно для отладки производительности и понимания, как Kotlin-конструкции отображаются на bytecode.

```bash
# Скомпилировать Kotlin файл в JVM bytecode
kotlinc Main.kt -include-runtime -d Main.jar

# Посмотреть bytecode в человекочитаемом виде
javap -c -p MainKt
```

Каждая строка вывода `javap` — одна bytecode-инструкция. Инструкции начинающиеся на `i` работают с `int` (iconst, iload, iadd), на `a` — с references (aload, astore, areturn), на `d` — с double.

Для просмотра Kotlin IR (промежуточного представления до генерации bytecode):

```bash
# Показать IR-форму, которую видит backend компилятора
kotlinc -Xprint-ir Main.kt
```

IR показывает, как компилятор "понял" ваш код после всех трансформаций frontend'а — desugaring лямбд, inline-функций, smart casts.

---

## Распространённые заблуждения

| Миф | Реальность | Почему так думают |
|-----|------------|-------------------|
| JVM всегда медленнее native | С JIT может быть быстрее — runtime-оптимизации под реальные данные | Ранние JVM (1995-2000) действительно были медленными |
| WASM только для браузера | Standalone runtimes (Wasmtime, Wasmer) работают везде | WASM родился в браузере, но вышел за его пределы |
| Bytecode = медленно | JIT компилирует в native код. Производительность сопоставима | Интерпретация bytecode действительно медленная, но JIT это исправляет |
| Register VM всегда быстрее stack VM | С JIT разница минимальна. Преимущество register-based — только в интерпретации | При интерпретации register-based действительно быстрее |
| JVM bytecode и WASM — одно и то же | Совершенно разные форматы с разными целями и security-моделями | Оба являются bytecode для VM |

---

## Подводные камни

### Когда понимание VM критически важно

**Debugging:**
- Stack trace показывает bytecode offsets — понимание bytecode помогает читать stack traces
- Memory profilers работают на уровне VM — VisualVM, MAT показывают JVM-специфичные метрики
- `OutOfMemoryError` на JVM — не та же проблема, что memory issues на Native

**Performance:**
- JIT warmup time — первые запуски медленнее. Для serverless и CLI это проблема
- Method inlining зависит от bytecode-размера метода — слишком большие методы JVM не инлайнит
- Escape analysis работает на уровне VM — если объект "убегает" из метода, он не может быть аллоцирован на стеке

**KMP специфика:**
- Разные VM = разное поведение. Например: integer overflow на JVM — wraparound, на Native — тоже, но на JS — другое поведение для больших чисел
- Interop с native требует понимания границ VM — передача данных между Kotlin/Native и Swift идёт через специальный мост
- Coroutines работают по-разному: на JVM — через ContinuationInterceptor, на Native — через native threading

---

## Связь с другими темами

**[[compilation-pipeline]]** — предшествующая тема. Pipeline показывает, как код превращается в bytecode. Backend компилятора генерирует bytecode как выходной формат. Понимание pipeline объясняет, почему bytecode выглядит так, а не иначе: каждая конструкция языка (if, for, lambda) проходит через все этапы и превращается в последовательность bytecode-инструкций. Рекомендуется прочитать перед этой статьёй.

**[[native-compilation-llvm]]** — альтернативный подход. Вместо bytecode + VM — native binary через LLVM. Kotlin/Native идёт этим путём для iOS. Сравнение подходов помогает понять, почему для одних задач лучше VM (серверы, Android), для других — native (iOS, CLI). Рекомендуется как следующий шаг.

**[[interpretation-jit]]** — глубокое погружение в то, как VM исполняет bytecode. Эта статья объясняет *что* такое bytecode и VM, interpretation-jit объясняет *как* VM превращает bytecode в быстрый native-код через JIT-компиляцию. Рекомендуется после native-compilation-llvm.

---

## Источники и дальнейшее чтение

- **Lindholm, T. et al. (2014). The Java Virtual Machine Specification (Java SE 8 Edition).** — Официальная спецификация JVM. Описывает каждую bytecode-инструкцию, class file format, верификацию. Тяжёлое, но незаменимое чтение для тех, кто хочет понять JVM на уровне спецификации.

- **Smith, J. & Nair, R. (2005). Virtual Machines: Versatile Platforms for Systems and Processes.** — Фундаментальная книга о виртуальных машинах всех видов: от process VM (JVM) до system VM (VMware). Объясняет историю, архитектуру и trade-offs разных подходов. Рекомендуется для глубокого понимания, почему VM устроены именно так.

- **Nystrom, R. (2021). Crafting Interpreters: A Bytecode Virtual Machine.** — Практическое руководство по созданию bytecode VM с нуля. Часть III ("A Bytecode Virtual Machine") проводит через реализацию stack-based VM шаг за шагом. Лучший ресурс для "почувствовать" как VM работает изнутри.

- **Shi, Y. et al. (2008). Virtual Machine Showdown: Stack vs. Registers.** — Академическое сравнение stack-based и register-based подходов. Показывает, что register-based сокращает количество инструкций на 47%, но увеличивает размер bytecode. Полезно для понимания решения Google при создании Dalvik.

- [AOSP: Android Runtime](https://source.android.com/docs/core/runtime) — Официальная документация ART. Объясняет гибридную AOT+JIT модель и profile-guided compilation.

- [JetBrains: Kotlin/Wasm](https://kotlinlang.org/docs/wasm-overview.html) — Документация по Kotlin и WebAssembly. Актуальное состояние WasmGC и Compose Multiplatform на Web.

---

*Проверено: 2026-02-10*
