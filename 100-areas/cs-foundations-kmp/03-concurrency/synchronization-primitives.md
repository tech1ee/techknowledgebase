---
title: "Synchronization Primitives: mutex, semaphore и другие"
created: 2026-01-04
modified: 2026-02-10
type: deep-dive
status: published
tags:
  - topic/cs-foundations
  - type/deep-dive
  - level/advanced
related:
  - "[[processes-threads-fundamentals]]"
  - "[[concurrency-vs-parallelism]]"
  - "[[async-models-overview]]"
prerequisites:
  - "[[processes-threads-fundamentals]]"
  - "[[concurrency-vs-parallelism]]"
  - "[[memory-model-fundamentals]]"
---

# Synchronization Primitives: mutex, semaphore и другие

> **TL;DR:** Примитивы синхронизации координируют доступ к shared resources. Mutex — механизм блокировки (один владелец). Semaphore — механизм сигнализации (счётчик). Deadlock возникает при 4 условиях Coffman: mutual exclusion + hold and wait + no preemption + circular wait. Лучшая синхронизация — её отсутствие: immutable data, message passing, thread confinement.

---

## Prerequisites

| Тема | Зачем нужно | Где изучить |
|------|-------------|-------------|
| **Процессы и потоки** | Что синхронизируем | [[processes-threads-fundamentals]] |
| **Concurrency vs Parallelism** | Когда нужна синхронизация | [[concurrency-vs-parallelism]] |
| **Memory Model** | Видимость данных между потоками | [[memory-model-fundamentals]] |

---

## Терминология

| Термин | Что это | Аналогия из жизни |
|--------|---------|-------------------|
| **Mutex** | Блокировка с владельцем | Ключ от туалета в кофейне |
| **Semaphore** | Счётчик доступных ресурсов | Счётчик свободных мест на парковке |
| **Monitor** | Mutex + condition variables | Комната ожидания с дверным замком и звонком |
| **Critical Section** | Код, работающий с shared data | Кабинка банкомата |
| **Deadlock** | Взаимная блокировка | Два человека в узком коридоре |
| **Race Condition** | Результат зависит от порядка | Два кассира обновляют баланс |
| **Spinlock** | Блокировка с активным ожиданием | Стоять у двери и дёргать ручку каждую секунду |
| **Priority Inversion** | Низкоприоритетная задача блокирует высокоприоритетную | Стажёр занял единственный принтер, директор ждёт |

---

## ПОЧЕМУ нужна синхронизация: история одного бага

### Race condition как история

Представь банковское приложение. У клиента на счёте 1000 рублей. Его жена одновременно оплачивает покупку на 800 рублей с телефона, а он снимает 800 рублей в банкомате. Оба устройства отправляют запрос серверу одновременно.

**Что должно произойти:** Первая операция проходит (баланс = 200), вторая отклоняется ("недостаточно средств").

**Что может произойти без синхронизации:**

Шаг 1: Поток A (банкомат) читает баланс: 1000.
Шаг 2: Поток B (телефон) читает баланс: 1000. (Поток A ещё не записал новый баланс!)
Шаг 3: Поток A вычисляет 1000 - 800 = 200, записывает баланс = 200.
Шаг 4: Поток B вычисляет 1000 - 800 = 200, записывает баланс = 200.

Результат: оба сняли по 800 рублей, а на счёте осталось 200 вместо -600. Банк потерял 600 рублей. Это **race condition** — результат зависит от непредсказуемого порядка выполнения потоков.

Эта история — не абстракция. В 2012 году подобный баг в системе Knight Capital Group привёл к потере $440 миллионов за 45 минут. Race condition в торговом алгоритме отправлял дублированные заказы на биржу.

### Формальное определение проблемы

Race condition возникает, когда выполнены **все три условия**:
1. Два или более потоков обращаются к одним данным
2. Хотя бы один поток **пишет** (если все только читают — проблемы нет)
3. Нет механизма **упорядочивания** доступа

Устрани любое из трёх — race condition исчезнет. Синхронизация устраняет третье условие. Immutable data устраняет второе. Thread confinement устраняет первое.

```
┌─────────────────────────────────────────────────────────────┐
│                    RACE CONDITION                           │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│   Thread A              Thread B                            │
│   ────────              ────────                            │
│   read counter = 0                                          │
│                         read counter = 0                    │
│   add 1 → 1                                                 │
│                         add 1 → 1                           │
│   write counter = 1                                         │
│                         write counter = 1                   │
│                                                             │
│   Результат: counter = 1 (потерян один increment!)         │
│                                                             │
│   ПРОБЛЕМА: read-modify-write не атомарна                  │
└─────────────────────────────────────────────────────────────┘
```

### Историческая справка: Дейкстра и THE System

**1962-1963:** Эдсгер Дейкстра разрабатывал операционную систему для компьютера Electrologica X8 в Технологическом университете Эйндховена (THE — Technische Hogeschool Eindhoven). Это была одна из первых ОС, построенных с нуля для многозадачности.

Проблема: на одном процессоре выполняются несколько программ. Каждая хочет использовать принтер, терминал, диск. Без координации — хаос: два процесса могут одновременно начать печатать, и на бумаге получится смесь двух документов.

**Решение Дейкстры — семафор (1965).** Простой счётчик с двумя атомарными операциями:
- **P** (probeer te verlagen — "попробовать уменьшить", нидерландский) — уменьшить счётчик или ждать
- **V** (vrijgave — "освобождение") — увеличить счётчик

Терминология взята из **железнодорожных семафоров**: поезд ждёт зелёного сигнала, чтобы занять участок пути. Семафор гарантирует, что на одном участке путей будет только один поезд — иначе столкновение.

**1968:** Публикация в Communications of the ACM. Эта статья стала фундаментом для всех современных примитивов синхронизации.

> **Ключевая идея:** Синхронизация — это не "добавочная опция". Это **необходимость**, вытекающая из shared mutable state. Если несколько потоков пишут в общую память без координации — программа сломана, даже если "обычно работает".

Мы разобрали, почему синхронизация необходима. Теперь — какие инструменты для неё существуют.

---

## ЧТО такое Mutex

### Определение и суть

Mutex (Mutual Exclusion) — примитив синхронизации, гарантирующий, что только один поток может находиться в критической секции в любой момент времени. Это самый базовый инструмент синхронизации, и его имя буквально означает "взаимное исключение" — если один поток "внутри", все остальные исключены.

**Ключевое свойство: владение (ownership).** Только тот поток, который заблокировал (lock) mutex, может его разблокировать (unlock). Это не просто формальность — это фундаментальная гарантия, которая позволяет реализовать **priority inheritance** (об этом ниже, в истории Mars Pathfinder).

```
┌─────────────────────────────────────────────────────────────┐
│                         MUTEX                               │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│   Thread A                    Thread B                      │
│   ────────                    ────────                      │
│   lock()   ✓                  lock() → ждёт...              │
│   [critical section]                 ↓                      │
│   unlock()                    [теперь владеет]              │
│                               [critical section]            │
│                               unlock()                      │
│                                                             │
│   Только ОДИН поток внутри critical section                │
│   Только ВЛАДЕЛЕЦ может unlock                             │
└─────────────────────────────────────────────────────────────┘
```

### Аналогия: ключ от туалета в кофейне

В кофейне один туалет и один ключ. Хочешь зайти — берёшь ключ с крючка. Если ключа нет — ждёшь у двери. Вышел — повесил ключ обратно.

Критически важно: **только ты** можешь вернуть ключ. Нельзя попросить друга повесить ключ за тебя. Это свойство ownership — и оно предотвращает путаницу: если кто угодно мог бы "отпирать" mutex, программа быстро потеряла бы контроль.

### КОГДА использовать mutex

Mutex — правильный выбор, когда нужно **защитить shared data** от одновременного доступа. Классические случаи:
- Обновление разделяемого счётчика
- Модификация структуры данных (HashMap, List)
- Чтение-модификация-запись (read-modify-write) последовательность

Mutex **не** подходит для сигнализации между потоками ("событие произошло, действуй") — для этого есть semaphore и condition variables.

### Использование в Kotlin/Java

Следующий пример показывает два способа обеспечить mutual exclusion в Kotlin: JVM-уровня (synchronized) и корутинного (Mutex). Разница — в том, что первый блокирует поток ОС, а второй только приостанавливает корутину.

```kotlin
// Java-style: synchronized блокирует ПОТОК ОС
val lock = Any()
fun increment() {
    synchronized(lock) {
        counter++  // Только один поток здесь — гарантировано
    }
}

// Kotlin coroutines: Mutex приостанавливает КОРУТИНУ, не поток
val mutex = Mutex()
suspend fun incrementSafe() {
    mutex.withLock {
        counter++  // Только одна корутина здесь — поток свободен для других
    }
}
```

**Критическое отличие:** `synchronized` блокирует поток ОС (blocking) — пока один поток в critical section, другие потоки ОС ждут, потребляя ресурсы. `Mutex.withLock` приостанавливает корутину (suspending) — поток ОС освобождается и может выполнять другие корутины.

---

## ЧТО такое Semaphore

### Определение и суть

Semaphore — счётчик, контролирующий доступ к ресурсу. В отличие от mutex, semaphore может разрешать **нескольким** потокам работать одновременно (до N), и **не имеет понятия владения** — любой поток может вызвать release().

Две атомарные операции:
- **acquire/wait/P** — уменьшить счётчик. Если счётчик > 0, уменьшаем и проходим. Если = 0, ждём.
- **release/signal/V** — увеличить счётчик. Если кто-то ждёт, разбудить одного.

Аналогия: **парковка на 3 места**. Табло показывает "3 свободных места". Машина заехала — табло показывает "2". Ещё одна — "1". Третья — "0". Четвёртая приехала — видит "0", стоит и ждёт. Когда одна машина уезжает — табло снова "1", и ждущая машина заезжает.

```
┌─────────────────────────────────────────────────────────────┐
│                    SEMAPHORE (count = 3)                    │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│   Начальное состояние: count = 3 (3 места на парковке)     │
│                                                             │
│   Thread A: acquire() → count = 2 ✓  (заехала)             │
│   Thread B: acquire() → count = 1 ✓  (заехала)             │
│   Thread C: acquire() → count = 0 ✓  (заехала)             │
│   Thread D: acquire() → ЖДЁТ (count = 0, мест нет)        │
│                                                             │
│   Thread A: release() → count = 1 (уехала)                 │
│   Thread D: просыпается → count = 0 ✓ (заехала)           │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

### КОГДА использовать semaphore

Semaphore — правильный выбор для двух сценариев:

**1. Ограничение concurrency.** Допустим, API позволяет не более 10 одновременных запросов. Semaphore(10) — идеальный инструмент: каждый запрос делает acquire() перед вызовом API и release() после.

**2. Сигнализация между потоками.** Producer создал элемент → release(). Consumer хочет элемент → acquire(). Семафор считает количество доступных элементов.

### Binary Semaphore vs Mutex: в чём разница

Binary semaphore (count = 1) **похож** на mutex, но это разные вещи. Разница фундаментальна:

| Аспект | Mutex | Binary Semaphore |
|--------|-------|------------------|
| **Владение** | Только владелец может unlock | Любой может release |
| **Priority inheritance** | Да (ОС поднимает приоритет владельца) | Нет |
| **Назначение** | Защита ресурса | Сигнализация |
| **Рекурсивный вход** | Возможен (recursive mutex) | Нет |

Mutex — это **замок с ключом**: только ты отпираешь то, что запер. Semaphore — это **контролёр**: он считает, сколько людей внутри, но не помнит, кто конкретно. Если ты путаешь mutex и semaphore — прочитай классическую статью "Mutexes and Semaphores Demystified" от Barr Group, которая расставляет всё по местам.

### Паттерн: Producer-Consumer

Одно из канонических применений семафора — координация producer и consumer. Два семафора: один считает доступные элементы, другой — свободные места в буфере.

Следующий пример демонстрирует паттерн producer-consumer с двумя семафорами: один отслеживает наличие элементов для потребления, другой — наличие свободного места для производства.

```kotlin
val itemsAvailable = Semaphore(0)  // Изначально нет элементов
val spaceAvailable = Semaphore(10) // Буфер на 10 элементов

// Producer: создаёт элемент и сигнализирует consumer'у
suspend fun produce(item: Item) {
    spaceAvailable.acquire()  // Ждём свободное место в буфере
    buffer.add(item)          // Кладём элемент
    itemsAvailable.release()  // Сигнал: "есть новый элемент!"
}

// Consumer: ждёт элемент и сигнализирует producer'у
suspend fun consume(): Item {
    itemsAvailable.acquire()  // Ждём элемент
    val item = buffer.remove() // Забираем
    spaceAvailable.release()  // Сигнал: "место освободилось!"
    return item
}
```

Здесь семафоры работают как **сигнальные механизмы**: producer сообщает "элемент готов", consumer сообщает "место свободно". Это невозможно сделать с mutex — mutex не умеет "ждать события".

---

## Monitor: mutex + condition variables

### Определение

Monitor — высокоуровневый примитив, предложенный Тони Хоаром (1974) и Пером Бринч Хансеном (1973). Monitor объединяет mutex и condition variables в единую конструкцию: mutex защищает данные, condition variables позволяют потокам **ждать** конкретных условий.

Аналогия: **комната ожидания у врача**. Дверь в кабинет — mutex (только один пациент внутри). Но пациент может оказаться внутри и обнаружить, что ему нужны результаты анализов, которых ещё нет. Он **выходит** из кабинета (release mutex), **садится в комнату ожидания** (condition wait) и ждёт, пока медсестра не объявит "результаты готовы" (condition signal). Тогда он снова заходит в кабинет (re-acquire mutex).

### КОГДА использовать monitor

Monitor — правильный выбор, когда поток должен не просто захватить ресурс, а **ждать определённого состояния** этого ресурса. Например: consumer ждёт, пока буфер не станет непустым. Не "проверь и повтори", а "жди, пока не будет условие".

В Java/Kotlin `synchronized` + `wait()/notify()` — это monitor. В Kotlin coroutines эквивалент — `Mutex` + `Channel` или `Mutex` + бизнес-логика с suspend.

Мы разобрали три основных примитива: mutex для защиты, semaphore для сигнализации, monitor для ожидания условий. Но что происходит, когда эти инструменты используются неправильно?

---

## Deadlock: взаимная блокировка

### ЧТО такое deadlock

Deadlock — ситуация, когда два или более потоков **бесконечно** ждут друг друга. Каждый держит ресурс, нужный другому, и ни один не может продвинуться. Система "замораживается" — не crashed, не работает, просто стоит.

Аналогия: **два грузовика на узком мосту**. Каждый заехал с одной стороны и не может развернуться. Каждый ждёт, что другой сдаст назад. Никто не сдаёт — оба стоят навсегда.

```
┌─────────────────────────────────────────────────────────────┐
│                        DEADLOCK                             │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│   Thread A                    Thread B                      │
│   ────────                    ────────                      │
│   lock(mutex1) ✓             lock(mutex2) ✓                │
│   lock(mutex2) → ждёт B      lock(mutex1) → ждёт A         │
│       ↓                           ↓                         │
│   ∞ ЖДЁТ                     ∞ ЖДЁТ                        │
│                                                             │
│   Кольцевое ожидание: A → B → A                            │
│   Ни один не может продвинуться                            │
└─────────────────────────────────────────────────────────────┘
```

### Четыре условия Coffman (1971): КАЖДОЕ объяснено

В 1971 году Эдвард Коффман, Майкл Элфик и Мелвин Шошани опубликовали статью "System Deadlocks" в ACM Computing Surveys, где сформулировали четыре **необходимых и достаточных** условия deadlock. Deadlock возникает **только если все четыре** выполнены одновременно.

**1. Mutual Exclusion (взаимное исключение).**
Ресурс не может быть разделён — только один поток может владеть им в один момент. Это принтер (нельзя печатать двум документам одновременно), файл в exclusive mode, mutex.

*Почему это условие:* Если ресурс можно разделить (как read-only данные), нет необходимости ждать — нет блокировки. Deadlock невозможен без блокировки.

**2. Hold and Wait (удержание и ожидание).**
Поток держит хотя бы один ресурс И ждёт другого. Thread A заблокировал mutex1 и теперь хочет mutex2. Он **не отпускает** mutex1 пока ждёт.

*Аналогия:* Ты сидишь за столом с вилкой в руке и ждёшь нож. Но вилку не кладёшь — вдруг кто-то заберёт. Если бы ты положил вилку ("заберу позже") — deadlock стал бы невозможен.

**3. No Preemption (невозможность отбора).**
Ресурс нельзя отобрать силой — только поток-владелец может его освободить добровольно. Операционная система не может "забрать" mutex у потока, как может забрать CPU (preemption).

*Почему это опасно:* Если бы ОС могла отобрать mutex — deadlock исчез бы, но появилась бы другая проблема: данные, защищённые mutex, могут оказаться в inconsistent state (частично записанная транзакция).

**4. Circular Wait (кольцевое ожидание).**
Существует цепочка потоков: Thread A ждёт ресурс Thread B, Thread B ждёт ресурс Thread C, ..., Thread N ждёт ресурс Thread A. Замкнутый цикл.

*Это ключевое условие:* Первые три условия создают **возможность** deadlock. Четвёртое — **реализует** его. Без цикла потоки могут ждать, но в конце концов кто-то получит ресурс и двинется дальше.

> **Ключевая идея:** Нарушь **любое одно** из четырёх условий — deadlock невозможен. Это даёт четыре стратегии предотвращения.

### Стратегии предотвращения

**1. Нарушить Circular Wait: Lock Ordering.**
Пронумеруй все mutex'ы и всегда захватывай в порядке возрастания номеров. Если все потоки захватывают lock(1) перед lock(2), цикл A→B→A невозможен: оба попытаются сначала взять lock(1), и один дождётся.

Следующий пример показывает, как lock ordering предотвращает deadlock: оба потока захватывают locks в одном и том же порядке (a, затем b).

```kotlin
// ПЛОХО: разный порядок → deadlock возможен
// Thread A: lock(a), lock(b)
// Thread B: lock(b), lock(a)

// ХОРОШО: одинаковый порядок везде → deadlock невозможен
// Thread A: lock(a), lock(b)
// Thread B: lock(a), lock(b)  ← тот же порядок!
```

Это самая простая и эффективная стратегия. Один порядок — нет цикла — нет deadlock.

**2. Нарушить No Preemption: Try-Lock с Timeout.**
Если не можешь захватить lock за разумное время — откатись и попробуй снова. Это позволяет "разорвать" ожидание.

Ниже — пример с tryLock и timeout: если mutex не удалось захватить за 1 секунду, поток не продолжает ждать, а откатывается.

```kotlin
if (mutex.tryLock(timeout = 1.seconds)) {
    try {
        // работа с защищёнными данными
    } finally {
        mutex.unlock()  // ВСЕГДА освобождай в finally!
    }
} else {
    // Не удалось захватить за 1 секунду — откатываемся
    // Можно повторить, залогировать, вернуть ошибку
}
```

Timeout превращает "бесконечное ожидание" в "ограниченное ожидание". Deadlock всё ещё может произойти, но он разрешится через timeout.

**3. Нарушить Hold and Wait: захватывай всё или ничего.**
Захватывай все нужные ресурсы атомарно. Если не можешь получить все — отпусти все и попробуй заново.

Следующий пример демонстрирует стратегию "всё или ничего" для банковского перевода: оба аккаунта блокируются в одном порядке (по ID), предотвращая deadlock.

```kotlin
fun transferMoney(from: Account, to: Account, amount: Int) {
    // Захватываем оба lock'а в определённом порядке (по ID)
    val (first, second) = if (from.id < to.id)
        from to to else to to from

    synchronized(first) {
        synchronized(second) {
            from.balance -= amount  // Оба lock'а захвачены
            to.balance += amount    // Операция атомарна
        }
    }
}
```

Заметь: здесь применяются **обе** стратегии одновременно — и lock ordering (по ID), и "всё или ничего" (оба lock'а захватываются вместе). Это типичный подход для банковских переводов.

---

## Mars Pathfinder: реальная история priority inversion

### Контекст

4 июля 1997 года NASA посадила аппарат Mars Pathfinder на Марс. Миссия стоила $265 миллионов. Через несколько дней после посадки аппарат начал **перезагружаться** — раз за разом, теряя научные данные.

### Что произошло

Бортовой компьютер работал на реальном-временном ОС VxWorks. Три задачи с разными приоритетами:

1. **High priority:** Bus management task (управление шиной данных, критически важно)
2. **Medium priority:** Communication task (передача данных на Землю)
3. **Low priority:** Meteorological task (сбор метеоданных)

Задачи high и low использовали общий **mutex** для доступа к шине данных.

### Что пошло не так: Priority Inversion

```
┌─────────────────────────────────────────────────────────────┐
│                    PRIORITY INVERSION                       │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│   Time →                                                    │
│                                                             │
│   LOW prio:  ████[lock]████████████████████[unlock]██       │
│   MED prio:       ↑ preempts LOW ████████████████           │
│   HIGH prio:           ↑ needs lock → ЖДЁТ LOW!            │
│                                                             │
│   Что происходит:                                          │
│   1. LOW захватывает mutex                                 │
│   2. MEDIUM вытесняет LOW (у MED приоритет выше)          │
│   3. HIGH просыпается, хочет mutex — ждёт LOW             │
│   4. LOW не может работать — MEDIUM забирает CPU!          │
│   5. HIGH ждёт LOW, LOW ждёт CPU, MED занимает CPU        │
│                                                             │
│   Результат: HIGH (самый важный) заблокирован              │
│   MEDIUM-приоритетной задачей через LOW                    │
│                                                             │
│   Watchdog timer: "HIGH не работает → ПЕРЕЗАГРУЗКА!"       │
└─────────────────────────────────────────────────────────────┘
```

**Priority inversion:** Высокоприоритетная задача (HIGH) заблокирована **низко**приоритетной (LOW), потому что **средне**приоритетная (MEDIUM) вытесняет LOW и не даёт ей освободить mutex. HIGH фактически "унаследовала" приоритет LOW. Watchdog timer видел, что HIGH не работает, и перезагружал аппарат.

### Решение: Priority Inheritance

Инженеры JPL (Jet Propulsion Laboratory) удалённо обновили ПО на Марсе (!) и включили **priority inheritance** — механизм, который автоматически поднимает приоритет потока-владельца mutex до уровня самого приоритетного ждущего потока.

С priority inheritance: когда HIGH ждёт mutex, который держит LOW — ОС временно поднимает приоритет LOW до HIGH. Теперь MEDIUM не может вытеснить LOW. LOW быстро завершает работу, отпускает mutex, и HIGH получает его.

**Именно поэтому mutex имеет concept of ownership, а semaphore — нет.** Priority inheritance возможен только при владении: ОС знает, **кто** держит mutex, и может поднять **его** приоритет. У semaphore нет владельца — ОС не знает, чей приоритет повышать.

---

## Spinlock: активное ожидание

### Как работает

Spinlock — это mutex, который не усыпляет поток при ожидании, а "крутится" в цикле, постоянно проверяя: "свободен ли lock?".

```
┌─────────────────────────────────────────────────────────────┐
│               SPINLOCK vs BLOCKING MUTEX                    │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│   SPINLOCK (busy-waiting):                                  │
│   while (lock != 0) { }  ← CPU крутится вхолостую          │
│   lock = 1;                                                 │
│                                                             │
│   BLOCKING MUTEX (sleeping):                                │
│   if (lock != 0) {                                          │
│       save_state();                                         │
│       sleep();   ← Поток засыпает, CPU свободен            │
│   }                                                         │
│   lock = 1;                                                 │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

### Когда spinlock оправдан

| Сценарий | Spinlock | Mutex |
|----------|----------|-------|
| Очень короткий critical section (нс) | Быстрее (нет overhead на sleep/wake) | Overhead context switch > время ожидания |
| Длинный critical section | CPU waste | Правильный выбор |
| Single-core | Бесполезен (некому отпустить lock!) | Единственный вариант |
| Kernel code | Часто единственный вариант (нельзя спать) | Зависит |

На single-core spinlock **бесполезен**: если ты крутишься в цикле, ожидая что другой поток отпустит lock — другой поток не может работать, потому что ты занимаешь единственное ядро.

Matklad (Алексей Кладов) в статье "Mutexes Are Faster Than Spinlocks" показывает бенчмарки: под высокой нагрузкой **mutex обычно быстрее spinlock**. Scheduler не знает, что поток "крутится впустую", и отдаёт ему полный time slice.

---

## Lock-free подход: ИДЕЯ

### Зачем lock-free

Все проблемы синхронизации — deadlock, priority inversion, convoying (потоки выстраиваются в очередь за lock'ом) — вытекают из одного: **блокировки**. Что если можно обойтись без них?

Lock-free (неблокирующая) синхронизация — это подход, при котором потоки **никогда** не блокируются. Вместо lock/unlock используются **атомарные операции процессора**: Compare-And-Swap (CAS), Load-Linked/Store-Conditional (LL/SC).

### Идея CAS (Compare-And-Swap)

CAS — атомарная инструкция процессора, которая делает три вещи за одну неделимую операцию:
1. Читает текущее значение переменной
2. Сравнивает с ожидаемым значением
3. Если совпадает — записывает новое значение. Если нет — ничего не делает

Аналогия: ты хочешь заменить лампочку. Ты помнишь, что стояла лампочка 60W. Подходишь: если стоит 60W — меняешь на 100W. Если кто-то уже поменял (стоит не 60W) — ты понимаешь, что ситуация изменилась, и действуешь по-другому (читаешь новое значение и пытаешься снова).

### Lock-free vs Lock-based: компромиссы

Lock-free подход исключает deadlock и priority inversion. Но он **сложнее** в реализации и понимании. Herlihy в своей эпохальной статье "Wait-Free Synchronization" (1991) доказал, что **любой** алгоритм, реализуемый с lock'ами, может быть реализован без них (с использованием CAS). Но доказательство существования не означает простоту реализации.

На практике: используй готовые lock-free структуры данных (ConcurrentHashMap, AtomicInteger), но не пиши свои, если ты не эксперт. Lock-free код — один из самых сложных для написания и верификации.

---

## Kotlin: практические инструменты синхронизации

### Иерархия выбора: от простого к сложному

```
┌─────────────────────────────────────────────────────────────┐
│              ВЫБОР ИНСТРУМЕНТА СИНХРОНИЗАЦИИ                │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│   1. Избегать shared state (ЛУЧШИЙ вариант)                │
│      └── Immutable data, message passing (Channels)        │
│                                                             │
│   2. Thread confinement                                    │
│      └── Dispatchers.Default.limitedParallelism(1)         │
│                                                             │
│   3. Atomic operations                                     │
│      └── AtomicInteger, AtomicReference                    │
│                                                             │
│   4. Lock-free structures                                  │
│      └── ConcurrentHashMap, ConcurrentLinkedQueue          │
│                                                             │
│   5. Fine-grained locking (ПОСЛЕДНИЙ вариант)              │
│      └── Mutex (coroutines), synchronized (blocking)       │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

Каждый шаг вниз по иерархии увеличивает сложность и вероятность ошибки. Если можешь обойтись immutable data — обходись. Если нужен mutable shared state — начинай с atomic. Mutex — последнее средство.

### synchronized vs Mutex

Следующий пример показывает, когда использовать JVM synchronized (для blocking кода) и Kotlin Mutex (для suspend-функций). Не смешивай: synchronized в suspend-функции заблокирует поток ОС.

```kotlin
// JVM blocking — для кода без suspend-вызовов
fun updateBlocking() {
    synchronized(lock) {
        Thread.sleep(100)  // Блокирует ПОТОК ОС — другие потоки ждут
        counter++
    }
}

// Coroutines suspending — для suspend-функций
suspend fun updateSuspending() {
    mutex.withLock {
        delay(100)   // Приостанавливает КОРУТИНУ — поток свободен
        counter++
    }
}
```

**Важно:** Никогда не используй `synchronized` внутри suspend-функции с другими suspend-вызовами — это заблокирует поток ОС на время всего блока, включая suspend-точки. Потоки dispatcher'а заблокированы — другие корутины не могут работать.

### StateFlow для UI State

Следующий пример демонстрирует thread-safe обновление UI state без ручной синхронизации: `MutableStateFlow.update` — атомарная операция.

```kotlin
class ViewModel {
    private val _state = MutableStateFlow(UiState())
    val state: StateFlow<UiState> = _state.asStateFlow()

    fun updateName(name: String) {
        _state.update { currentState ->
            currentState.copy(name = name)  // Атомарное обновление
        }
    }
}
```

`MutableStateFlow.update` использует CAS (Compare-And-Swap) внутри — если два потока вызовут update одновременно, один из них увидит, что значение изменилось, и повторит операцию. Внешняя синхронизация не нужна.

---

## Распространённые заблуждения

### Миф 1: "volatile решает все проблемы синхронизации"

**Реальность:** `volatile` в Java/Kotlin гарантирует **visibility** (изменения видны другим потокам) и **ordering** (нет reordering вокруг volatile), но **не atomicity**. `counter++` с volatile counter по-прежнему не атомарен — это три операции (read, add, write), и между ними другой поток может вклиниться.

### Миф 2: "Чем больше locks, тем безопаснее"

**Реальность:** Избыточная синхронизация создаёт две проблемы. Первая — deadlock: чем больше lock'ов, тем больше возможностей для circular wait. Вторая — convoying: потоки выстраиваются в очередь за lock'ом, и программа фактически становится однопоточной. Лучшая синхронизация — её отсутствие (immutable data, thread confinement).

### Миф 3: "Deadlock легко отловить в тестах"

**Реальность:** Deadlock — это **heisenbug** (баг, который исчезает при наблюдении). Он зависит от конкретного timing: какой поток получил time slice, в какой момент произошёл context switch. В тестах timing может отличаться от production, и deadlock никогда не проявится. Инструменты статического анализа (ThreadSanitizer, FindBugs) лучше тестов для поиска deadlock'ов.

### Миф 4: "Если программа работает корректно 1000 раз — в ней нет race conditions"

**Реальность:** Race condition может проявляться при конкретной комбинации: определённая нагрузка, определённый timing, определённое количество ядер. Программа может "работать" месяцами и упасть один раз — в самый неподходящий момент. Ben-Ari в "Principles of Concurrent Programming" подчёркивает: корректность concurrent программы нужно **доказывать**, а не тестировать.

---

## Подводные камни

### Когда НЕ синхронизировать

**Immutable data:** Если данные не меняются после создания — синхронизация не нужна. Несколько потоков могут безопасно читать одни и те же данные.

**Thread-local data:** Если каждый поток работает со своей копией — конфликтов нет.

### Распространённые ошибки

| Ошибка | Последствие | Решение |
|--------|-------------|---------|
| Забыть unlock | Вечная блокировка | `withLock { }`, `try-finally` |
| Lock на разные объекты | Race condition (false safety) | Один lock для одних данных |
| Nested locks в разном порядке | Deadlock | Lock ordering |
| synchronized в suspend | Thread blocked | Использовать Mutex |
| Coarse-grained lock | Плохая производительность | Fine-grained или lock-free |
| Lock на public объект | Другой код может взять тот же lock | Private lock object |

---

## Связь с другими темами

**[[processes-threads-fundamentals]]** — чтобы понять, зачем нужна синхронизация, нужно разобраться, что такое потоки и shared memory. Потоки делят heap и data segment — это источник race conditions. Текущая статья — продолжение.

**[[concurrency-vs-parallelism]]** — синхронизация нужна при concurrency (несколько потоков работают с общими данными). Тип задачи (CPU-bound vs IO-bound) определяет инструменты: для IO-bound часто хватает channels вместо mutex.

**[[async-models-overview]]** — альтернативы lock-based синхронизации: channels (share by communicating), actors (isolated state), reactive streams (immutable events). Каждая модель предлагает свой подход к проблеме shared state.

---

## Источники и дальнейшее чтение

- **Coffman, E.G., Elphick, M., Shoshani, A. (1971). System Deadlocks.** — Оригинальная статья с четырьмя условиями Coffman. Короткая, ясная, фундаментальная. Обязательное чтение для понимания deadlock.

- **Herlihy, M. (1991). Wait-Free Synchronization.** — Революционная статья: доказательство, что любой sequential object может быть реализован без блокировок. Основа всех lock-free структур данных. Turing Award 2012.

- **Herlihy, M. & Shavit, N. (2012). The Art of Multiprocessor Programming.** — Лучший учебник по concurrent programming: от теории (linearizability, consensus) до практики (lock-free queues, skip lists). Главы 7-9 покрывают lock-free подходы.

- **Ben-Ari, M. (2006). Principles of Concurrent and Distributed Programming.** — Академический подход с формальными моделями. Объясняет, как **доказать** корректность concurrent программы, а не просто тестировать.

- **Dijkstra, E. (1965). Cooperating Sequential Processes.** — Оригинальная работа о семафорах. Исторический документ, заложивший основы.

- **Jones, M.B. (1997). What Really Happened on Mars (report).** — Детальное описание бага Mars Pathfinder с priority inversion. Показывает, как ошибка синхронизации чуть не погубила миссию за $265 млн.

---

*Проверено: 2026-02-10*
