---
title: "Процессы и потоки: фундамент конкурентности"
created: 2026-01-04
modified: 2026-02-10
type: deep-dive
status: published
tags:
  - topic/cs-foundations
  - type/deep-dive
  - level/intermediate
related:
  - "[[concurrency-vs-parallelism]]"
  - "[[synchronization-primitives]]"
  - "[[async-models-overview]]"
prerequisites:
  - "[[os-fundamentals-for-devs]]"
  - "[[memory-model-fundamentals]]"
---

# Процессы и потоки: фундамент конкурентности

> **TL;DR:** Процесс — экземпляр программы с изолированной памятью. Поток — единица исполнения внутри процесса, потоки делят память. Context switch — переключение CPU между задачами. Kernel threads управляются ОС, user/green threads — runtime'ом (дешевле, но ограничения). Для KMP критично: Kotlin coroutines — это "зелёные потоки" поверх thread pools, отсюда их эффективность.

---

## Prerequisites

| Тема | Зачем нужно | Где изучить |
|------|-------------|-------------|
| **Memory Model** | Понять shared memory | [[memory-model-fundamentals]] |
| **OS Fundamentals** | Базовое понимание работы ОС | [[os-fundamentals-for-devs]] |

---

## Терминология

| Термин | Что это | Аналогия |
|--------|---------|----------|
| **Process** | Экземпляр программы с изолированной памятью | Отдельная квартира |
| **Thread** | Единица исполнения внутри процесса | Жилец в квартире |
| **Context Switch** | Переключение CPU между задачами | Смена работника у станка |
| **Scheduler** | Компонент ОС, распределяющий CPU | Менеджер смен |
| **Preemption** | Принудительное прерывание программы | Звонок будильника |
| **Thread Pool** | Набор готовых потоков для работы | Команда дежурных |
| **IPC** | Inter-Process Communication | Письма между квартирами |
| **PCB** | Process Control Block — структура данных для хранения состояния процесса | Личное дело сотрудника |
| **TCB** | Thread Control Block — структура данных для хранения состояния потока | Запись о текущей задаче сотрудника |

---

## ПОЧЕМУ нужны процессы и потоки

### Одна программа — один CPU: мир до многозадачности

В 1940-х и 1950-х годах компьютеры работали в самом простом режиме: одна программа загружается в память, выполняется от начала до конца, потом следующая. Программисты записывались в очередь и ждали часами, чтобы запустить свою программу на машине стоимостью в миллионы долларов.

Проблема была очевидна: CPU — самый дорогой компонент системы — простаивал большую часть времени. Пользователь печатает на клавиатуре — CPU ждёт. Данные читаются с перфокарты или магнитной ленты — CPU ждёт. По оценкам того времени, утилизация процессора составляла 10-30%.

Представь это так: ты нанял самого дорогого повара в городе, но он может готовить только одно блюдо за раз. Пока жарится стейк (5 минут ожидания) — повар стоит и смотрит на него. Ты платишь за каждую минуту, включая простой. Это расточительство.

### 1960-е: рождение многозадачности

Решение: пока одна программа ждёт I/O, запустить другую. Эта идея материализовалась в нескольких системах:

**1961 — CTSS (Compatible Time-Sharing System)** в MIT: одна из первых систем, разделяющих процессор между несколькими пользователями. Каждый пользователь за своим терминалом думал, что компьютер работает только для него.

**1964 — Multics** (MIT, Bell Labs, GE): амбициозный проект многозадачной ОС. Слишком сложный для своего времени, но заложил фундаментальные идеи: виртуальная память, иерархическая файловая система, кольца защиты.

**1969 — Unix:** Кен Томпсон и Деннис Ритчи, разочарованные в Multics, создали Unix — простую и элегантную ОС с preemptive multitasking. ОС **сама** решает когда переключить программу — программа не может "захватить" CPU навсегда.

> **Ключевая идея:** Многозадачность родилась не из желания "делать несколько вещей одновременно", а из экономики: CPU слишком дорог, чтобы простаивать. Процессы — это механизм, позволяющий утилизировать CPU во время ожидания I/O.

### От процессов к потокам: почему процессов оказалось недостаточно

Процессы решили проблему утилизации CPU, но создали новую. Каждый процесс — это изолированная сущность с собственной памятью. Если одна программа хочет делать несколько вещей одновременно (например, текстовый редактор: одновременно принимать ввод, проверять орфографию и сохранять автоматически), она должна создать несколько процессов.

Но создание процесса — дорогая операция: нужно выделить новое адресное пространство, скопировать данные, настроить таблицы страниц. А общение между процессами (IPC) через pipes, sockets или shared memory — медленно и неудобно.

**Потоки** появились как "облегчённые процессы": несколько потоков исполнения внутри одного процесса, разделяющих общую память. Это дёшево (нет копирования адресного пространства) и удобно (общая память — быстрый обмен данными). Но, как мы увидим, общая память — это и проклятие.

---

## ЧТО такое процесс на уровне ОС

### Анатомия процесса

Процесс — это не просто "запущенная программа". Это целый набор ресурсов, которые операционная система выделяет и отслеживает. Tanenbaum в "Modern Operating Systems" определяет процесс как **контейнер** для группы связанных ресурсов.

Каждый процесс включает:

**1. Text segment (код программы).** Скомпилированные машинные инструкции. Обычно read-only: код не меняется во время выполнения. Несколько процессов одной программы могут разделять этот сегмент для экономии памяти.

**2. Data segment (статические данные).** Глобальные и статические переменные. Разделён на initialized data (переменные с начальными значениями) и BSS (Block Started by Symbol) — переменные без начальных значений, инициализированные нулями.

**3. Heap (динамическая память).** Область для динамически выделяемой памяти (malloc/new). Растёт "вверх" — от низких адресов к высоким. Управляется программой: если забыл освободить — memory leak.

**4. Stack (стек вызовов).** Локальные переменные, аргументы функций, адреса возврата. Растёт "вниз" — от высоких адресов к низким. Каждый вызов функции создаёт stack frame, возврат — уничтожает его.

**5. Ресурсы ОС.** Открытые файлы (file descriptors), сетевые сокеты, привязки к устройствам, environment variables, текущая рабочая директория.

**6. Контекст выполнения.** Регистры процессора, program counter (адрес текущей инструкции), stack pointer, status register.

```
┌─────────────────────────────────────────────────────────────────┐
│                    АНАТОМИЯ ПРОЦЕССА                             │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│   High addresses                                                │
│   ┌─────────────────┐                                           │
│   │     Stack        │ ← Локальные переменные, call frames      │
│   │       ↓          │   Растёт вниз                            │
│   │                  │                                          │
│   │   (свободно)     │                                          │
│   │                  │                                          │
│   │       ↑          │                                          │
│   │     Heap         │ ← Динамическая память (new/malloc)       │
│   ├─────────────────┤   Растёт вверх                            │
│   │   Data (BSS)     │ ← Неинициализированные глобальные       │
│   ├─────────────────┤                                           │
│   │   Data (init)    │ ← Инициализированные глобальные         │
│   ├─────────────────┤                                           │
│   │   Text (code)    │ ← Машинные инструкции (read-only)       │
│   └─────────────────┘                                           │
│   Low addresses                                                 │
│                                                                 │
│   + PID, file descriptors, signal handlers, регистры...        │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

Каждый процесс имеет уникальный Process ID (PID). ОС ведёт таблицу процессов, где для каждого хранится **Process Control Block (PCB)** — структура данных с полным состоянием процесса: регистры, состояние (running/waiting/ready), PID, указатели на память, открытые файлы, статистику использования CPU.

### Изоляция процессов: ПОЧЕМУ она критически важна

Процесс A не может читать или писать в память процесса B. Это обеспечивается механизмом **виртуальной памяти**: каждый процесс видит своё собственное адресное пространство, а ОС + MMU (Memory Management Unit) транслирует виртуальные адреса в физические.

Изоляция даёт три ключевых свойства:

**Безопасность.** Вредоносная программа не может прочитать пароли из памяти браузера. Каждый процесс живёт в своём "аквариуме" и не видит соседей. Без изоляции любая программа могла бы читать данные любой другой — именно так работали ранние ОС (MS-DOS), и это было источником бесконечных проблем.

**Надёжность.** Crash одного процесса не роняет другие. Если текстовый редактор упал из-за бага, браузер продолжает работать. Без изоляции один баг мог повредить память другой программы, вызвав каскадный сбой.

**Независимость.** Каждый процесс может использовать свои версии библиотек. Процесс A использует версию 2.0 библиотеки, процесс B — версию 3.0. Никакого конфликта.

Аналогия: квартиры в многоквартирном доме. Каждая квартира — отдельное пространство с замком на двери. Жильцы не могут зайти в чужие квартиры (изоляция). Если в одной квартире прорвало трубу — другие не пострадают (надёжность). Каждый обставляет квартиру по-своему (независимость).

Chrome использует отдельный процесс для каждой вкладки именно поэтому. Вкладка зависла? Другие работают. Вкладка пытается эксплуатировать уязвимость? Она изолирована от остальных.

### Inter-Process Communication (IPC): как процессы общаются

Изоляция — это хорошо, но иногда процессам нужно обмениваться данными. Для этого существует IPC — набор механизмов для общения между изолированными процессами.

**Pipes (каналы).** Однонаправленный поток байтов между двумя процессами. В Unix это `|` в командной строке: `cat file.txt | grep "error"` — pipe передаёт вывод cat на вход grep. Простой, но ограниченный: только между "родственными" процессами, однонаправленный.

**Sockets.** Двунаправленная связь, работает и между процессами на одной машине, и по сети. Более гибкий, но с бо́льшим overhead. Используется повсеместно: веб-серверы, базы данных, микросервисы.

**Shared Memory.** Область памяти, видимая нескольким процессам. Самый быстрый IPC (нет копирования данных), но требует синхронизации (semaphores). Используется для высокопроизводительных приложений.

**Message Queues.** Структурированные сообщения с типами. Похоже на электронную почту: отправитель кладёт сообщение в очередь, получатель забирает когда готов. Используется в системах с разной скоростью работы компонентов.

> **Ключевая идея:** IPC — это "плата" за изоляцию. Процессы безопасны, но общение между ними дорого. Потоки решают эту проблему — ценой потери изоляции.

---

## ЧТО такое поток и ЧЕМ он отличается от процесса

### Что делят потоки

Потоки внутри одного процесса **разделяют**:
- Код (text segment) — все потоки выполняют один и тот же код
- Данные (globals) — глобальные переменные видны всем потокам
- Heap — динамически выделенная память общая
- Открытые файлы — file descriptors доступны всем потокам
- Signal handlers — обработчики сигналов общие

У каждого потока **своё**:
- Stack — свой стек вызовов (обычно 1-8 MB)
- Program Counter — свой указатель на текущую инструкцию
- Регистры — свой набор регистров процессора
- Thread ID — уникальный идентификатор
- Thread Local Storage (TLS) — приватные данные потока

```
┌─────────────────────────────────────────────────────────────────┐
│                    ПРОЦЕСС vs ПОТОК                             │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│   ПРОЦЕСС A           ПРОЦЕСС B                                │
│   ┌─────────────┐     ┌─────────────┐                          │
│   │ Code        │     │ Code        │                          │
│   │ Data        │     │ Data        │                          │
│   │ Heap        │     │ Heap        │  ← Изолированная память  │
│   │ Stack       │     │ Stack       │                          │
│   └─────────────┘     └─────────────┘                          │
│                                                                 │
│   ПРОЦЕСС C (с потоками)                                       │
│   ┌─────────────────────────────────┐                          │
│   │ Code  (shared)                  │                          │
│   │ Data  (shared)                  │                          │
│   │ Heap  (shared)                  │                          │
│   ├─────────┬─────────┬─────────────┤                          │
│   │ Stack 1 │ Stack 2 │ Stack 3     │  ← Отдельные стеки      │
│   │ Thread1 │ Thread2 │ Thread3     │                          │
│   └─────────┴─────────┴─────────────┘                          │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

### ПОЧЕМУ потоки легче процессов

Создание процесса — тяжёлая операция. ОС должна: выделить новое адресное пространство, настроить таблицы страниц виртуальной памяти, скопировать или подготовить data и text сегменты, создать PCB. Это занимает **миллисекунды** и десятки килобайт метаданных.

Создание потока — лёгкая операция. Нужно лишь: выделить стек (обычно 1 MB), создать TCB (Thread Control Block) с регистрами и program counter. Это занимает **микросекунды** — в 100-1000 раз быстрее.

Переключение между потоками одного процесса тоже дешевле — не нужно менять адресное пространство (TLB flush), не нужно инвалидировать кэш страниц.

Silberschatz в "Operating System Concepts" приводит конкретные цифры: на типичной Linux-системе создание процесса занимает ~3000 микросекунд, создание потока — ~30 микросекунд. Разница в 100 раз.

### Shared memory: ПОЧЕМУ это одновременно преимущество и проблема

Общая память — это самая быстрая форма коммуникации. Один поток записал значение в переменную — другой мгновенно его видит (с оговорками о memory ordering). Нет сериализации, десериализации, копирования данных. Просто запись и чтение по адресу.

Но именно эта скорость создаёт фундаментальную проблему: **race condition** (состояние гонки). Когда два потока одновременно читают и пишут одну переменную, результат непредсказуем.

Следующий пример демонстрирует классический race condition: два потока пытаются инкрементировать один и тот же счётчик, но из-за неатомарности операции один инкремент "теряется".

```kotlin
// Два потока инкрементируют один счётчик
var counter = 0

// Thread 1                    // Thread 2
val temp = counter             val temp = counter    // Оба читают 0
counter = temp + 1             counter = temp + 1    // Оба пишут 1

// Ожидаемо: counter = 2
// Реально: counter = 1 (один инкремент потерян!)
```

Почему это происходит? Потому что `counter++` — это не одна атомарная операция, а три: чтение, сложение, запись. Между этими тремя шагами другой поток может "вклиниться". Это как два кассира, одновременно проверяющие баланс одного счёта: оба видят 1000 рублей, оба снимают 800, и на счёте оказывается -600 вместо 200.

Потоки требуют синхронизации: mutex, semaphore, atomic operations. Подробнее — в [[synchronization-primitives]].

---

## КАК работает Context Switch

### ЗАЧЕМ переключаться

CPU (одно ядро) выполняет один поток в один момент времени. Чтобы создать иллюзию одновременности — multitasking — ОС переключает потоки быстро: десятки-сотни раз в секунду. Для пользователя это выглядит как "всё работает одновременно", хотя CPU просто очень быстро скачет между задачами.

### ЧТО конкретно происходит при переключении

Context switch — одна из самых детальных операций в ядре ОС. Tanenbaum описывает её как последовательность шагов, каждый из которых критически важен.

```
┌─────────────────────────────────────────────────────────────────┐
│                    CONTEXT SWITCH                               │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│   Thread A работает                                             │
│       ↓                                                         │
│   Причина: timer interrupt / I/O / yield / priority             │
│       ↓                                                         │
│   1. Сохранить регистры Thread A в его TCB                      │
│   2. Сохранить program counter Thread A                         │
│   3. Сохранить stack pointer Thread A                           │
│   4. Обновить статус Thread A: Running → Ready/Waiting          │
│       ↓                                                         │
│   Scheduler выбирает следующий поток (scheduling algorithm)     │
│       ↓                                                         │
│   5. Загрузить регистры Thread B из его TCB                     │
│   6. Загрузить program counter Thread B                         │
│   7. Загрузить stack pointer Thread B                           │
│   8. Обновить статус Thread B: Ready → Running                  │
│       ↓                                                         │
│   Thread B продолжает с того места, где остановился             │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

При переключении между **потоками одного процесса** адресное пространство остаётся тем же — это дешевле. При переключении между **потоками разных процессов** нужно сменить адресное пространство (TLB flush), что значительно дороже.

### Стоимость context switch: ПОЧЕМУ это не бесплатно

Context switch кажется простым — сохрани регистры, загрузи другие. Но реальная стоимость намного выше видимой:

**Прямая стоимость (direct cost):** 1000-10000 CPU циклов на сохранение и восстановление регистров. На 3 GHz процессоре это 0.3-3.3 микросекунды. Кажется мало, но при 1000 переключениях в секунду это уже 3.3 миллисекунды чистого overhead.

**Cache miss (косвенная стоимость).** Это главный убийца производительности. L1/L2 кэш процессора заполнен данными предыдущего потока. Новый поток начинает работать — и каждое обращение к памяти промахивается мимо кэша (cache miss), требуя обращения к более медленной памяти. "Прогрев" кэша после переключения может стоить десятки тысяч циклов.

**TLB flush.** Translation Lookaside Buffer — кэш таблицы страниц виртуальной памяти. При переключении между процессами (не потоками!) TLB инвалидируется, и все трансляции адресов нужно выполнять заново.

**Pipeline flush.** Современные процессоры используют конвейер (pipeline) — несколько инструкций выполняются одновременно на разных стадиях. Context switch очищает конвейер, теряя уже начатую работу.

Аналогия: представь переводчика-синхрониста, который переводит с одного языка на другой. Переключение на новую тему — это context switch. Ему нужно: забыть контекст предыдущей темы, загрузить в голову словарь новой темы, вспомнить где остановился. Даже отличный переводчик теряет несколько секунд на каждом переключении. Если темы меняются каждые 10 секунд — половина времени уйдёт на "переключение".

### КОГДА происходит переключение

ОС переключает потоки по четырём причинам:

- **Time slice expired** — таймер прерывает поток. Обычно time slice = 1-10 мс.
- **Blocking I/O** — поток вызвал read/write и ждёт диск/сеть. Нет смысла тратить CPU на ожидание.
- **Higher priority ready** — проснулась более важная задача (interrupt, real-time task).
- **Voluntary yield** — поток сам отдаёт управление (Thread.yield(), suspend в корутинах).

---

## Kernel Threads vs User (Green) Threads

### Kernel (Native) Threads: ОС видит и управляет

Kernel threads — это потоки, которыми управляет ядро операционной системы. Scheduler ОС знает о каждом kernel thread и распределяет их по ядрам процессора.

**Как это работает:** Каждый kernel thread имеет свой TCB (Thread Control Block) в ядре ОС. Scheduler выбирает, какой thread запустить на каком ядре, основываясь на приоритетах, fairness и других политиках. Переключение между kernel threads — это полноценный context switch через ядро ОС.

**Достоинства:**
- Настоящий параллелизм на multicore — ОС распределяет потоки по ядрам
- Если один поток блокируется на I/O — другие продолжают работать
- Преемптивность (preemption) — ОС может прервать "зависший" поток

**Недостатки:**
- Создание дорого (~30-100 мкс, ~1 MB стека)
- Context switch дорого (kernel mode transition)
- Количество ограничено (тысячи, не миллионы)
- Syscall overhead при каждой операции с потоками

### User / Green Threads: runtime управляет, ОС не знает

Green threads (user-level threads) управляются runtime'ом приложения в user space. ОС не знает о них — для ОС вся программа это один (или несколько) kernel thread(s).

Аналогия: представь менеджера отдела (runtime) и директора компании (ОС). Директор распределяет задачи между отделами (kernel threads). Внутри каждого отдела менеджер сам решает, кто что делает (green threads). Директор видит только "отдел работает", не вникая в детали.

**Достоинства:**
- Очень лёгкие — можно создать тысячи и миллионы
- Быстрое переключение — нет kernel mode transition
- Полный контроль runtime над scheduling

**Критическая проблема:** Если green thread делает **blocking syscall** (чтение файла, сетевой запрос) — заблокируется весь kernel thread, а вместе с ним **все** green threads, привязанные к нему. Это как если менеджер отдела ушёл на обед, и весь отдел остановился — директор думает, что отдел работает, но все сидят без дела.

```
┌─────────────────────────────────────────────────────────────────┐
│                    KERNEL vs GREEN THREADS                      │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│   KERNEL THREADS (1:1 model):                                   │
│   ┌─────────┬─────────┬─────────┐                               │
│   │ Thread1 │ Thread2 │ Thread3 │    OS видит все               │
│   └────┬────┴────┬────┴────┬────┘                               │
│        │         │         │                                    │
│        ▼         ▼         ▼                                    │
│   ┌─────────────────────────────┐                               │
│   │      OS Scheduler           │                               │
│   └─────────────────────────────┘                               │
│                                                                 │
│   GREEN THREADS (N:1 model):                                    │
│   ┌─────────────────────────────────────┐                       │
│   │ Green1 Green2 Green3 Green4 Green5  │  Runtime scheduler    │
│   └─────────────────┬───────────────────┘                       │
│                     │                                           │
│                     ▼                                           │
│              ┌─────────────┐                                    │
│              │ 1 Kernel Th │     OS видит только это            │
│              └─────────────┘                                    │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

### Mapping Models: три способа связать миры

**Many-to-One (N:1).** Все user threads привязаны к одному kernel thread. Просто, но нет параллелизма: один kernel thread = одно ядро. Если один user thread блокируется — все ждут. Исторически использовался в ранних Java (Green Threads в Java 1.1) и ранних POSIX реализациях.

**One-to-One (1:1).** Каждый user thread привязан к kernel thread. Linux pthreads, Windows threads, Java с версии 1.3 используют этот подход. Настоящий параллелизм, но тяжело: количество ограничено возможностями ОС.

**Many-to-Many (M:N).** M user threads распределяются по N kernel threads. Go goroutines работают именно так: тысячи горутин распределяются по GOMAXPROCS kernel threads (обычно = число ядер). Это сочетает лёгкость green threads с параллелизмом kernel threads.

| Модель | Параллелизм | Blocking I/O | Количество | Кто использует |
|--------|-------------|-------------|------------|----------------|
| **N:1** | Нет | Блокирует всех | Миллионы | Ранняя Java |
| **1:1** | Да | Блокирует одного | Тысячи | Linux, Windows, JVM |
| **M:N** | Да | Зависит от реализации | Миллионы | Go, Kotlin coroutines |

Мы разобрали виды потоков. Но как решить проблему их частого создания и уничтожения?

---

## Green threads, корутины, virtual threads: эволюция идеи

### Историческая перспектива

Идея "лёгких потоков" не нова — она эволюционировала десятилетия:

**1963 — Coroutines (Мелвин Конвей).** Первое упоминание кооперативной многозадачности: функция может "приостановиться" и передать управление другой. Конвей использовал термин "coroutine" — routine, которая кооперируется с другими.

**1995 — Green Threads (Java 1.0).** Sun Microsystems реализовали M:1 user threads в первых версиях Java. Работали на платформах без поддержки POSIX threads. Были убраны в Java 1.3 в пользу native threads (1:1).

**1986/1998 — Erlang Processes.** Erlang реализовал сверхлёгкие "процессы" (фактически green threads с изоляцией). Миллион Erlang processes на одной машине — норма. Каждый процесс занимает ~300 байт стартовой памяти.

**2009 — Go Goroutines.** Go предложил goroutines — M:N green threads с runtime scheduler. Goroutine стартует с 2 KB стека (растёт динамически). Go runtime обрабатывает blocking syscalls, автоматически создавая новые OS threads при необходимости, решая проблему blocking I/O.

**2017 — Kotlin Coroutines.** Kotlin подошёл иначе: корутины не являются green threads в традиционном смысле. Они реализованы через CPS (Continuation-Passing Style) трансформацию на уровне компилятора. Suspend-функция трансформируется в state machine, и каждый "suspend" — это сохранение состояния и возврат из функции, а не переключение контекста.

**2023 — Java Virtual Threads (Project Loom).** Java вернулась к идее лёгких потоков через 20+ лет. Virtual threads — это M:N threads, интегрированные в JVM. Ключевое отличие от ранних green threads: JVM обрабатывает blocking I/O автоматически, перемещая virtual thread с carrier thread при блокировке.

> **Ключевая идея:** Индустрия прошла полный круг: green threads → native threads → снова green threads (но лучше). Ключевое улучшение — обработка blocking I/O: Go runtime и Java Loom автоматически предотвращают блокировку.

### ПОЧЕМУ корутины и virtual threads победили

Корневая причина — **C10K problem** (1999): как обрабатывать 10 000+ одновременных соединений. С 1:1 моделью (один поток на соединение) это значит 10 000 OS threads, каждый с 1 MB стека = 10 GB только на стеки. Плюс overhead на context switch между 10 000 потоками.

Современные серверы должны обрабатывать **C10M** (10 миллионов соединений). С kernel threads это физически невозможно. С корутинами или virtual threads — реально: 10 миллионов корутин по ~1 KB = 10 GB, и переключение в user space без syscalls.

---

## Thread Pools

### Проблема частого создания потоков

Создание потока занимает время (десятки микросекунд) и память (мегабайты стека). Если веб-сервер создаёт новый поток на каждый запрос и обрабатывает 10 000 запросов в секунду — он тратит огромные ресурсы только на инфраструктуру.

Аналогия: ресторан, который нанимает нового повара на каждый заказ и увольняет после его выполнения. Найм + обучение + увольнение = потеря денег и времени. Лучше держать команду поваров и давать им заказы.

### Решение: пул готовых потоков

Thread pool — набор заранее созданных потоков. Задачи добавляются в очередь (work queue), свободный поток берёт следующую задачу. Когда задача завершена — поток возвращается в пул, а не уничтожается.

Ниже — иллюстрация использования thread pool в Java и Kotlin. В обоих случаях потоки создаются заранее и переиспользуются.

```kotlin
// Java ExecutorService — явный thread pool
val pool = Executors.newFixedThreadPool(4)  // 4 потока, готовых к работе
pool.submit { doWork() }                    // Задача идёт в очередь

// Kotlin coroutines — пул потоков скрыт за dispatcher
launch(Dispatchers.Default) {
    doWork()  // Выполняется на одном из потоков пула Default
}
```

В обоих случаях потоки не создаются и не уничтожаются с каждой задачей. Пул амортизирует стоимость создания потоков: заплатили один раз при старте, потом переиспользуем.

### Размер пула: наука выбора

Оптимальный размер пула зависит от типа задач:

- **CPU-bound работа:** ~количество ядер. Больше потоков создаст context switch overhead без увеличения throughput.
- **I/O-bound работа:** больше (потоки ждут I/O). Формула Брайана Гётца из "Java Concurrency in Practice": `threads = cores * (1 + wait_time / compute_time)`. Если wait = 9x compute, то threads = cores * 10.
- **Слишком много:** overhead на переключения и синхронизацию.
- **Слишком мало:** недоиспользование CPU, задачи стоят в очереди.

---

## Kotlin Coroutines как эволюция Green Threads

### Что такое coroutine на самом деле

Coroutine — это suspendable computation: вычисление, которое может приостановиться и возобновиться без блокировки потока. В отличие от "классических" green threads, Kotlin coroutines реализованы не через отдельные стеки, а через **state machine transformation** на уровне компилятора.

Когда компилятор Kotlin встречает `suspend fun`, он трансформирует её в конечный автомат (state machine). Каждый `suspend` point — это переход в новое состояние. При suspend'е состояние сохраняется в объект Continuation, поток освобождается. При возобновлении — состояние восстанавливается, и выполнение продолжается с следующего состояния.

Следующий пример показывает suspend-функцию, которая освобождает поток на время ожидания сетевого ответа.

```kotlin
suspend fun fetchData(): Data {
    val response = httpClient.get(url)  // suspend: поток освобождается
    return response.parse()              // resume: поток (возможно другой) продолжает
}
```

Критически важно: в точке `httpClient.get(url)` происходит suspend — текущий поток возвращается в пул, и его может использовать другая корутина. Когда ответ сервера приходит, scheduler находит свободный поток (не обязательно тот же) и продолжает выполнение.

### Как это работает внутри

```
Coroutine → suspend → Dispatcher возвращает thread в pool
                     ...другие coroutines работают на этом thread...
Coroutine → resume → Dispatcher назначает thread из pool
```

Один поток может исполнять тысячи coroutines (по очереди). Это возможно потому, что при suspend'е coroutine "уходит" с потока, не занимая его.

### Dispatchers: три стратегии

- **Dispatchers.Default:** CPU-bound, #cores потоков. Для вычислений.
- **Dispatchers.IO:** I/O-bound, расширяемый пул (64+). Для ожидания.
- **Dispatchers.Main:** UI поток (Android). Для обновления интерфейса.

### Преимущества coroutines над threads

| Аспект | Threads | Coroutines |
|--------|---------|------------|
| Память | Тяжёлые (~1 MB stack) | Лёгкие (~сотни байт — KB) |
| Ожидание I/O | Блокируют поток | Suspend без блокировки |
| Масштаб | Сотни — тысячи max | Тысячи — миллионы |
| Scheduling | OS scheduling | Structured concurrency |
| Отмена | Сложная (interrupt) | Кооперативная (CancellationException) |
| Lifecycle | Ручное управление | Привязан к CoroutineScope |

---

## Подводные камни

### Race Conditions

Общая память + несколько потоков = race conditions. Это фундаментальная проблема модели shared memory. Решения:
- Mutex / synchronized — взаимное исключение
- Atomic operations — неделимые операции
- Channels (share by communicating) — обмен через каналы вместо общей памяти
- Immutable data — неизменяемые данные не требуют синхронизации

### Deadlocks

Два потока ждут друг друга, каждый держит ресурс, нужный другому. Оба заблокированы навсегда. Это как два человека в узком коридоре: каждый ждёт, что другой уступит, и никто не двигается.

Следующий пример показывает классический deadlock: Thread 1 захватывает lock A и ждёт lock B, а Thread 2 захватывает lock B и ждёт lock A.

```kotlin
// Thread 1: lock A, then lock B
// Thread 2: lock B, then lock A
// → Deadlock! Каждый держит то, что нужно другому
```

Решение: всегда захватывать locks в одном и том же порядке. Подробнее — в [[synchronization-primitives]].

### Context Switch Overhead

Много потоков не значит много работы. Если у вас 1000 потоков на 4-ядерном CPU — 996 потоков в любой момент ждут, и каждое переключение между ними стоит CPU cycles. Правило: для CPU-bound задач оптимально потоков примерно столько, сколько ядер.

### Green Threads и Blocking: критическая ловушка

Blocking вызов в корутине блокирует поток dispatcher'а, лишая другие корутины возможности выполняться на этом потоке.

Следующий пример показывает ошибку — использование `Thread.sleep()` вместо `delay()` внутри корутины. Thread.sleep() блокирует поток ОС, а delay() только приостанавливает корутину.

```kotlin
// ПЛОХО: blocking call в coroutine — блокирует dispatcher thread!
launch {
    Thread.sleep(1000)  // Поток ОС заблокирован на 1 секунду
}

// ХОРОШО: suspend function — поток освобождается
launch {
    delay(1000)  // Suspend: поток возвращается в пул на 1 секунду
}
```

Разница критична: `Thread.sleep(1000)` на `Dispatchers.Default` с 4 ядрами блокирует 25% вычислительных ресурсов на секунду. `delay(1000)` не блокирует ничего — поток свободен для других корутин.

---

## Связь с другими темами

**[[concurrency-vs-parallelism]]** — процессы и потоки являются "кирпичиками", из которых строятся concurrent и parallel системы. Понимание потоков необходимо для осознания разницы: concurrency — это структура (как организовать потоки), parallelism — это выполнение (сколько потоков работают одновременно). Текущая статья — prerequisite.

**[[synchronization-primitives]]** — общая память потоков порождает необходимость в синхронизации. Mutex, semaphore, atomic operations — инструменты для безопасного доступа к shared state. Читай после текущей статьи.

**[[async-models-overview]]** — корутины, описанные здесь, это один из async моделей. В этой статье описаны и другие: callbacks, promises, reactive streams. Даёт более широкий контекст.

**[[memory-model-fundamentals]]** — чтобы понять, почему shared memory потоков создаёт проблемы, нужно разобраться в memory ordering: когда запись одного потока становится видимой другому. Это prerequisite.

---

## Источники и дальнейшее чтение

- **Tanenbaum, A. (2014). Modern Operating Systems.** — Каноническая книга по ОС. Главы 2-3 детально описывают процессы и потоки: от PCB до scheduling алгоритмов. Обязательное чтение для глубокого понимания.

- **Silberschatz, A. et al. (2018). Operating System Concepts.** — Альтернативный учебник, хорош для сравнения подходов. Главы 3-4 покрывают процессы и потоки с другого ракурса, включая thread models и thread libraries.

- **Goetz, B. et al. (2006). Java Concurrency in Practice.** — Практическое руководство по concurrent программированию на JVM. Формула размера thread pool и паттерны безопасного использования потоков.

- **Bryant, R. & O'Hallaron, D. (2015). Computer Systems: A Programmer's Perspective.** — Связь между hardware и software: как context switch работает на уровне процессора, TLB, кэша.

- **Love, R. (2010). Linux Kernel Development.** — Как процессы и потоки реализованы в ядре Linux. Task struct, clone(), scheduling policies.

---

*Проверено: 2026-02-10*
