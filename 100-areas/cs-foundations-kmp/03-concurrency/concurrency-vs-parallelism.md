---
title: "Concurrency vs Parallelism: принципиальная разница"
created: 2026-01-04
modified: 2026-01-04
type: concept
status: published
tags:
  - topic/cs-foundations
  - type/concept
  - level/intermediate
related:
  - "[[processes-threads-fundamentals]]"
  - "[[async-models-overview]]"
  - "[[synchronization-primitives]]"
---

# Concurrency vs Parallelism: принципиальная разница

> **TL;DR:** Concurrency — это **структура** программы (dealing with many things). Parallelism — это **выполнение** (doing many things). Одно про дизайн, другое про железо. Concurrency возможна на одном ядре, parallelism требует нескольких. Rob Pike: "Concurrency is about structure, parallelism is about execution."

---

## Prerequisites

| Тема | Зачем нужно | Где изучить |
|------|-------------|-------------|
| **Процессы и потоки** | Понимание единиц выполнения | [[processes-threads-fundamentals]] |
| **Async модели** | Как организуется concurrent код | [[async-models-overview]] |

---

## Терминология

| Термин | Что это | Аналогия из жизни |
|--------|---------|-------------------|
| **Concurrency** | Структурирование программы для работы с несколькими задачами | Жонглёр подбрасывает несколько мячей, но в руке всегда один |
| **Parallelism** | Одновременное выполнение нескольких задач | Несколько жонглёров, каждый со своим мячом |
| **Context switch** | Переключение процессора между задачами | Повар переключается между блюдами |
| **Throughput** | Количество выполненной работы за единицу времени | Пропускная способность кассы |

---

## ПОЧЕМУ важно различать

### Проблема: смешение понятий

Термины "concurrency" и "parallelism" постоянно путают. Разработчики говорят "параллельно" про любой многозадачный код. Это приводит к:

- Неправильному выбору инструментов
- Ожиданию ускорения там, где его не будет
- Избыточной сложности архитектуры

### История термина

**1960-е:** Появление многозадачных ОС. Один процессор, много программ. Это была concurrency — time-sharing, иллюзия одновременности.

**1980-е:** Многопроцессорные системы. Теперь действительно можно выполнять несколько операций одновременно. Это parallelism.

**2012:** Rob Pike (создатель Go) в докладе ["Concurrency is not Parallelism"](https://go.dev/blog/waza-talk) чётко разделил понятия. Этот доклад стал каноническим объяснением разницы.

### Ключевая цитата Rob Pike

> "Concurrency is about dealing with lots of things at once. Parallelism is about doing lots of things at once. Not the same, but related. Concurrency is about structure, parallelism is about execution."

**Перевод:**
- Concurrency — про **работу** с множеством вещей (структура)
- Parallelism — про **выполнение** множества вещей (исполнение)
- Это не одно и то же, но связано

---

## ЧТО такое Concurrency

### Определение

Concurrency — это **композиция независимо выполняемых процессов**. Это свойство программы, способ её организации. Программа concurrent, если она структурирована как набор задач, которые могут выполняться в любом порядке.

```
┌─────────────────────────────────────────────────────────────┐
│                      CONCURRENCY                            │
│                                                             │
│   Программа разбита на независимые части                    │
│                                                             │
│   ┌──────┐   ┌──────┐   ┌──────┐   ┌──────┐               │
│   │Task A│   │Task B│   │Task C│   │Task D│               │
│   └──────┘   └──────┘   └──────┘   └──────┘               │
│                                                             │
│   Могут выполняться в любом порядке:                        │
│   A → B → C → D                                             │
│   A → C → B → D                                             │
│   B → A → D → C                                             │
│                                                             │
│   Важно: это про СТРУКТУРУ, не про исполнение              │
└─────────────────────────────────────────────────────────────┘
```

### Аналогия: один повар, несколько блюд

Представь повара на кухне. Ему нужно приготовить три блюда: суп, салат, стейк.

**Concurrent подход:**
1. Поставил суп вариться (10 минут ожидания)
2. Пока суп варится — режет салат
3. Салат готов, проверил суп
4. Поставил стейк на гриль (5 минут)
5. Пока стейк жарится — доделывает суп
6. Всё готово

Повар **один**, но он **работает** с тремя задачами. Это concurrency — структурирование работы так, чтобы эффективно использовать время ожидания.

### Возможна на одном ядре

Критически важно: concurrency не требует нескольких процессоров. На single-core системе concurrent программа работает через **context switching** — процессор быстро переключается между задачами.

```
Single-core CPU timeline:
┌────┬────┬────┬────┬────┬────┬────┬────┐
│ A  │ B  │ A  │ C  │ B  │ A  │ C  │ B  │
└────┴────┴────┴────┴────┴────┴────┴────┘
         Time →

Задачи A, B, C выполняются "по очереди".
Для пользователя выглядит как "одновременно".
```

---

## ЧТО такое Parallelism

### Определение

Parallelism — это **одновременное выполнение** нескольких вычислений. Это свойство исполнения, а не программы. Parallelism требует hardware: несколько ядер, процессоров или машин.

```
┌─────────────────────────────────────────────────────────────┐
│                      PARALLELISM                            │
│                                                             │
│   Несколько ядер выполняют работу одновременно             │
│                                                             │
│   Core 1: ████████████████████                             │
│   Core 2: ████████████████████                             │
│   Core 3: ████████████████████                             │
│   Core 4: ████████████████████                             │
│                                                             │
│   В каждый момент времени работают ВСЕ ядра                │
│                                                             │
│   Важно: это про ИСПОЛНЕНИЕ, требует hardware              │
└─────────────────────────────────────────────────────────────┘
```

### Аналогия: несколько поваров

Теперь на кухне **четыре повара**. Каждый готовит своё блюдо одновременно с другими.

**Parallel подход:**
- Повар 1 готовит суп
- Повар 2 режет салат
- Повар 3 жарит стейк
- Повар 4 делает десерт

Все работают **одновременно**. Это parallelism — реальное одновременное выполнение.

### Требует нескольких ядер

Parallelism невозможен на single-core системе. Чтобы делать две вещи одновременно, нужно два исполнителя.

```
Multi-core CPU timeline:
Core 1: ████████████████████ Task A
Core 2: ████████████████████ Task B
Core 3: ████████████████████ Task C
Core 4: ████████████████████ Task D
                Time →

Все задачи выполняются ОДНОВРЕМЕННО.
```

---

## Комбинации Concurrency и Parallelism

### Матрица возможностей

| Сценарий | Concurrent? | Parallel? | Пример |
|----------|-------------|-----------|--------|
| Single-core, одна задача | Нет | Нет | Простой скрипт |
| Single-core, много задач | **Да** | Нет | Node.js event loop |
| Multi-core, одна задача | Нет | **Да** | Параллельная сортировка массива |
| Multi-core, много задач | **Да** | **Да** | Web-сервер с thread pool |

### Визуализация комбинаций

```
┌───────────────────────────────────────────────────────────────┐
│           CONCURRENT + PARALLEL (идеальный случай)            │
├───────────────────────────────────────────────────────────────┤
│                                                               │
│   Core 1: ──A──A──A──B──B──C──                               │
│   Core 2: ──B──C──C──A──A──A──                               │
│   Core 3: ──C──B──B──C──D──D──                               │
│   Core 4: ──D──D──A──B──B──C──                               │
│                                                               │
│   Много задач (concurrent) на много ядер (parallel)          │
│   Максимальная эффективность                                  │
└───────────────────────────────────────────────────────────────┘

┌───────────────────────────────────────────────────────────────┐
│            CONCURRENT, NOT PARALLEL (single-core)             │
├───────────────────────────────────────────────────────────────┤
│                                                               │
│   Core 1: ──A──B──C──A──B──A──C──B──A──C──                   │
│                                                               │
│   Много задач переключаются на одном ядре                    │
│   Node.js на одноядерном сервере                             │
└───────────────────────────────────────────────────────────────┘

┌───────────────────────────────────────────────────────────────┐
│            PARALLEL, NOT CONCURRENT (data parallelism)        │
├───────────────────────────────────────────────────────────────┤
│                                                               │
│   Core 1: ──────────TASK A part 1──────────                  │
│   Core 2: ──────────TASK A part 2──────────                  │
│   Core 3: ──────────TASK A part 3──────────                  │
│   Core 4: ──────────TASK A part 4──────────                  │
│                                                               │
│   Одна задача разбита на части                               │
│   Параллельная обработка массива                             │
└───────────────────────────────────────────────────────────────┘
```

---

## CPU-bound vs IO-bound: когда что использовать

### Таблица выбора

| Тип задачи | Примеры | Лучший подход | Почему |
|------------|---------|---------------|--------|
| **CPU-bound** | Вычисления, ML, рендеринг, сжатие | Parallelism | Больше ядер = больше throughput |
| **IO-bound** | Network, disk, database | Concurrency | Поток ждёт IO, можно делать другое |

### CPU-bound задачи

CPU-bound задача — та, где время выполнения ограничено скоростью процессора. Примеры:
- Математические вычисления
- Рендеринг видео
- Обучение ML-модели
- Сжатие файлов

**Для CPU-bound нужен parallelism:**

```kotlin
// CPU-bound: расчёт хешей
val hashes = files.map { file ->
    async(Dispatchers.Default) {  // Default = CPU cores
        calculateHash(file)
    }
}.awaitAll()

// Dispatchers.Default использует столько потоков,
// сколько ядер на машине
```

### IO-bound задачи

IO-bound задача — та, где время выполнения ограничено ожиданием ввода-вывода. Примеры:
- HTTP-запросы
- Чтение с диска
- Запросы к базе данных
- WebSocket соединения

**Для IO-bound достаточно concurrency:**

```kotlin
// IO-bound: загрузка данных из API
val results = urls.map { url ->
    async(Dispatchers.IO) {  // IO = 64+ потоков
        fetchFromNetwork(url)
    }
}.awaitAll()

// Пока один запрос ждёт ответа,
// другие запросы отправляются
```

### Почему так?

**CPU-bound:** Процессор занят 100% времени. Единственный способ ускорить — добавить процессоры. Concurrency на single-core не даст ускорения — просто те же вычисления будут переключаться.

**IO-bound:** Процессор ждёт 90% времени. Можно использовать это время для других задач. Concurrency позволяет одному ядру обрабатывать тысячи соединений.

---

## Amdahl's Law: предел ускорения

### Формула

Gene Amdahl в 1967 году сформулировал закон, ограничивающий ускорение от parallelism:

```
         1
S = ─────────────
    (1-P) + P/N

S = итоговое ускорение
P = доля параллелизуемого кода (0 до 1)
N = количество процессоров
```

### Визуализация

```
┌─────────────────────────────────────────────────────────────┐
│                     AMDAHL'S LAW                            │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│   Программа: 90% параллелизуемо, 10% последовательно        │
│                                                             │
│   N=1:   [████████████████████] = 1x                       │
│   N=2:   [██████████]           = 1.8x                     │
│   N=4:   [██████]               = 3.1x                     │
│   N=8:   [████]                 = 4.7x                     │
│   N=16:  [███]                  = 6.4x                     │
│   N=∞:   [██]                   = 10x (предел!)            │
│                                                             │
│   Sequential часть (10%) — bottleneck                       │
│   Даже с бесконечными ядрами: max 10x                      │
└─────────────────────────────────────────────────────────────┘
```

### Практический вывод

**Предел ускорения определяется sequential частью:**

```
При P = 0.9 (90% параллельно):
S∞ = 1/(1-0.9) = 10x maximum

При P = 0.5 (50% параллельно):
S∞ = 1/(1-0.5) = 2x maximum

При P = 0.99 (99% параллельно):
S∞ = 1/(1-0.99) = 100x maximum
```

**Это значит:**
- Добавление ядер даёт diminishing returns
- Sequential bottleneck важнее количества ядер
- Оптимизация sequential части эффективнее, чем добавление hardware

---

## Kotlin Dispatchers: практическое применение

### Три основных диспетчера

| Dispatcher | Назначение | Количество потоков |
|------------|------------|-------------------|
| **Default** | CPU-bound задачи | Число ядер |
| **IO** | IO-bound задачи | 64 (или число ядер, если больше) |
| **Main** | UI операции | 1 |

### Как выбрать диспетчер

```kotlin
// CPU-bound: сортировка, хеширование, парсинг JSON
withContext(Dispatchers.Default) {
    val sorted = hugeList.sorted()
    val hash = calculateSHA256(data)
    val parsed = Json.decodeFromString<Data>(json)
}

// IO-bound: сеть, файлы, база данных
withContext(Dispatchers.IO) {
    val response = httpClient.get(url)
    val content = file.readText()
    val users = database.getUsers()
}

// UI: обновление интерфейса (Android/Desktop)
withContext(Dispatchers.Main) {
    textView.text = result
    progressBar.visibility = View.GONE
}
```

### limitedParallelism: контроль параллелизма

```kotlin
// Ограничить IO до 4 параллельных операций
val limitedIO = Dispatchers.IO.limitedParallelism(4)

// Последовательное выполнение (1 операция за раз)
val sequential = Dispatchers.IO.limitedParallelism(1)

// Пример: ограничение запросов к API
val apiDispatcher = Dispatchers.IO.limitedParallelism(10)

suspend fun fetchData(): List<Result> {
    return urls.map { url ->
        async(apiDispatcher) {
            api.fetch(url)
        }
    }.awaitAll()
}
```

**Важно:** `limitedParallelism` не создаёт новые потоки — это view с ограничением на существующий пул.

---

## Практические примеры

### Web-сервер

```
┌─────────────────────────────────────────────────────────────┐
│                      WEB SERVER                             │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│   CONCURRENCY:                                              │
│   Обрабатывает тысячи соединений "одновременно"            │
│   Event loop не блокируется на каждом запросе              │
│                                                             │
│   PARALLELISM:                                              │
│   Worker threads обрабатывают запросы на разных ядрах      │
│   Тяжёлые операции распределяются                          │
│                                                             │
│   Client 1 ─┐                    ┌─> Core 1                │
│   Client 2 ─┼─> Event Loop ─────>├─> Core 2                │
│   Client 3 ─┤   (concurrent)     ├─> Core 3                │
│   Client N ─┘                    └─> Core 4                │
│                                      (parallel)            │
└─────────────────────────────────────────────────────────────┘
```

### Видео-рендеринг

```
┌─────────────────────────────────────────────────────────────┐
│                    VIDEO RENDERING                          │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│   Parallelism доминирует:                                   │
│                                                             │
│   Frame 1-100:   Core 1 ████████████                       │
│   Frame 101-200: Core 2 ████████████                       │
│   Frame 201-300: Core 3 ████████████                       │
│   Frame 301-400: Core 4 ████████████                       │
│                                                             │
│   Каждое ядро рендерит свой кусок                          │
│   Минимум concurrency — чистый parallelism                 │
└─────────────────────────────────────────────────────────────┘
```

### Чат-приложение

```
┌─────────────────────────────────────────────────────────────┐
│                    CHAT APPLICATION                         │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│   Concurrency доминирует:                                   │
│                                                             │
│   Single Core: ─ws1─ws2─ws1─ws3─ws2─ws1─ws4─                │
│                                                             │
│   Тысячи WebSocket соединений                              │
│   IO-bound: ждём сообщений                                 │
│   Одно ядро справляется                                    │
│                                                             │
│   Parallelism не даст ускорения                            │
│   (нечего вычислять параллельно)                           │
└─────────────────────────────────────────────────────────────┘
```

---

## Подводные камни

### Когда НЕ нужен parallelism

**IO-bound операции:** Добавление ядер не ускорит ожидание сети. 4 ядра ждут ответа от сервера так же долго, как одно.

**Малый объём данных:** Overhead на создание потоков и синхронизацию может превысить выигрыш. Сортировка 100 элементов быстрее на одном ядре.

**Sequential dependencies:** Если задача B зависит от результата A, параллелить нечего.

### Когда НЕ нужна concurrency

**Простые скрипты:** Если задача одна и линейная, concurrency добавит сложности без пользы.

**Tight loops:** CPU-bound код без IO не выиграет от concurrent структуры.

### Распространённые ошибки

| Ошибка | Последствие | Решение |
|--------|-------------|---------|
| Dispatchers.IO для CPU-bound | 64+ потоков борются за ядра, context switching overhead | Использовать Dispatchers.Default |
| Dispatchers.Default для IO | Заблокированы все ядра, UI зависает | Использовать Dispatchers.IO |
| Parallelism для малых задач | Overhead > выигрыш | Измерить, использовать threshold |
| Игнорирование Amdahl's Law | Ожидание линейного ускорения | Оптимизировать sequential часть |

### Мифы и заблуждения

**Миф:** "Больше потоков = быстрее"
**Реальность:** Для CPU-bound оптимально potokов ≈ ядер. Больше — только overhead.

**Миф:** "Concurrent = параллельный"
**Реальность:** Concurrent код может выполняться последовательно на одном ядре.

**Миф:** "Async/await делает код параллельным"
**Реальность:** Async делает код concurrent. Parallelism зависит от dispatcher и hardware.

---

## Куда дальше

**Если здесь впервые:**
→ [[processes-threads-fundamentals]] — как работают потоки

**Если понял и хочешь глубже:**
→ [[synchronization-primitives]] — mutex, semaphore, проблемы синхронизации

**Практическое применение:**
→ [[async-models-overview]] — как применить concurrency в коде

---

## Источники

- [Rob Pike: Concurrency is not Parallelism](https://go.dev/blog/waza-talk) — оригинальный доклад, определения
- [ByteByteGo: Visual Guide](https://bytebytego.com/guides/concurrency-is-not-parallelism/) — отличные диаграммы
- [kt.academy: Dispatchers](https://kt.academy/article/cc-dispatchers) — Kotlin специфика
- [Wikipedia: Amdahl's Law](https://en.wikipedia.org/wiki/Amdahl%27s_law) — формула и история
- [Baeldung: Concurrency vs Parallelism](https://www.baeldung.com/cs/concurrency-vs-parallelism) — чёткие различия

---

*Проверено: 2026-01-09*
