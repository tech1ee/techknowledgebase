---
title: "Concurrency vs Parallelism: принципиальная разница"
created: 2026-01-04
modified: 2026-02-10
type: concept
status: published
tags:
  - topic/cs-foundations
  - type/concept
  - level/intermediate
related:
  - "[[processes-threads-fundamentals]]"
  - "[[async-models-overview]]"
  - "[[synchronization-primitives]]"
prerequisites:
  - "[[processes-threads-fundamentals]]"
---

# Concurrency vs Parallelism: принципиальная разница

> **TL;DR:** Concurrency — это **структура** программы (dealing with many things). Parallelism — это **выполнение** (doing many things). Одно про дизайн, другое про железо. Concurrency возможна на одном ядре, parallelism требует нескольких. Rob Pike: "Concurrency is about structure, parallelism is about execution."

---

## Prerequisites

| Тема | Зачем нужно | Где изучить |
|------|-------------|-------------|
| **Процессы и потоки** | Понимание единиц выполнения | [[processes-threads-fundamentals]] |
| **Async модели** | Как организуется concurrent код | [[async-models-overview]] |

---

## Терминология

| Термин | Что это | Аналогия из жизни |
|--------|---------|-------------------|
| **Concurrency** | Структурирование программы для работы с несколькими задачами | Жонглёр подбрасывает несколько мячей, но в руке всегда один |
| **Parallelism** | Одновременное выполнение нескольких задач | Несколько жонглёров, каждый со своим мячом |
| **Context switch** | Переключение процессора между задачами | Повар переключается между блюдами |
| **Throughput** | Количество выполненной работы за единицу времени | Пропускная способность кассы |
| **Amdahl's Law** | Закон, ограничивающий максимальное ускорение от параллелизма | Самый медленный участник конвейера определяет скорость всей цепи |
| **Concurrency model** | Подход к организации одновременно выполняемых задач | Способ управления несколькими рабочими на стройке |

---

## ПОЧЕМУ важно различать

### Проблема: смешение понятий ведёт к ошибкам архитектуры

Термины "concurrency" и "parallelism" постоянно путают. Разработчики говорят "параллельно" про любой многозадачный код. Это не просто терминологическая неточность — это ведёт к реальным проблемам в проектировании. Когда инженер путает эти понятия, он выбирает неправильные инструменты, ожидает ускорение там, где его не будет, и создаёт избыточно сложную архитектуру.

Представь себе ситуацию: мобильный разработчик решает, что его приложение "тормозит" из-за недостатка параллелизма. Он разбивает задачу на 8 потоков — по одному на ядро. Но задача IO-bound: приложение ждёт ответа от сервера. 8 потоков ждут ответа ровно так же долго, как один. Проблема была не в parallelism, а в отсутствии правильной concurrency — нужен был неблокирующий ввод-вывод.

Обратный пример: ML-инженер обрабатывает матрицу размером 10 000 x 10 000. Он использует async/await, думая что это "параллельно". Но async — это concurrency, структурирование задач. Если код CPU-bound (умножение матриц), async на одном ядре ничего не ускорит — нужен настоящий parallelism, распределение работы между ядрами.

> **Ключевая идея:** Правильное различение concurrency и parallelism — это не педантизм, а инструмент для выбора правильной стратегии. IO-bound проблемы требуют concurrency. CPU-bound проблемы требуют parallelism. Применить не то = потерять время.

### История термина

**1960-е:** Появление многозадачных ОС. Один процессор, много программ. Это была concurrency — time-sharing, иллюзия одновременности. Операционная система Multics (1964) и позже Unix (1969) заложили фундамент: несколько программ поочерёдно используют один процессор, и каждая "думает", что она одна.

**1967:** Джин Амдал (Gene Amdahl) выступает на конференции AFIPS и формулирует закон, который навсегда определит пределы параллелизма. Его аргумент был направлен против подхода "просто добавь процессоров" — Амдал показал, что последовательная часть программы определяет потолок ускорения.

**1978:** Тони Хоар (Tony Hoare) публикует "Communicating Sequential Processes" — формальный язык для описания паттернов взаимодействия в concurrent системах. Эта работа через 30 лет ляжет в основу Go goroutines.

**1980-е:** Многопроцессорные системы становятся доступными. Теперь действительно можно выполнять несколько операций одновременно. Это parallelism — и стало ясно, что это другая, отдельная вещь.

**1986:** Карл Хьюитт (Carl Hewitt) развивает модель акторов, предложенную им ещё в 1973 году. Акторы — ещё одна модель concurrency, альтернатива shared memory.

**2012:** Rob Pike (создатель Go) в докладе ["Concurrency is not Parallelism"](https://go.dev/blog/waza-talk) чётко разделил понятия. Этот доклад стал каноническим объяснением разницы и расставил точки над i для целого поколения программистов.

---

## ПОЧЕМУ различие не ограничивается цитатой Пайка

Цитата Rob Pike — хорошая мнемоника, но она не объясняет глубины различия. Давай разберём подробнее, почему эти понятия принципиально разные.

### Concurrency — свойство программы

Concurrency — это свойство **кода**, а не **среды выполнения**. Программа либо concurrent, либо нет — вне зависимости от того, на скольких ядрах она запущена. Concurrent программа разбита на части, которые **логически** независимы и могут быть выполнены в любом порядке.

Аналогия: рецепт приготовления обеда. Если рецепт написан так, что ты можешь начать готовить салат пока суп варится — это concurrent рецепт. Один ты на кухне или четверо — рецепт не меняется. Он **структурирован** для работы с несколькими задачами.

### Parallelism — свойство выполнения

Parallelism — это свойство **исполняющей среды**. Это означает, что две или более операции физически выполняются в один и тот же момент времени. Для parallelism нужен hardware: несколько ядер, процессоров или машин.

Аналогия: в ресторане может быть рецепт для одного повара (sequential), рецепт для одного повара с переключениями (concurrent), или рецепт для бригады из четырёх поваров (parallel). Рецепт — это программа, количество поваров — это hardware.

### Три критических различия

**1. Независимость от hardware.** Concurrency не зависит от количества ядер. Node.js — concurrent, хотя работает на одном потоке. Go runtime — concurrent и parallel одновременно.

**2. Разный тип проблем.** Concurrency решает задачу **управления сложностью**: как организовать программу, которая одновременно обрабатывает HTTP-запросы, пишет в базу и отправляет уведомления. Parallelism решает задачу **скорости**: как быстрее перемножить матрицу 10000x10000.

**3. Разная модель мышления.** Думая о concurrency, ты декомпозируешь задачу на независимые части. Думая о parallelism, ты декомпозируешь **данные** на порции для обработки на разных ядрах.

> **Ключевая идея:** Concurrency без parallelism — это Node.js event loop на одном ядре. Parallelism без concurrency — это GPU, обрабатывающий тысячи одинаковых операций одновременно. Лучшие системы используют оба: concurrent программа на parallel hardware.

---

## ЧТО такое Concurrency

### Определение

Concurrency — это **композиция независимо выполняемых процессов**. Это свойство программы, способ её организации. Программа concurrent, если она структурирована как набор задач, которые могут выполняться в любом порядке.

Важно понимать слово "независимо" правильно. Задачи не обязательно полностью изолированы — они могут обмениваться данными и координироваться. "Независимо выполняемые" означает, что каждая задача имеет свою логику и продвигается своим темпом, а не что задачи ничего не знают друг о друге.

```
┌─────────────────────────────────────────────────────────────┐
│                      CONCURRENCY                            │
│                                                             │
│   Программа разбита на независимые части                    │
│                                                             │
│   ┌──────┐   ┌──────┐   ┌──────┐   ┌──────┐               │
│   │Task A│   │Task B│   │Task C│   │Task D│               │
│   └──────┘   └──────┘   └──────┘   └──────┘               │
│                                                             │
│   Могут выполняться в любом порядке:                        │
│   A → B → C → D                                             │
│   A → C → B → D                                             │
│   B → A → D → C                                             │
│                                                             │
│   Важно: это про СТРУКТУРУ, не про исполнение              │
└─────────────────────────────────────────────────────────────┘
```

### Аналогия: один повар, несколько блюд

Представь повара на кухне. Ему нужно приготовить три блюда: суп, салат, стейк.

**Concurrent подход:**
1. Поставил суп вариться (10 минут ожидания)
2. Пока суп варится — режет салат
3. Салат готов, проверил суп
4. Поставил стейк на гриль (5 минут)
5. Пока стейк жарится — доделывает суп
6. Всё готово

Повар **один**, но он **работает** с тремя задачами. Это concurrency — структурирование работы так, чтобы эффективно использовать время ожидания. Заметь: повар не стал быстрее нарезать овощи. Он стал **умнее** организовывать своё время.

### Возможна на одном ядре

Критически важно: concurrency не требует нескольких процессоров. На single-core системе concurrent программа работает через **context switching** — процессор быстро переключается между задачами.

```
Single-core CPU timeline:
┌────┬────┬────┬────┬────┬────┬────┬────┐
│ A  │ B  │ A  │ C  │ B  │ A  │ C  │ B  │
└────┴────┴────┴────┴────┴────┴────┴────┘
         Time →

Задачи A, B, C выполняются "по очереди".
Для пользователя выглядит как "одновременно".
```

Мы разобрали, что такое concurrency как свойство программы. Но что происходит, когда задачи действительно выполняются одновременно?

---

## ЧТО такое Parallelism

### Определение

Parallelism — это **одновременное выполнение** нескольких вычислений. Это свойство исполнения, а не программы. Parallelism требует hardware: несколько ядер, процессоров или машин.

Чтобы две операции выполнялись параллельно, им нужны два **физических** исполнителя. Нельзя обмануть физику: один процессор в один момент времени выполняет одну инструкцию (упрощённо — без pipelining и superscalar).

```
┌─────────────────────────────────────────────────────────────┐
│                      PARALLELISM                            │
│                                                             │
│   Несколько ядер выполняют работу одновременно             │
│                                                             │
│   Core 1: ████████████████████                             │
│   Core 2: ████████████████████                             │
│   Core 3: ████████████████████                             │
│   Core 4: ████████████████████                             │
│                                                             │
│   В каждый момент времени работают ВСЕ ядра                │
│                                                             │
│   Важно: это про ИСПОЛНЕНИЕ, требует hardware              │
└─────────────────────────────────────────────────────────────┘
```

### Аналогия: несколько поваров

Теперь на кухне **четыре повара**. Каждый готовит своё блюдо одновременно с другими.

**Parallel подход:**
- Повар 1 готовит суп
- Повар 2 режет салат
- Повар 3 жарит стейк
- Повар 4 делает десерт

Все работают **одновременно**. Это parallelism — реальное одновременное выполнение. Но заметь: чтобы parallelism был эффективным, нужна предварительная **concurrent** декомпозиция: кто-то должен был разбить меню на независимые блюда и раздать их поварам.

### Требует нескольких ядер

Parallelism невозможен на single-core системе. Чтобы делать две вещи одновременно, нужно два исполнителя.

```
Multi-core CPU timeline:
Core 1: ████████████████████ Task A
Core 2: ████████████████████ Task B
Core 3: ████████████████████ Task C
Core 4: ████████████████████ Task D
                Time →

Все задачи выполняются ОДНОВРЕМЕННО.
```

Мы увидели, как concurrency и parallelism работают по отдельности. А что если их комбинировать?

---

## Комбинации Concurrency и Parallelism

### Матрица возможностей

| Сценарий | Concurrent? | Parallel? | Пример |
|----------|-------------|-----------|--------|
| Single-core, одна задача | Нет | Нет | Простой скрипт |
| Single-core, много задач | **Да** | Нет | Node.js event loop |
| Multi-core, одна задача | Нет | **Да** | Параллельная сортировка массива |
| Multi-core, много задач | **Да** | **Да** | Web-сервер с thread pool |

### Визуализация комбинаций

```
┌───────────────────────────────────────────────────────────────┐
│           CONCURRENT + PARALLEL (идеальный случай)            │
├───────────────────────────────────────────────────────────────┤
│                                                               │
│   Core 1: ──A──A──A──B──B──C──                               │
│   Core 2: ──B──C──C──A──A──A──                               │
│   Core 3: ──C──B──B──C──D──D──                               │
│   Core 4: ──D──D──A──B──B──C──                               │
│                                                               │
│   Много задач (concurrent) на много ядер (parallel)          │
│   Максимальная эффективность                                  │
└───────────────────────────────────────────────────────────────┘

┌───────────────────────────────────────────────────────────────┐
│            CONCURRENT, NOT PARALLEL (single-core)             │
├───────────────────────────────────────────────────────────────┤
│                                                               │
│   Core 1: ──A──B──C──A──B──A──C──B──A──C──                   │
│                                                               │
│   Много задач переключаются на одном ядре                    │
│   Node.js на одноядерном сервере                             │
└───────────────────────────────────────────────────────────────┘

┌───────────────────────────────────────────────────────────────┐
│            PARALLEL, NOT CONCURRENT (data parallelism)        │
├───────────────────────────────────────────────────────────────┤
│                                                               │
│   Core 1: ──────────TASK A part 1──────────                  │
│   Core 2: ──────────TASK A part 2──────────                  │
│   Core 3: ──────────TASK A part 3──────────                  │
│   Core 4: ──────────TASK A part 4──────────                  │
│                                                               │
│   Одна задача разбита на части                               │
│   Параллельная обработка массива                             │
└───────────────────────────────────────────────────────────────┘
```

---

## CPU-bound vs IO-bound: когда что использовать

### Таблица выбора

| Тип задачи | Примеры | Лучший подход | Почему |
|------------|---------|---------------|--------|
| **CPU-bound** | Вычисления, ML, рендеринг, сжатие | Parallelism | Больше ядер = больше throughput |
| **IO-bound** | Network, disk, database | Concurrency | Поток ждёт IO, можно делать другое |

### CPU-bound задачи

CPU-bound задача — та, где время выполнения ограничено скоростью процессора. Процессор загружен на 100%, и единственный способ ускорить — это дать больше вычислительных ресурсов. Примеры: математические вычисления, рендеринг видео, обучение ML-модели, сжатие файлов.

Для CPU-bound задач нужен parallelism. Представь, что тебе нужно рассчитать хеши SHA-256 для миллиона файлов. Каждый хеш — чистая вычислительная работа. Чем больше ядер работают одновременно, тем быстрее результат.

Ниже показано, как Kotlin распределяет CPU-bound работу между ядрами через `Dispatchers.Default`, который создаёт пул потоков равный количеству ядер процессора.

```kotlin
// CPU-bound: расчёт хешей — каждый файл загружает ядро полностью
val hashes = files.map { file ->
    async(Dispatchers.Default) {  // Default = столько потоков, сколько ядер
        calculateHash(file)       // Чистые вычисления, CPU загружен на 100%
    }
}.awaitAll()
```

Здесь `Dispatchers.Default` использует ровно столько потоков, сколько ядер на машине. Больше потоков не нужно — лишние потоки только создадут overhead на context switching, потому что ядра и так загружены на 100%.

### IO-bound задачи

IO-bound задача — та, где время выполнения ограничено ожиданием ввода-вывода. Процессор бездействует 90%+ времени, ожидая ответа от сети, диска или базы данных. Примеры: HTTP-запросы, чтение с диска, запросы к базе данных, WebSocket соединения.

Для IO-bound задач достаточно concurrency. Не нужно добавлять ядра — нужно эффективно использовать время ожидания. Один поток может управлять тысячами сетевых соединений, если он не блокируется на каждом.

Следующий пример демонстрирует concurrent загрузку данных из API. Пока один запрос ждёт ответа сервера, поток освобождается для обработки других запросов.

```kotlin
// IO-bound: загрузка данных из API — поток ждёт 99% времени
val results = urls.map { url ->
    async(Dispatchers.IO) {  // IO = 64+ потоков (потоки в основном ждут)
        fetchFromNetwork(url) // Поток ждёт ответа сервера
    }
}.awaitAll()
```

`Dispatchers.IO` использует пул из 64+ потоков, потому что IO-bound потоки большую часть времени спят в ожидании. Много потоков не перегружают CPU — они просто ждут.

### Почему так?

**CPU-bound:** Процессор занят 100% времени. Единственный способ ускорить — добавить процессоры. Concurrency на single-core не даст ускорения — просто те же вычисления будут переключаться, а overhead на переключение ещё и замедлит.

**IO-bound:** Процессор ждёт 90% времени. Можно использовать это время для других задач. Concurrency позволяет одному ядру обрабатывать тысячи соединений. Parallelism тут избыточен — четыре ядра ждут сервер не быстрее одного.

---

## Amdahl's Law: предел ускорения

### Формула и её происхождение

Gene Amdahl в 1967 году выступил на конференции AFIPS (American Federation of Information Processing Societies) с докладом, который навсегда изменил понимание пределов параллельных вычислений. Его аргумент был прост и жесток: не важно сколько процессоров вы добавите — программа не может работать быстрее своей последовательной части.

```
         1
S = ─────────────
    (1-P) + P/N

S = итоговое ускорение
P = доля параллелизуемого кода (0 до 1)
N = количество процессоров
```

Чтобы понять формулу, разберём её по частям. `(1-P)` — это доля кода, которую **невозможно** распараллелить. Она выполняется всегда: хоть на 1 ядре, хоть на миллионе. `P/N` — это параллельная часть, разделённая на N процессоров. При N стремящемся к бесконечности `P/N` стремится к нулю, и остаётся `S = 1/(1-P)` — это **потолок**, который нельзя пробить.

### Практическое значение: таблица ускорений

Ниже — таблица, которая показывает, что происходит при разных долях параллельного кода. Она наглядно демонстрирует закон убывающей отдачи от добавления процессоров.

| % параллельного кода | 2 ядра | 4 ядра | 8 ядер | 16 ядер | 64 ядра | ∞ ядер (предел) |
|---------------------|--------|--------|--------|---------|---------|----------------|
| **50%** | 1.33x | 1.60x | 1.78x | 1.88x | 1.97x | **2x** |
| **75%** | 1.60x | 2.29x | 2.91x | 3.37x | 3.82x | **4x** |
| **90%** | 1.82x | 3.08x | 4.71x | 6.40x | 8.77x | **10x** |
| **95%** | 1.90x | 3.48x | 5.93x | 9.14x | 15.42x | **20x** |
| **99%** | 1.98x | 3.88x | 7.48x | 13.91x | 39.26x | **100x** |

Посмотри на строку 50%: даже с **бесконечным** числом ядер ускорение не превысит 2x. Половина программы работает последовательно — и это непреодолимый барьер. А 64 ядра дают лишь 1.97x — почти весь выигрыш достигается уже на 4 ядрах.

Строка 95% выглядит лучше: с 16 ядрами мы получаем 9.14x ускорения. Но предел — 20x. Добавление ядер сверх 16 даёт всё меньше отдачи.

### Визуализация

```
┌─────────────────────────────────────────────────────────────┐
│                     AMDAHL'S LAW                            │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│   Программа: 90% параллелизуемо, 10% последовательно        │
│                                                             │
│   N=1:   [████████████████████] = 1x                       │
│   N=2:   [██████████]           = 1.8x                     │
│   N=4:   [██████]               = 3.1x                     │
│   N=8:   [████]                 = 4.7x                     │
│   N=16:  [███]                  = 6.4x                     │
│   N=∞:   [██]                   = 10x (предел!)            │
│                                                             │
│   Sequential часть (10%) — bottleneck                       │
│   Даже с бесконечными ядрами: max 10x                      │
└─────────────────────────────────────────────────────────────┘
```

### Практический вывод: что это значит для инженера

Амдал показал три вещи, которые определяют стратегию оптимизации:

**1. Diminishing returns.** Каждое следующее ядро даёт меньше прироста, чем предыдущее. Переход с 1 на 2 ядра даёт максимальный прирост. Переход с 32 на 64 — почти незаметный.

**2. Sequential bottleneck важнее hardware.** Оптимизация 10% последовательного кода даёт больше, чем удвоение числа ядер. Если ты превратил 10% sequential в 5% — предел поднялся с 10x до 20x. Это мощнее любого hardware upgrade.

**3. Gustafson's Law как контраргумент.** В 1988 году Джон Густафсон (John Gustafson) предложил альтернативный взгляд: при увеличении числа ядер мы не ускоряем ту же задачу — мы решаем **бо́льшую** задачу за то же время. Массив не в 10K, а в 100K элементов. Это снижает долю sequential кода, потому что sequential часть обычно фиксирована (инициализация, финализация), а параллельная часть масштабируется с размером данных.

---

## Модели конкурентности (Concurrency Models)

Мы разобрали, что такое concurrency и parallelism. Теперь вопрос: КАК организовать concurrent программу? За десятилетия были разработаны несколько фундаментальных моделей, каждая со своими идеями и компромиссами.

### Потоки и общая память (Threads + Shared Memory)

Это самая распространённая и самая старая модель. Несколько потоков работают в одном адресном пространстве и **делят** память. Любой поток может прочитать или записать любую переменную.

**Идея:** Максимальная гибкость. Потоки общаются через общие переменные — быстро и просто. Но общая память — это и проклятие: нужна синхронизация (mutex, semaphore), иначе race conditions и data corruption.

Аналогия: команда строителей на стройке, где все инструменты лежат в одной куче. Каждый может взять что хочет, но если двое одновременно потянутся за молотком — будет конфликт. Нужны правила (синхронизация): "возьми молоток, повесь табличку 'занято', поработай, верни, сними табличку."

**Используется в:** Java/Kotlin threads, C++ std::thread, POSIX pthreads. Это то, что большинство разработчиков используют каждый день.

**Достоинства:** Максимальная производительность (нет overhead на копирование данных), широкая поддержка ОС, прямой контроль.

**Недостатки:** Сложность отладки (heisenbug — баги, которые исчезают при наблюдении), deadlock, livelock, race conditions. Herlihy и Shavit в "The Art of Multiprocessor Programming" посвящают три главы тому, что может пойти не так.

### Акторы (Actor Model)

Модель акторов предложена Карлом Хьюиттом в 1973 году и формализована Гулом Агой в 1985. Идея радикально отличается от shared memory: **никакой общей памяти**. Каждый актор — изолированная сущность с собственным состоянием. Общение — только через **сообщения**.

**Идея:** "Не общайся через общую память — передавай данные через сообщения." Каждый актор обрабатывает сообщения по одному, последовательно. Это автоматически исключает race conditions внутри актора — нет shared state, нечего защищать.

Аналогия: вместо строителей в одной куче инструментов — каждый строитель в своей комнате, с собственными инструментами. Когда нужно что-то от другого — пишет записку и кладёт в его почтовый ящик. Каждый читает свой ящик по очереди. Конфликтов нет — но записки идут не мгновенно.

**Используется в:** Erlang/OTP (эталонная реализация), Akka (JVM), Swift actors, Kotlin channels (частично). Erlang — язык, на котором работают телеком-системы Ericsson с uptime 99.9999999% ("девять девяток"). Устойчивость системы — прямое следствие модели акторов.

**Достоинства:** Нет shared state → нет race conditions. Естественная масштабируемость (акторы можно распределить по машинам). Изоляция ошибок: сбой одного актора не роняет остальных.

**Недостатки:** Overhead на передачу сообщений. Сложность отладки потоков сообщений. Неэффективность для задач, где нужен быстрый доступ к общим данным (например, общая кэш-таблица).

### CSP — Communicating Sequential Processes

CSP разработан Тони Хоаром в 1978 году. Похож на акторов, но с ключевым отличием: акцент на **каналах** связи, а не на самих процессах. В модели акторов сообщение адресовано конкретному актору. В CSP сообщение отправляется в **канал**, и любой процесс может из него прочитать.

**Идея:** Независимые процессы общаются через типизированные каналы. Канал — как труба: один конец для записи, другой для чтения. Процесс блокируется, если канал пуст (при чтении) или полон (при записи), обеспечивая синхронизацию без mutex.

Аналогия: конвейерная лента на заводе. Рабочий А кладёт деталь на ленту, рабочий Б забирает с другого конца. Если лента полна — А ждёт. Если пуста — Б ждёт. Никакой "общей кучи" — только лента.

**Используется в:** Go goroutines + channels (основной пример), Kotlin Channels, Clojure core.async. Go — язык, построенный вокруг CSP. Роб Пайк, один из создателей Go, был соавтором CSP-подхода ещё в Plan 9.

**Достоинства:** Простая модель мышления ("отправь в канал / прими из канала"). Естественная синхронизация через каналы. Композиция — сложные системы строятся из простых процессов и каналов.

**Недостатки:** Каналы могут стать bottleneck. Deadlock по-прежнему возможен (процесс A ждёт данных от B, а B от A). Не подходит для задач с интенсивным shared state.

### Корутины (Coroutines)

Корутины — самая молодая из "взрослых" моделей, хотя идея восходит к Мелвину Конвею (1963). Корутина — это функция, которая может **приостановиться** (suspend) и **возобновиться** (resume) без блокировки потока.

**Идея:** Вместо тяжёлых потоков ОС — лёгкие "виртуальные потоки", управляемые runtime'ом. Тысячи корутин работают на нескольких реальных потоках. Переключение между корутинами — в user space, без дорогого kernel context switch.

Аналогия: вместо найма 10 000 поваров (потоков ОС) для 10 000 блюд — один повар с идеальной памятью. Он начинает блюдо, ставит его "на паузу" (suspend), переходит к следующему. Когда таймер звонит — возвращается к первому. В голове у него чёткий план, кто где остановился.

**Используется в:** Kotlin coroutines (structured concurrency), Python asyncio, JavaScript async/await, Go goroutines (гибрид CSP + корутин), Java virtual threads (Project Loom).

**Достоинства:** Лёгкие (килобайты vs мегабайты для потоков). Structured concurrency (в Kotlin) — жизненный цикл корутин привязан к scope, предотвращая утечки. Естественный для IO-bound задач.

**Недостатки:** CPU-bound задачи всё равно требуют parallelism (корутина на одном ядре не быстрее потока). "Colored functions" — suspend функции нельзя вызывать из обычных, это создаёт "два мира".

### Сравнительная таблица моделей

| Модель | Общение | Синхронизация | Пример языка | Подходит для |
|--------|---------|---------------|--------------|-------------|
| **Threads + Shared Memory** | Общие переменные | Mutex, Semaphore | Java, C++ | CPU-bound, максимальная производительность |
| **Actors** | Сообщения | Очередь сообщений актора | Erlang, Akka | Распределённые системы, отказоустойчивость |
| **CSP** | Каналы | Блокирующие каналы | Go | Серверы, пайплайны обработки |
| **Coroutines** | Зависит от реализации | Structured concurrency | Kotlin, Python | IO-bound, мобильные приложения |

> **Ключевая идея:** Нет "лучшей" модели — есть модель, подходящая задаче. Erlang выбрал акторов для телеком-отказоустойчивости. Go выбрал CSP для серверного программирования. Kotlin выбрал корутины для мобильной разработки. Выбор модели — это design decision, определяющее архитектуру всего проекта.

---

## Kotlin Dispatchers: практическое применение

Мы разобрали теорию. Теперь посмотрим, как concurrency и parallelism реализованы в Kotlin — через систему dispatchers.

### Три основных диспетчера

| Dispatcher | Назначение | Количество потоков |
|------------|------------|-------------------|
| **Default** | CPU-bound задачи | Число ядер |
| **IO** | IO-bound задачи | 64 (или число ядер, если больше) |
| **Main** | UI операции | 1 |

### Как выбрать диспетчер

Выбор диспетчера напрямую зависит от типа задачи — CPU-bound или IO-bound. Следующий пример показывает три типичных сценария и правильный диспетчер для каждого.

```kotlin
// CPU-bound: сортировка, хеширование, парсинг JSON
withContext(Dispatchers.Default) {
    val sorted = hugeList.sorted()       // CPU загружен на 100%
    val hash = calculateSHA256(data)     // Чистые вычисления
    val parsed = Json.decodeFromString<Data>(json) // Парсинг — CPU работа
}

// IO-bound: сеть, файлы, база данных
withContext(Dispatchers.IO) {
    val response = httpClient.get(url)   // Ждём ответ сервера
    val content = file.readText()        // Ждём данные с диска
    val users = database.getUsers()      // Ждём ответ БД
}

// UI: обновление интерфейса (Android/Desktop)
withContext(Dispatchers.Main) {
    textView.text = result               // Только из main thread
    progressBar.visibility = View.GONE   // UI обновления
}
```

Каждый диспетчер оптимизирован для своего сценария: `Default` ограничивает потоки числом ядер (больше — лишний context switch), `IO` создаёт много потоков (всё равно они спят), `Main` — единственный UI-поток.

### limitedParallelism: контроль параллелизма

Иногда нужен тонкий контроль: например, API позволяет не более 10 одновременных запросов. Для этого Kotlin предлагает `limitedParallelism` — "окно" на существующий пул потоков.

```kotlin
// Ограничить IO до 4 параллельных операций
val limitedIO = Dispatchers.IO.limitedParallelism(4)

// Последовательное выполнение (1 операция за раз)
val sequential = Dispatchers.IO.limitedParallelism(1)

// Пример: ограничение запросов к API — не более 10 одновременных
val apiDispatcher = Dispatchers.IO.limitedParallelism(10)

suspend fun fetchData(): List<Result> {
    return urls.map { url ->
        async(apiDispatcher) { api.fetch(url) }  // Макс. 10 одновременно
    }.awaitAll()
}
```

`limitedParallelism` не создаёт новые потоки — это view с ограничением на существующий пул. Это элегантный способ контролировать степень параллелизма без ручного управления потоками.

---

## Практические примеры

### Web-сервер

```
┌─────────────────────────────────────────────────────────────┐
│                      WEB SERVER                             │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│   CONCURRENCY:                                              │
│   Обрабатывает тысячи соединений "одновременно"            │
│   Event loop не блокируется на каждом запросе              │
│                                                             │
│   PARALLELISM:                                              │
│   Worker threads обрабатывают запросы на разных ядрах      │
│   Тяжёлые операции распределяются                          │
│                                                             │
│   Client 1 ─┐                    ┌─> Core 1                │
│   Client 2 ─┼─> Event Loop ─────>├─> Core 2                │
│   Client 3 ─┤   (concurrent)     ├─> Core 3                │
│   Client N ─┘                    └─> Core 4                │
│                                      (parallel)            │
└─────────────────────────────────────────────────────────────┘
```

### Видео-рендеринг

```
┌─────────────────────────────────────────────────────────────┐
│                    VIDEO RENDERING                          │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│   Parallelism доминирует:                                   │
│                                                             │
│   Frame 1-100:   Core 1 ████████████                       │
│   Frame 101-200: Core 2 ████████████                       │
│   Frame 201-300: Core 3 ████████████                       │
│   Frame 301-400: Core 4 ████████████                       │
│                                                             │
│   Каждое ядро рендерит свой кусок                          │
│   Минимум concurrency — чистый parallelism                 │
└─────────────────────────────────────────────────────────────┘
```

### Чат-приложение

```
┌─────────────────────────────────────────────────────────────┐
│                    CHAT APPLICATION                         │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│   Concurrency доминирует:                                   │
│                                                             │
│   Single Core: ─ws1─ws2─ws1─ws3─ws2─ws1─ws4─                │
│                                                             │
│   Тысячи WebSocket соединений                              │
│   IO-bound: ждём сообщений                                 │
│   Одно ядро справляется                                    │
│                                                             │
│   Parallelism не даст ускорения                            │
│   (нечего вычислять параллельно)                           │
└─────────────────────────────────────────────────────────────┘
```

---

## Распространённые заблуждения

### Миф 1: "Больше потоков = быстрее"

**Реальность:** Для CPU-bound оптимально потоков ≈ ядер. Больше — только overhead. Herlihy и Shavit подробно показывают, что сверхпоточность (thread oversubscription) ведёт к деградации: каждое переключение контекста — это 1000-10000 тактов процессора, плюс инвалидация кэша.

### Миф 2: "Concurrent = параллельный"

**Реальность:** Concurrent код может выполняться последовательно на одном ядре. Node.js — concurrent, но не parallel (на single thread). Go runtime — concurrent и parallel одновременно.

### Миф 3: "Async/await делает код параллельным"

**Реальность:** Async делает код concurrent. Parallelism зависит от dispatcher и hardware. `async { ... }` в Kotlin создаёт корутину, но запущена ли она параллельно — зависит от того, на каком dispatcher'е и сколько ядер доступно.

### Миф 4: "Concurrency всегда ускоряет программу"

**Реальность:** Concurrency может даже замедлить программу. Overhead на создание потоков, context switching и синхронизацию иногда превышает выигрыш. Для сортировки 100 элементов sequential код будет быстрее concurrent — просто из-за стоимости инфраструктуры.

---

## Подводные камни

### Когда НЕ нужен parallelism

**IO-bound операции:** Добавление ядер не ускорит ожидание сети. 4 ядра ждут ответа от сервера так же долго, как одно.

**Малый объём данных:** Overhead на создание потоков и синхронизацию может превысить выигрыш. Сортировка 100 элементов быстрее на одном ядре.

**Sequential dependencies:** Если задача B зависит от результата A, параллелить нечего.

### Когда НЕ нужна concurrency

**Простые скрипты:** Если задача одна и линейная, concurrency добавит сложности без пользы.

**Tight loops:** CPU-bound код без IO не выиграет от concurrent структуры на одном ядре.

### Распространённые ошибки в Kotlin

| Ошибка | Последствие | Решение |
|--------|-------------|---------|
| Dispatchers.IO для CPU-bound | 64+ потоков борются за ядра, context switching overhead | Использовать Dispatchers.Default |
| Dispatchers.Default для IO | Заблокированы все ядра, UI зависает | Использовать Dispatchers.IO |
| Parallelism для малых задач | Overhead > выигрыш | Измерить, использовать threshold |
| Игнорирование Amdahl's Law | Ожидание линейного ускорения | Оптимизировать sequential часть |

---

## Связь с другими темами

**[[processes-threads-fundamentals]]** — процессы и потоки являются базовыми единицами выполнения, на которых строятся все модели concurrency. Без понимания того, как устроен поток (собственный стек, разделяемая куча) и процесс (изолированная память), невозможно осознанно выбирать между моделями. Читай перед текущей статьёй.

**[[synchronization-primitives]]** — если concurrency — это структура, то синхронизация — это клей, удерживающий структуру от разрушения. Mutex, semaphore и другие примитивы решают проблемы, неизбежно возникающие при concurrent доступе к shared state. Читай после текущей статьи.

**[[async-models-overview]]** — практическая реализация concurrency моделей в коде: callbacks, promises, async/await, reactive streams. Связывает теорию из текущей статьи с конкретными паттернами программирования.

---

## Источники и дальнейшее чтение

- **Herlihy, M. & Shavit, N. (2012). The Art of Multiprocessor Programming.** — Фундаментальный учебник: от теории невозможности до lock-free структур данных. Главы 1-3 дают глубокое понимание разницы между concurrency и parallelism.

- **Ben-Ari, M. (2006). Principles of Concurrent and Distributed Programming.** — Академический подход к concurrent programming. Формальные модели, доказательства корректности. Даёт математическую строгость, которой не хватает практическим книгам.

- **Pike, R. (2012). Concurrency is not Parallelism (talk).** — Каноническое объяснение разницы от создателя Go. 30-минутный доклад, который расставляет точки над i.

- **Hoare, C.A.R. (1978). Communicating Sequential Processes.** — Оригинальная статья, заложившая основы CSP. Формальна, но поворотный момент в истории concurrency.

- **Amdahl, G. (1967). Validity of the single processor approach to achieving large-scale computing capabilities.** — Оригинальная статья с формулировкой Amdahl's Law. Короткая (1.5 страницы), но определившая мышление о параллелизме на десятилетия.

- **Gustafson, J. (1988). Reevaluating Amdahl's Law.** — Контраргумент к Amdahl: при масштабировании данных доля sequential кода уменьшается. Важный баланс к пессимизму Amdahl's Law.

---

*Проверено: 2026-02-10*
