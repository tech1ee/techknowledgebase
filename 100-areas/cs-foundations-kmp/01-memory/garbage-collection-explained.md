---
title: "Garbage Collection: как компьютер убирает за тобой"
created: 2026-01-04
modified: 2026-01-04
type: deep-dive
status: published
tags:
  - topic/cs-foundations
  - type/deep-dive
  - level/intermediate
related:
  - "[[memory-model-fundamentals]]"
  - "[[reference-counting-arc]]"
---

# Garbage Collection: как компьютер убирает за тобой

> **TL;DR:** Garbage Collection — автоматическое освобождение неиспользуемой памяти. Изобретён в 1959 году для Lisp. Два базовых подхода: tracing (находим живое) и reference counting (считаем ссылки). Современные сборщики используют поколения (молодые объекты умирают быстро) и работают параллельно с программой. JVM предлагает 7 коллекторов для разных задач. Kotlin/Native использует mark-and-sweep без поколений.

---

## Prerequisites

| Тема | Зачем нужно | Где изучить |
|------|-------------|-------------|
| **Stack vs Heap** | GC работает с heap-памятью | [[memory-model-fundamentals]] |

---

## Терминология

| Термин | Что это | Аналогия |
|--------|---------|----------|
| **Garbage** | Объекты, к которым нет доступа | Грязные тарелки, которые больше никому не нужны |
| **Roots** | Точки входа в граф объектов (стек, глобальные переменные) | Входные двери в здание |
| **Reachable** | Объект, к которому можно добраться от roots | Комната, до которой можно дойти от входа |
| **Mark** | Пометить объект как живой | Наклейка "не выбрасывать" |
| **Sweep** | Удалить непомеченные объекты | Уборка всего без наклеек |
| **Compaction** | Дефрагментация — сдвинуть объекты вместе | Сложить книги на полке без пробелов |
| **STW (Stop-the-World)** | Пауза приложения для GC | Закрыть ресторан на санитарный день |
| **Generational** | Разделение heap на поколения | Отдельная корзина для скоропортящегося |

---

## ПОЧЕМУ существует Garbage Collection

### Проблема: ручное управление памятью

В [[memory-model-fundamentals]] мы разобрали, что heap-память требует явного управления. В языках C/C++ программист сам вызывает `malloc`/`free` или `new`/`delete`. Это создаёт целый класс ошибок:

```
┌─────────────────────────────────────────────────────────────────┐
│              ОШИБКИ РУЧНОГО УПРАВЛЕНИЯ ПАМЯТЬЮ                 │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│   Memory Leak          Забыл вызвать free()                    │
│   ──────────────       → память никогда не освободится         │
│                        → приложение "течёт"                    │
│                                                                 │
│   Use-After-Free       Используешь объект после free()         │
│   ──────────────       → undefined behavior                    │
│                        → crash или security vulnerability      │
│                                                                 │
│   Double-Free          Вызвал free() дважды для одного адреса  │
│   ──────────────       → corrupted heap                        │
│                        → crash                                 │
│                                                                 │
│   Dangling Pointer     Указатель на освобождённую память       │
│   ──────────────       → те же проблемы что use-after-free     │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

Эти ошибки коварны: программа может работать годами, пока не произойдёт "правильная" комбинация событий. Отладка занимает дни и недели.

### История: John McCarthy и Lisp (1959-1960)

В конце 1950-х John McCarthy в MIT работал над языком Lisp для искусственного интеллекта. Lisp манипулировал связанными списками, которые постоянно создавались и уничтожались. Ручное управление памятью было бы кошмаром.

McCarthy придумал элегантное решение: пусть компьютер сам определяет, какая память больше не используется. Он описал алгоритм mark-and-sweep всего в трёх абзацах своей статьи 1960 года. Термин "garbage collection" впервые появился именно там.

Интересно, что McCarthy сначала отложил реализацию GC, потому что тестировал только маленькие примеры. Когда память стала заканчиваться на реальных программах, команда быстро реализовала сборщик.

В том же 1960 году George E. Collins предложил альтернативный подход — reference counting. Вместо периодического обхода графа объектов, каждый объект хранит счётчик ссылок на себя. Когда счётчик обнуляется, объект сразу удаляется.

### Что на самом деле делает GC

Есть популярное заблуждение: "GC — это когда операционная среда автоматически освобождает неиспользуемую память". Raymond Chen из Microsoft объясняет, почему это неправильно:

> Это как сказать, что работа пожарного — "ездить на красной машине и поливать водой".

GC не столько освобождает память, сколько **симулирует компьютер с бесконечной памятью**. С точки зрения программиста, ты просто создаёшь объекты, и они существуют пока нужны. Не надо думать об освобождении — память как будто бесконечная.

---

## ЧТО такое Garbage Collection

### Главный вопрос: что считать мусором?

GC не может читать мысли программиста. Он использует консервативное приближение: **память считается нужной, если к ней можно добраться по ссылкам от известных "корней"**.

```
┌─────────────────────────────────────────────────────────────────┐
│                    ГРАФ ОБЪЕКТОВ В ПАМЯТИ                       │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│   ROOTS (корни)                                                 │
│   ├── Stack: локальные переменные                              │
│   ├── Globals: глобальные переменные                           │
│   └── CPU registers: текущие значения                          │
│                                                                 │
│         │                                                       │
│         ▼                                                       │
│   ┌─────────┐     ┌─────────┐     ┌─────────┐                  │
│   │ Object  │────▶│ Object  │────▶│ Object  │  ← REACHABLE     │
│   │    A    │     │    B    │     │    C    │                  │
│   └─────────┘     └─────────┘     └─────────┘                  │
│                                                                 │
│                                                                 │
│   ┌─────────┐     ┌─────────┐                                  │
│   │ Object  │────▶│ Object  │  ← UNREACHABLE (garbage)         │
│   │    D    │◀────│    E    │                                  │
│   └─────────┘     └─────────┘                                  │
│        ▲               │                                        │
│        └───────────────┘  (цикл!)                              │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

Объекты A, B, C достижимы от корней — они живые. Объекты D и E ссылаются друг на друга, но от корней к ним не добраться — это мусор.

### Два фундаментальных подхода

Исследователи из Cornell доказали интересный факт: tracing и reference counting — это дуалы друг друга, как материя и антиматерия. Tracing находит живые объекты и удаляет остальное. Reference counting находит мёртвые объекты (с нулевым счётчиком) и удаляет их.

Все реальные сборщики — гибриды этих двух подходов.

---

## Алгоритм Mark-and-Sweep

Классический tracing GC работает в две фазы:

### Фаза 1: Mark (разметка)

Начинаем с корней и обходим граф объектов в глубину (DFS). Каждый посещённый объект помечаем битом "живой".

```
Алгоритм MARK:
1. Собрать все корни (стек, глобальные)
2. Для каждого корня:
   a. Если объект не помечен → пометить
   b. Рекурсивно обойти все ссылки из объекта
3. После обхода: все достижимые объекты помечены
```

### Фаза 2: Sweep (уборка)

Проходим по всей памяти heap. Непомеченные объекты — мусор, освобождаем их память.

```
Алгоритм SWEEP:
1. Пройти по списку всех объектов в heap
2. Для каждого объекта:
   a. Если НЕ помечен → освободить память
   b. Если помечен → сбросить метку (для следующего цикла)
3. После sweep: остались только живые объекты
```

### Преимущества Mark-and-Sweep

- **Обрабатывает циклы.** В примере выше D↔E образуют цикл, но они недостижимы от корней — будут удалены.
- **Нет overhead при работе программы.** Во время обычной работы никаких лишних операций — только при запуске GC.

### Недостатки

- **Stop-the-World.** Классический mark-and-sweep останавливает всё приложение на время сборки. Если heap большой — пауза может быть секунды.
- **Фрагментация.** После удаления объектов в памяти остаются "дырки". Со временем невозможно выделить большой непрерывный блок, хотя суммарно памяти достаточно.

---

## Алгоритм Copying (Semi-space)

Cheney в 1970 году предложил другой подход. Делим heap пополам:

```
┌─────────────────────────────────────────────────────────────────┐
│                     COPYING COLLECTION                          │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│   ДО СБОРКИ:                                                   │
│   ┌────────────────────────┬────────────────────────┐          │
│   │    FROM-SPACE          │     TO-SPACE           │          │
│   │  [A][.][B][.][C][.]    │     (пусто)            │          │
│   └────────────────────────┴────────────────────────┘          │
│                                                                 │
│   ПОСЛЕ СБОРКИ:                                                │
│   ┌────────────────────────┬────────────────────────┐          │
│   │    FROM-SPACE          │     TO-SPACE           │          │
│   │  (теперь пусто)        │  [A][B][C]             │          │
│   └────────────────────────┴────────────────────────┘          │
│                                                                 │
│   Мусор остался в FROM-SPACE, живое скопировано в TO-SPACE     │
│   Потом пространства меняются ролями                           │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

### Как это работает

1. Аллоцируем только в FROM-space
2. Когда FROM-space заполнен, начинаем сборку
3. Копируем живые объекты в TO-space (компактно, без дырок)
4. Меняем FROM и TO местами
5. Старое FROM-space теперь полностью свободно

### Преимущества

- **Нет фрагментации.** Объекты копируются компактно.
- **Быстрое выделение.** Просто двигаем указатель (bump pointer allocation).
- **Время пропорционально живым объектам.** Если живого мало — сборка быстрая. Mark-and-sweep тратит время пропорционально всему heap.

### Недостатки

- **Требует вдвое больше памяти.** Половина heap всегда пустует.
- **Много копирования.** Долгоживущие объекты копируются снова и снова.

---

## Generational GC: главная оптимизация

В 1980-х исследователи заметили закономерность: **большинство объектов умирает молодыми**. Это называется "weak generational hypothesis" или правило 80-20.

```
┌─────────────────────────────────────────────────────────────────┐
│              WEAK GENERATIONAL HYPOTHESIS                       │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│   Время жизни объектов:                                        │
│                                                                 │
│   ▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓                             │
│   ▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓                   │                         │
│   ▓▓▓▓▓▓▓▓                           │                         │
│   ▓▓▓▓                               ▼                         │
│   ▓▓                                                           │
│   ▓                              Единицы % объектов            │
│   ──────────────────────────────────────────────────▶          │
│   Очень      Коротко    Средне     Долго      Очень            │
│   коротко                                     долго            │
│                                                                 │
│   ~80% объектов живут очень недолго (temporary strings,        │
│   промежуточные коллекции, краткие вычисления)                 │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

### Идея: разделить heap на поколения

Если 80% объектов умирает быстро, зачем каждый раз сканировать весь heap? Создадим отдельную область для молодых объектов и будем чистить её часто, а старую — редко.

```
┌─────────────────────────────────────────────────────────────────┐
│                  СТРУКТУРА GENERATIONAL HEAP                    │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│   YOUNG GENERATION (1/3 heap)        OLD GENERATION (2/3 heap) │
│   ┌──────────────────────────────┐  ┌────────────────────────┐ │
│   │ Eden │ S0 │ S1 │             │  │                        │ │
│   │      │    │    │             │  │   Долгоживущие         │ │
│   │ Все  │Sur-│Sur-│             │  │   объекты              │ │
│   │ new  │vi- │vi- │             │  │                        │ │
│   │ тут  │vor │vor │             │  │                        │ │
│   └──────────────────────────────┘  └────────────────────────┘ │
│                                                                 │
│   Minor GC: часто, быстро           Major GC: редко, долго    │
│   (только Young Gen)                (весь heap)               │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

### Как работает

1. **Новые объекты** создаются в Eden
2. **Minor GC** запускается когда Eden заполнен
3. Живые объекты из Eden копируются в Survivor (S0 или S1)
4. Объекты, пережившие N сборок, "продвигаются" (promote) в Old Generation
5. **Major GC** запускается когда Old Generation заполнен

### Почему это эффективно

Сканируем 1/3 памяти → собираем ~80% мусора. В 2.4 раза эффективнее!

Young Gen использует copying collection (быстрое, без фрагментации). Old Gen — mark-sweep-compact (медленнее, но запускается редко).

---

## Tricolor Abstraction: модель для понимания concurrent GC

Когда GC работает параллельно с программой, сложно понять, что происходит. Для этого придумали модель "трёх цветов":

```
┌─────────────────────────────────────────────────────────────────┐
│                     TRICOLOR ABSTRACTION                        │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│   ⬜ WHITE    Ещё не посещён                                   │
│              (изначально все объекты белые)                    │
│                                                                 │
│   🔳 GRAY     Достижим, но ссылки не просканированы            │
│              (в очереди на обработку)                          │
│                                                                 │
│   ⬛ BLACK    Достижим, все ссылки просканированы              │
│              (полностью обработан)                             │
│                                                                 │
│   ─────────────────────────────────────────────────            │
│                                                                 │
│   Процесс:                                                     │
│                                                                 │
│   ⬜⬜⬜⬜⬜   →   ⬜⬜🔳⬜⬜   →   ⬜🔳⬛🔳⬜   →   ⬜⬛⬛⬛⬜   │
│   (старт)       (корни серые)   (волна идёт)    (финиш)       │
│                                                                 │
│   Белые в конце = мусор                                        │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

"Серая волна" продвигается через граф. Всё, что осталось белым в конце — мусор. Эта модель помогает доказать корректность concurrent алгоритмов.

---

## Concurrent GC и барьеры

Главная проблема concurrent GC: пока коллектор сканирует объекты, программа их меняет. Объект может стать недостижимым или, наоборот, достижимым между фазами mark и sweep.

### Решение: барьеры (barriers)

Барьер — это маленький кусок кода, который JVM вставляет при каждой записи или чтении указателя.

**Write barrier** перехватывает запись ссылки:
```kotlin
// Программист пишет:
obj.field = newValue

// JVM выполняет:
writeBarrier(obj, oldValue, newValue)  // ← барьер
obj.field = newValue
```

**Read barrier** перехватывает чтение:
```kotlin
// Программист пишет:
val x = obj.field

// JVM выполняет:
val x = readBarrier(obj.field)  // ← барьер
```

Write barriers дешевле (записей меньше чем чтений), поэтому большинство GC используют их. Read barriers используют ZGC и Shenandoah — они сложнее, но позволяют перемещать объекты во время работы программы.

---

## КАК это работает на практике: JVM

JVM предлагает 7 сборщиков мусора. Каждый — trade-off между throughput (сколько работы делает приложение) и latency (длина пауз).

### Обзор JVM коллекторов

| Collector | Тип | Паузы | Когда использовать |
|-----------|-----|-------|-------------------|
| **Serial** | STW, 1 поток | Долгие | Маленькие heaps, embedded |
| **Parallel** | STW, N потоков | Средние | Batch jobs, throughput |
| **G1** | Generational, mostly concurrent | 50-200ms | Default с JDK 9 |
| **ZGC** | Concurrent, colored pointers | <10ms | Ultra-low latency |
| **Shenandoah** | Concurrent, forwarding | <10ms | Red Hat, low latency |
| **Epsilon** | Нет сборки | Нет | Тестирование, короткие программы |

### G1 GC: баланс

G1 (Garbage-First) — default collector с Java 9. Он делит heap на много маленьких регионов (не на два поколения). Регионы могут быть Eden, Survivor или Old. G1 собирает сначала регионы с наибольшим количеством мусора ("garbage first").

```
┌─────────────────────────────────────────────────────────────────┐
│                    G1 HEAP STRUCTURE                            │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│   ┌───┬───┬───┬───┬───┬───┬───┬───┬───┬───┬───┬───┐           │
│   │ E │ E │ S │ O │ O │ E │ O │ O │ S │ E │ O │ H │           │
│   └───┴───┴───┴───┴───┴───┴───┴───┴───┴───┴───┴───┘           │
│                                                                 │
│   E = Eden    S = Survivor    O = Old    H = Humongous         │
│                                                                 │
│   Регионы НЕ обязаны быть рядом!                               │
│   G1 сначала собирает регионы с максимумом мусора              │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

### ZGC: ultra-low latency

ZGC использует colored pointers — специальные биты в указателях для отслеживания состояния объектов. Это позволяет делать почти всю работу concurrent, с паузами <10ms даже на heap в терабайты.

С JDK 21 ZGC стал generational — получил преимущества обоих подходов.

### Выбор collector

```
Нужен максимальный throughput?
├── Heap < 2GB → Serial
└── Heap > 2GB → Parallel

Нужен баланс throughput/latency?
└── G1 (default)

Нужны минимальные паузы (<10ms)?
├── Heap до 32GB → ZGC или Shenandoah
└── Heap > 32GB → ZGC
```

---

## Kotlin/Native Memory Manager

Kotlin/Native использует собственный memory manager, отличный от JVM. Это важно для KMP — один и тот же Kotlin-код на JVM работает с JVM GC, а на iOS — с Kotlin/Native GC.

### Архитектура

- **Алгоритм:** stop-the-world mark + concurrent sweep
- **Поколения:** НЕТ (в отличие от JVM)
- **Запуск:** отдельный поток, по memory pressure или таймеру
- **Marking:** параллельный (несколько потоков)

### Особенности

```kotlin
import kotlin.native.internal.GC

// Принудительный запуск GC
GC.collect()

// Получить информацию о последней сборке
@OptIn(ExperimentalStdlibApi::class)
val info = GC.lastGCInfo
println("Memory after GC: ${info?.memoryUsageAfter}")
```

### Experimental: concurrent marking

Можно включить concurrent marking для уменьшения пауз:

```kotlin
// В build.gradle.kts
kotlin {
    targets.withType<org.jetbrains.kotlin.gradle.plugin.mpp.KotlinNativeTarget> {
        binaries.all {
            freeCompilerArgs += "-Xbinary=gc=cms"
        }
    }
}
```

### Взаимодействие с Swift/ARC

На iOS Kotlin объекты могут передаваться в Swift код. Swift использует ARC (reference counting), а Kotlin — tracing GC. Они работают вместе:

1. Kotlin-объект в Swift обёрнут в Swift-обёртку с ARC
2. Пока Swift держит ссылку, Kotlin GC не удалит объект
3. Когда Swift освобождает обёртку, объект становится доступен для Kotlin GC

Подробнее в [[reference-counting-arc]].

---

## Подводные камни

### Мифы о Garbage Collection

**Миф 1: "GC — для ленивых/неопытных разработчиков"**

Реальность: GC даёт архитектурные преимущества. Не тратишь время на отладку use-after-free. Можешь делать сложные структуры данных без страха утечек. Даже эксперты выбирают GC когда он подходит.

**Миф 2: "GC = никаких утечек памяти"**

Реальность: memory leaks возможны! Если ты держишь ссылку на объект, который больше не нужен (забытый listener, растущий кеш), GC не удалит его — объект же достижим.

```kotlin
// Memory leak в Android
class MyActivity : Activity() {
    companion object {
        val cache = mutableListOf<Bitmap>()  // Статический список
    }

    fun loadImage() {
        cache.add(loadHugeBitmap())  // Bitmap никогда не удалится!
    }
}
```

**Миф 3: "Память освобождается сразу"**

Реальность: GC недетерминистичен. После `obj = null` объект может жить ещё долго, пока GC не запустится. Нельзя полагаться на timing.

**Миф 4: "Minor GC не паузит приложение"**

Реальность: Minor GC тоже stop-the-world (в классических реализациях). Паузы короче, но они есть.

**Миф 5: "Reference counting избегает пауз GC"**

Реальность: при удалении большого графа объектов RC может иметь длинные паузы — нужно рекурсивно уменьшить счётчики и удалить всю цепочку.

**Миф 6: "GC катастрофически влияет на производительность"**

Реальность: современные GC часто быстрее ручного управления. Bump pointer allocation дешевле malloc. Compaction улучшает cache locality.

### Когда GC НЕ подходит

- **Hard real-time системы** (контроль ракеты, медицинское оборудование) — непредсказуемые паузы недопустимы
- **Очень ограниченная память** — GC требует overhead (6x память для оптимальной производительности по исследованиям)
- **Системное программирование** — ядро ОС, драйверы не могут паузить

### Типичные проблемы

| Проблема | Симптом | Решение |
|----------|---------|---------|
| Частые Full GC | Высокий CPU, паузы | Увеличить heap, проверить leaks |
| Долгие паузы | Latency spikes | ZGC/Shenandoah, уменьшить Young Gen |
| Excessive allocation | GC не успевает | Оптимизировать код, object pooling |
| Memory leak | Heap растёт без конца | Профилировать, найти retained references |

---

## Куда дальше

**Если здесь впервые:**
→ [[memory-model-fundamentals]] — сначала разберись со Stack/Heap

**Следующий уровень:**
→ [[reference-counting-arc]] — альтернативный подход (используется в Swift/iOS)

**Практическое применение:**
→ [[kmp-memory-management]] — как это работает в Kotlin Multiplatform

---

## Источники

- [Crafting Interpreters: Garbage Collection](https://craftinginterpreters.com/garbage-collection.html) — лучшее объяснение с аналогиями
- [Datadog: Java GC Deep Dive](https://www.datadoghq.com/blog/understanding-java-gc/) — сравнение JVM коллекторов
- [Kotlin/Native Memory Manager](https://kotlinlang.org/docs/native-memory-manager.html) — официальная документация
- [Holly Cummins: Six Myths of GC](https://hollycummins.com/six-myths-and-paradoxes-of-garbage/) — развенчание мифов
- [Cornell CS6120: Unified Theory of GC](https://www.cs.cornell.edu/courses/cs6120/2019fa/blog/unified-theory-gc/) — tracing vs RC как дуалы
- [GCEasy Blog](https://blog.gceasy.io/) — практические советы по tuning

---

*Проверено: 2026-01-09*
