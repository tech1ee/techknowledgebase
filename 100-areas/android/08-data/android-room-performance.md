---
title: "Производительность Room: индексы, WAL, оптимизация запросов"
created: 2026-02-11
modified: 2026-02-11
type: deep-dive
area: android
status: published
confidence: high
cs-foundations: [indexing, b-tree, query-optimization, write-ahead-logging, database-performance]
tags:
  - topic/android
  - topic/data
  - topic/performance
  - type/deep-dive
  - level/intermediate
related:
  - "[[android-room-deep-dive]]"
  - "[[android-room-migrations]]"
  - "[[android-data-persistence]]"
  - "[[android-performance-profiling]]"
  - "[[database-design-optimization]]"
prerequisites:
  - "[[android-room-deep-dive]]"
  - "[[android-data-persistence]]"
---

# Производительность Room: индексы, WAL, оптимизация запросов

Производительность Room — это, по существу, производительность SQLite. Room не добавляет значимого runtime overhead: это compile-time обёртка, которая генерирует тот же код, что разработчик написал бы вручную. Все проблемы с быстродействием коренятся в SQL-запросах, отсутствии индексов, неправильном использовании транзакций и непонимании того, как SQLite хранит и читает данные на диске. Эта глава разбирает механику, стоящую за каждой из этих проблем.

---

## Зачем это знать

Представьте три ситуации из реальных проектов. Первая: приложение-каталог с 10 000 товаров. При открытии экрана списка пользователь видит белый экран 3 секунды — Room выполняет `SELECT *` без индекса, и SQLite просматривает каждую строку. Вторая: чат-приложение, где INSERT 500 сообщений после синхронизации с сервером подвешивает UI-поток на 5 секунд, потому что каждая вставка оборачивается в отдельную транзакцию. Третья: поиск по истории переписки занимает 2 секунды, потому что SQLite выполняет full table scan по текстовому полю без индекса.

Все три проблемы решаются пониманием нескольких фундаментальных концепций: как SQLite хранит данные на диске, как работают индексы, зачем нужны транзакции и что показывает EXPLAIN QUERY PLAN. Без этого понимания разработчик работает вслепую — добавляет индексы наугад, не понимает почему запрос медленный, и не знает как измерить улучшение.

---

## Терминология

| Термин | Значение | Аналогия из жизни |
|--------|----------|-------------------|
| **Index** | Структура данных для быстрого поиска по колонке | Алфавитный указатель в конце книги — не нужно листать все 500 страниц |
| **B-tree** | Сбалансированное дерево — структура данных индексов SQLite | Дерево решений: на каждом уровне выбираешь направление |
| **WAL** | Write-Ahead Logging — стратегия записи: сначала в лог, потом в файл | Черновик заметок: пишешь быстро в черновик, потом переносишь в чистовик |
| **EXPLAIN QUERY PLAN** | Команда, показывающая как SQLite будет выполнять запрос | Рентгеновский снимок запроса — видишь внутреннюю структуру |
| **Full table scan** | Просмотр КАЖДОЙ строки таблицы для поиска результата | Поиск книги в библиотеке без каталога — идёшь вдоль каждой полки |
| **CursorWindow** | Буфер в памяти (2 MB), через который SQLite отдаёт данные приложению | Поднос в столовой — сколько тарелок влезет на поднос, столько и унесёшь за раз |
| **Page size** | Размер блока данных на диске (4 KB по умолчанию) | Страница в блокноте — минимальная единица чтения |
| **Checkpoint** | Перенос данных из WAL-файла в основной файл базы | Перенос записей из черновика в чистовую тетрадь |
| **Batch operation** | Групповая операция: несколько вставок/обновлений за раз | Отправка 100 писем в одном конверте вместо 100 отдельных |
| **Transaction** | Атомарная группа операций: либо все выполняются, либо ни одна | Банковский перевод: деньги либо переведены целиком, либо нет |

---

## Историческая справка

SQLite создал D. Richard Hipp в 2000 году. Причина была конкретной: Hipp работал над программным обеспечением для эсминцев ВМС США и был разочарован тем, что Informix — промышленная СУБД — требовала администратора и могла не запуститься из-за проблем с конфигурацией сервера. Hipp задался вопросом: почему нельзя иметь базу данных, которая работает без сервера, без настройки, хранится в одном файле и просто работает?

Так родился SQLite — "lite" означает лёгкость. Первый релиз поддерживал только gdbm как бэкенд хранения. В 2001 году Hipp переписал движок на собственный формат B-tree, что дало SQLite полноценную реляционную функциональность. К 2004 году SQLite стал стандартной базой данных в Symbian OS, а затем — в Android (2008) и iOS.

Критический момент для производительности наступил в 2010 году: SQLite 3.7.0 добавил WAL mode (Write-Ahead Logging). До этого SQLite использовал rollback journal — стратегию, при которой запись блокировала всех читателей. WAL перевернул эту модель: читатели больше не блокируются при записи. Для мобильных приложений, где UI-поток постоянно читает данные для отображения, а фоновый поток пишет данные после синхронизации с сервером, это было революцией.

Android Room, появившийся в 2017 году как часть Architecture Components, включает WAL mode по умолчанию начиная с Room 2.x. До Room разработчики работали с SQLiteOpenHelper напрямую — это требовало написания SQL-строк без compile-time проверок, ручного управления курсорами и миграциями. Room абстрагировал эту сложность, но фундамент остался прежним: под капотом работает тот же SQLite.

> **Ключевой факт:** SQLite — самая распространённая база данных в мире. Она работает на каждом Android-устройстве, iPhone, каждом браузере, в каждом Mac и Windows-компьютере. По оценке D. Richard Hipp, в мире работает более триллиона (10^12) баз данных SQLite.

---

## Prerequisites

| Материал | Зачем нужен |
|----------|-------------|
| [[android-room-deep-dive]] | Понимание архитектуры Room: Entity, DAO, Database, TypeConverter |
| [[android-data-persistence]] | Общая картина хранения данных на Android: Room, DataStore, Files |
| Базовый SQL | SELECT, INSERT, UPDATE, DELETE, WHERE, JOIN — без этого запросы непонятны |

---

## SQLite на Android: как устроено хранилище

Прежде чем оптимизировать, нужно понять как SQLite физически хранит данные. Это не абстрактный вопрос — от физической организации зависит, почему одни запросы быстрые, а другие медленные.

### Embedded database: файл, а не сервер

SQLite — это embedded database. В отличие от PostgreSQL или MySQL, здесь нет отдельного серверного процесса, нет сетевого соединения, нет протокола обмена данными. Вся база данных — один файл на диске. Когда Room выполняет запрос, библиотека SQLite (написанная на C, скомпилированная в нативный код) читает и пишет этот файл напрямую через системные вызовы операционной системы.

Аналогия: если PostgreSQL — это библиотека с библиотекарем (ты просишь книгу, библиотекарь ищет и приносит), то SQLite — это твой личный блокнот. Ты сам открываешь нужную страницу, сам пишешь, сам ищешь. Нет посредника — нет сетевых задержек, но и нет оптимизатора, который распараллелит работу.

### Page-based storage: блокнот с фиксированными страницами

SQLite хранит данные в **страницах** (pages) фиксированного размера — по умолчанию 4096 байт (4 KB). Каждая страница — минимальная единица чтения и записи. Даже если тебе нужна одна строка таблицы длиной 50 байт, SQLite прочитает с диска всю страницу в 4 KB.

Это похоже на тетрадь с фиксированными страницами: даже если тебе нужно только одно слово со страницы 47, ты переворачиваешь на эту страницу целиком. Ты не можешь прочитать полстраницы — это физическое ограничение.

Почему это важно для производительности? Потому что чтение с диска (даже с flash-памяти телефона) — медленная операция. Каждое обращение к диску стоит времени. Если запрос требует прочитать 100 страниц — это 100 операций ввода/вывода. Если правильный индекс позволяет найти нужную строку за 3 страницы — это 33-кратное ускорение.

```
┌──────────────────────────────────────────────────┐
│              Файл базы данных SQLite              │
├──────────┬──────────┬──────────┬──────────┬──────┤
│ Page 1   │ Page 2   │ Page 3   │ Page 4   │ ...  │
│ (Header) │ (Data)   │ (Data)   │ (Index)  │      │
│ 4 KB     │ 4 KB     │ 4 KB     │ 4 KB     │      │
├──────────┴──────────┴──────────┴──────────┴──────┤
│ Каждая страница = минимальная единица I/O         │
│ Строки таблицы хранятся в data pages              │
│ Индексы хранятся в отдельных index pages          │
└──────────────────────────────────────────────────┘
```

Строки таблицы хранятся в data pages. Когда ты вставляешь строку, SQLite находит страницу с достаточным свободным местом и записывает туда. Индексы хранятся в отдельных страницах — это дополнительные структуры, которые занимают место, но ускоряют поиск.

Мы разобрали как данные лежат на диске. Но как SQLite обеспечивает надёжность записи? Что происходит, если приложение крашится посреди INSERT? Ответ — в стратегии журналирования.

---

## WAL mode: почему записи не блокируют чтение

### Проблема: запись блокирует всех

Представь ситуацию: фоновый поток синхронизирует 200 сообщений с сервером (INSERT), а UI-поток одновременно отображает список сообщений (SELECT). Без WAL mode эти операции конфликтуют: SQLite использует rollback journal, который требует эксклюзивной блокировки файла при записи. Пока пишется хотя бы одна строка — никто не может читать. UI замирает.

### Как работает WAL

WAL (Write-Ahead Logging) переворачивает стратегию записи. Вместо того чтобы менять основной файл базы данных напрямую, SQLite записывает изменения в отдельный WAL-файл. Основной файл остаётся нетронутым, и читатели продолжают работать с ним без блокировки.

Аналогия: представь бухгалтера, который ведёт главную книгу учёта. Без WAL — это один бухгалтер с одной книгой: пока он записывает новую операцию, никто не может заглянуть в книгу. С WAL — бухгалтер пишет новые операции на отдельных листочках (WAL-файл). Главная книга лежит открытой — любой может её читать. Периодически бухгалтер переносит записи с листочков в главную книгу (checkpoint) — но это происходит в фоне.

Процесс по шагам:

1. **Запись (INSERT/UPDATE/DELETE):** изменённые страницы записываются в WAL-файл в конец. Это быстро — последовательная запись, без необходимости искать место в основном файле.

2. **Чтение (SELECT):** SQLite сначала проверяет WAL-файл — есть ли там более свежая версия нужной страницы. Если есть — берёт оттуда. Если нет — читает из основного файла. Для этого SQLite поддерживает индекс WAL-файла (wal-index) в shared memory.

3. **Checkpoint:** когда WAL-файл накапливает достаточно изменений (по умолчанию — 1000 страниц, то есть ~4 MB), SQLite переносит эти изменения в основной файл. Это и есть checkpoint — "перенос черновика в чистовик".

```
┌─────────────┐     ┌─────────────────┐
│ Writer       │────▶│ WAL-файл (.wal) │
│ (INSERT/     │     │ [Page 5']       │
│  UPDATE)     │     │ [Page 12']      │
└─────────────┘     │ [Page 5'']      │
                    └────────┬────────┘
                             │ checkpoint
                             ▼
┌─────────────┐     ┌─────────────────┐
│ Reader       │────▶│ Основной файл   │
│ (SELECT)     │     │ (.db)           │
│ UI-поток     │     │ [Page 1..N]     │
└─────────────┘     └─────────────────┘

Читатель сначала проверяет WAL — если там
свежая версия страницы, берёт оттуда.
Иначе читает из основного файла.
```

### Почему WAL быстрее

Три причины, каждая из которых заслуживает отдельного объяснения.

Во-первых, **параллелизм**: читатели и писатели не блокируют друг друга. UI-поток может отображать данные пока фоновый поток пишет — это критично для мобильных приложений. В rollback journal режиме писатель блокирует весь файл, и любой SELECT должен ждать завершения записи. В WAL режиме SELECT работает с "замороженным снимком" базы (snapshot), а запись идёт параллельно в WAL-файл. Это принципиально меняет user experience: вместо заметных "подвисаний" при синхронизации — плавная работа.

Во-вторых, **последовательная запись**: WAL пишет в конец файла (append-only), что быстрее чем random write в основной файл. Flash-память телефонов особенно хорошо работает с последовательной записью. Причина в физике: flash-память организована в блоки (erase blocks), и случайная запись требует стирания и перезаписи целого блока. Последовательная запись минимизирует эти операции.

В-третьих, **меньше fsync вызовов**: синхронизация с диском (fsync) — самая дорогая операция ввода-вывода. Один fsync на мобильном устройстве стоит 1-5 миллисекунд. WAL группирует несколько изменений и синхронизирует их за один fsync при checkpoint, вместо того чтобы вызывать fsync для каждой транзакции отдельно.

### Trade-offs WAL

Ничего не даётся бесплатно. WAL создаёт дополнительные файлы: помимо основного `database.db` появляются `database.db-wal` (WAL-файл) и `database.db-shm` (shared memory для wal-index). Это занимает место на диске. WAL-файл может вырасти до десятков мегабайт если checkpoint не успевает или заблокирован долгой читающей транзакцией.

Ещё один trade-off: WAL поддерживает только одного писателя одновременно. Если два потока пытаются писать одновременно, второй будет ждать. Для мобильных приложений это редко проблема — обычно фоновый поток пишет, а UI-поток читает. Но если у тебя несколько корутин одновременно пишут в разные таблицы одной базы — они будут сериализованы.

Room включает WAL автоматически. Если ты создаёшь базу через `Room.databaseBuilder()`, WAL уже активен — ничего дополнительно настраивать не нужно. Это можно проверить через Database Inspector или выполнив `PRAGMA journal_mode;` — результат должен быть `wal`.

> **Подводный камень:** Если длинная читающая транзакция (например, ленивая загрузка через Paging) держит snapshot базы, checkpoint не может завершиться и WAL-файл растёт неограниченно. Решение — не держать транзакции открытыми дольше необходимого.

Мы разобрали как SQLite пишет данные. Теперь перейдём к чтению — как понять, почему конкретный запрос медленный.

---

## EXPLAIN QUERY PLAN: рентген запроса

### Зачем нужен

Разработчик пишет SQL-запрос, Room его компилирует, SQLite выполняет. Но как SQLite решает, КАК именно выполнить запрос? Использовать ли индекс? Какой? В каком порядке соединять таблицы? EXPLAIN QUERY PLAN отвечает на все эти вопросы — он показывает план выполнения запроса ДО его выполнения.

Аналогия: это рентгеновский снимок запроса. Снаружи запрос выглядит нормально — `SELECT * FROM users WHERE name = 'Alice'`. Но рентген показывает: SQLite собирается просмотреть ВСЮ таблицу из 100 000 строк чтобы найти одну Алису. Без рентгена ты бы не узнал об этом до тех пор, пока пользователь не пожалуется на тормоза.

### Как использовать на Android

В Android Studio есть Database Inspector (меню App Inspection → Database Inspector). Подключившись к работающему приложению, можно выполнить запрос прямо в интерфейсе. Чтобы увидеть план — добавь EXPLAIN QUERY PLAN перед запросом.

Ниже — пример того, как выглядит запрос к Database Inspector и что показывает план выполнения. Обрати внимание на ключевое слово в результате: SCAN или SEARCH.

```sql
-- В Database Inspector или через rawQuery:
EXPLAIN QUERY PLAN
SELECT * FROM messages
WHERE chat_id = 42
ORDER BY timestamp DESC
LIMIT 50;
```

Результат покажет одну из следующих картин — и от этого зависит всё.

### Чтение плана: три ключевых паттерна

**SCAN TABLE** — плохо. Это full table scan: SQLite просматривает каждую строку таблицы. Если в таблице 100 000 строк — проверяются все 100 000, даже если результат — 5 строк. Это как искать слово в книге, перечитывая каждую страницу от первой до последней.

**SEARCH TABLE USING INDEX** — хорошо. SQLite использует индекс, чтобы быстро найти нужные строки. Вместо 100 000 проверок — 3-4 обращения к B-tree. Это как найти слово через алфавитный указатель: открыл указатель, нашёл страницу, перешёл.

**USING COVERING INDEX** — лучшее. Покрывающий индекс содержит все колонки, которые нужны запросу. SQLite даже не обращается к основной таблице — вся информация в индексе. Это как если бы алфавитный указатель содержал не только номер страницы, но и краткое содержание абзаца — не нужно даже открывать основную книгу.

```
┌─────────────────────────────────────────────────┐
│             План выполнения запроса              │
├─────────────────────────────────────────────────┤
│                                                 │
│  SCAN TABLE messages        ← Плохо!           │
│  ╰─ Проверяет ВСЕ строки       O(n)            │
│                                                 │
│  SEARCH TABLE messages      ← Хорошо           │
│  USING INDEX idx_chat_id                        │
│  ╰─ Находит через индекс      O(log n)         │
│                                                 │
│  SEARCH TABLE messages      ← Лучше всего      │
│  USING COVERING INDEX idx_chat_timestamp        │
│  ╰─ Ответ целиком из индекса  O(log n), no I/O │
│                                                 │
└─────────────────────────────────────────────────┘
```

### Практический пример

Допустим, EXPLAIN QUERY PLAN показал `SCAN TABLE messages`. Это значит: нет подходящего индекса для `WHERE chat_id = 42`. Добавляем индекс — и план меняется на `SEARCH TABLE USING INDEX`. Запрос, который занимал 800ms на таблице из 50 000 строк, теперь выполняется за 2ms. Разница — 400-кратная.

Другой частый случай: запрос с ORDER BY. `SELECT * FROM messages WHERE chat_id = 42 ORDER BY timestamp DESC` может использовать индекс для фильтрации (WHERE), но если индекса по `timestamp` нет — SQLite будет сортировать все найденные строки в памяти. EXPLAIN покажет `USE TEMP B-TREE FOR ORDER BY` — это сигнал, что сортировка выполняется "на лету", без индекса. Составной индекс `[chat_id, timestamp]` решает обе задачи: и фильтрацию, и сортировку.

Привычка проверять EXPLAIN QUERY PLAN для каждого нетривиального запроса — одна из самых ценных привычек при работе с Room. Особенно для запросов, которые выполняются часто: отображение списков, поиск, фильтрация. Проверяй план на таблицах с реалистичным количеством данных — на пустой таблице SQLite может выбрать другую стратегию, чем на таблице с 50 000 строк.

Мы увидели, что индексы критичны для производительности. Но что такое индекс изнутри? Как он устроен и почему ускоряет поиск?

---

## B-tree индексы: структура, которая делает поиск быстрым

### Проблема без индекса

Без индекса SQLite выполняет full table scan — последовательно читает каждую строку таблицы и проверяет условие WHERE. Для 100 000 строк это 100 000 проверок. Сложность — O(n): линейная зависимость от количества данных. Удвоил данные — удвоил время. На первый взгляд это не кажется критичным — современные процессоры быстрые. Но на мобильном устройстве, где CPU throttled для экономии батареи, а flash-память работает медленнее SSD десктопа, 100 000 проверок превращаются в заметную задержку.

### Что такое B-tree

B-tree (balanced tree, сбалансированное дерево) — это структура данных, которую SQLite использует для хранения индексов. "Сбалансированное" означает, что путь от корня до любого листа одинаковой длины. Это гарантирует, что поиск любого значения занимает одинаковое количество шагов.

Аналогия из жизни: представь почтовую систему сортировки. На первом уровне — контейнеры по странам. Внутри каждого контейнера — коробки по городам. Внутри каждой коробки — конверты по улицам. Чтобы найти нужное письмо, ты не перебираешь все письма — ты идёшь по уровням: страна → город → улица. На каждом уровне отбрасываешь 90%+ вариантов. Три уровня — и ты у цели.

B-tree работает так же. Каждый "уровень" дерева — это набор узлов, которые содержат ключи (значения индексированной колонки) и указатели на дочерние узлы. При поиске значения SQLite начинает с корня, на каждом уровне выбирает нужное направление и спускается вниз.

```
               ┌─────────────┐
               │  [30 | 70]  │          Корень
               └──┬────┬───┬─┘
            ┌─────┘    │   └──────┐
            ▼          ▼          ▼
      ┌──────────┐ ┌──────────┐ ┌──────────┐
      │ [10 | 20]│ │ [40 | 50]│ │ [80 | 90]│   Ветви
      └─┬──┬──┬──┘ └─┬──┬──┬─┘ └─┬──┬──┬──┘
        ▼  ▼  ▼       ▼  ▼  ▼     ▼  ▼  ▼
       [5] [15] [25] [35] [45] [55] [75] [85] [95]  Листья
                                                     (→ строки)

  Поиск значения 45:
  Корень: 45 > 30, 45 < 70 → средний ребёнок
  Ветвь: 45 > 40, 45 ≤ 50  → средний ребёнок
  Лист:  найдено 45 → указатель на строку таблицы

  3 шага вместо полного перебора!
```

### Математика: почему это быстро

В B-tree с фактором ветвления 100 (типичное значение для SQLite при 4 KB страницах) три уровня дерева могут индексировать до 100^3 = 1 000 000 строк. Четыре уровня — 100 000 000 строк. Это значит: для поиска среди миллиона строк нужно прочитать с диска всего 3 страницы. Сложность — O(log n): логарифмическая. Удвоил данные — добавил одну проверку.

Для конкретных чисел: таблица из 100 000 строк. Без индекса SQLite читает ~100 000 строк (если каждая строка 100 байт, это ~2 400 страниц). С индексом — 3-4 страницы. Разница в 600-800 раз. На flash-памяти телефона одна страница читается за ~0.05ms. Без индекса: 2 400 × 0.05 = 120ms. С индексом: 4 × 0.05 = 0.2ms.

### Когда индексы помогают

Индексы ускоряют три типа операций. **WHERE-фильтрация:** `WHERE user_id = 42` — вместо перебора всех строк SQLite находит нужные через B-tree. **JOIN:** `JOIN users ON messages.user_id = users.id` — без индекса на `user_id` каждое соединение — это full scan вложенной таблицы. **ORDER BY:** `ORDER BY timestamp DESC` — если есть индекс по `timestamp`, данные уже отсортированы в B-tree, и SQLite не тратит время на сортировку.

### Когда индексы вредят

Каждый индекс — это дополнительная структура B-tree, которую SQLite должен обновлять при каждом INSERT, UPDATE и DELETE. Вставил строку — обнови все индексы этой таблицы. Если у таблицы 5 индексов, одна вставка превращается в 6 операций записи (строка + 5 индексов).

Помимо замедления записи, индексы занимают место на диске. Один индекс по колонке с 8-байтовыми значениями (Long) на таблице из 100 000 строк занимает примерно 1.5-2 MB. Пять индексов — 8-10 MB. Для мобильного приложения, где пользователь следит за размером приложения в настройках, это не мелочь.

Trade-off формулируется просто: **индексы ускоряют чтение, но замедляют запись и увеличивают размер базы.** Для приложения, которое читает в 100 раз чаще, чем пишет (типичный сценарий для UI), это выгодный обмен. Для приложения, которое массово импортирует данные (IoT-сенсоры, логи), избыток индексов может стать проблемой. Стратегия: при массовом импорте можно временно удалить индексы, вставить данные, и пересоздать индексы. В Room это реализуется через миграцию или `execSQL`.

> **Правило большого пальца:** Создавай индексы для колонок, которые появляются в WHERE, JOIN и ORDER BY часто выполняемых запросов. Не создавай индексы "на всякий случай".

Мы разобрали теорию индексов. Теперь — как создавать их в Room.

---

## @Index в Room: практическое применение

### Single-column index

Самый простой случай — индекс по одной колонке. Если у тебя есть запрос `WHERE chat_id = ?`, который выполняется при каждом открытии экрана чата, колонка `chat_id` — кандидат на индекс.

Ниже — как объявить Entity с индексом. Обрати внимание: индекс указывается в аннотации `@Entity`, а не в `@ColumnInfo`.

```kotlin
@Entity(
    tableName = "messages",
    indices = [
        Index(value = ["chat_id"])  // B-tree по chat_id
    ]
)
data class Message(
    @PrimaryKey val id: Long,
    @ColumnInfo(name = "chat_id") val chatId: Long,
    val text: String,
    val timestamp: Long
)
```

Этот код создаёт B-tree индекс по колонке `chat_id`. Теперь запрос `SELECT * FROM messages WHERE chat_id = 42` будет использовать SEARCH вместо SCAN. Room сгенерирует SQL `CREATE INDEX index_messages_chat_id ON messages(chat_id)` при создании базы.

### Composite index: порядок колонок критичен

Composite index (составной индекс) — это индекс по нескольким колонкам. Он работает по принципу **leftmost prefix rule** (правило левого префикса): SQLite может использовать составной индекс только если запрос фильтрует по колонкам слева направо.

Это похоже на телефонный справочник, отсортированный по фамилии, затем по имени. Ты можешь быстро найти всех Ивановых (первая колонка). Можешь найти Иванова Петра (обе колонки). Но НЕ можешь быстро найти всех Петров — справочник не отсортирован по имени без фамилии.

Ниже — составной индекс и запросы, которые он ускоряет. Порядок `chat_id, timestamp` выбран не случайно: сначала фильтруем по чату, потом сортируем по времени.

```kotlin
@Entity(
    tableName = "messages",
    indices = [
        Index(value = ["chat_id", "timestamp"])  // Порядок важен!
    ]
)
data class Message(
    @PrimaryKey val id: Long,
    @ColumnInfo(name = "chat_id") val chatId: Long,
    val text: String,
    val timestamp: Long
)
// ✅ Использует индекс: WHERE chat_id = ? ORDER BY timestamp
// ✅ Использует индекс: WHERE chat_id = ?
// ❌ НЕ использует:     WHERE timestamp > ? (нет leftmost prefix)
```

Этот пример демонстрирует ключевое правило: составной индекс `[chat_id, timestamp]` работает для запросов, которые начинаются с `chat_id`. Запрос только по `timestamp` не может использовать этот индекс — для него нужен отдельный индекс `[timestamp]`.

### Unique index

Unique index добавляет ограничение уникальности: SQLite не позволит вставить две строки с одинаковым значением индексированной колонки. Это полезно для идентификаторов, email-адресов, уникальных кодов.

```kotlin
@Entity(
    tableName = "users",
    indices = [
        Index(value = ["email"], unique = true)  // Уникальность
    ]
)
data class User(
    @PrimaryKey val id: Long,
    val email: String,
    val name: String
)
```

Unique index не только обеспечивает целостность данных, но и ускоряет поиск — SQLite знает, что результат будет максимум одна строка, и может прекратить поиск после первого совпадения.

### Когда индекс НЕ нужен

Не каждая колонка заслуживает индекса. Есть три случая, когда индекс бесполезен или даже вреден.

**Маленькие таблицы (< 1000 строк).** Full table scan по 1000 строкам занимает доли миллисекунды. Индекс не даст заметного ускорения, но добавит overhead при записи. Таблица настроек приложения, список категорий, справочник стран — индексы не нужны.

**Колонки с низкой selectivity.** Selectivity — это отношение уникальных значений к общему количеству строк. Булева колонка `is_read` имеет selectivity 2/N — крайне низкую. Индекс по такой колонке бесполезен: SQLite всё равно вернёт ~50% таблицы, и full scan будет быстрее, чем обход индекса плюс чтение строк.

**Колонки, используемые только для INSERT.** Если колонка записывается, но никогда не фильтруется в WHERE и не используется в ORDER BY, индекс на ней — чистый overhead.

Мы разобрали индексы — инструмент ускорения чтения. Но что делать когда проблема — скорость записи?

---

## Batch операции: 100-кратное ускорение вставок

### Проблема: одна вставка — одна транзакция

Каждая операция записи в SQLite выполняется внутри транзакции. Если транзакция не указана явно, SQLite создаёт неявную (autocommit): начинает транзакцию, выполняет операцию, делает commit. Commit — дорогая операция: SQLite вызывает fsync для гарантии, что данные записаны на диск.

Один fsync на flash-памяти телефона занимает ~1-5ms. Если ты вставляешь 1000 строк по одной — это 1000 транзакций, 1000 fsync-ов, 1000-5000ms. Пять секунд на тысячу вставок — пользователь заметит.

### Решение: групповая транзакция

Аналогия: представь, что ты переезжаешь. Можно вызвать грузовик для каждой коробки — 100 рейсов по 30 минут, 50 часов работы. Или загрузить все 100 коробок в один грузовик — 1 рейс, 30 минут. Результат одинаковый, но разница в эффективности — 100-кратная.

В SQLite грузовик — это транзакция. Один commit на 1000 операций вместо 1000 commit-ов.

Room предоставляет два способа. Первый — передать список в @Insert. Room автоматически обернёт в одну транзакцию. Ниже — DAO-метод, который принимает список и вставляет все элементы за одну транзакцию.

```kotlin
@Dao
interface MessageDao {
    @Insert
    suspend fun insertAll(messages: List<Message>)  // Одна транзакция!

    @Insert
    suspend fun insert(message: Message)  // Каждый вызов = транзакция
}
// insertAll(1000 сообщений) ≈ 50ms
// 1000 × insert(сообщение)  ≈ 5000ms
```

Разница наглядна: `insertAll` с 1000 элементами работает ~50ms (одна транзакция, один fsync), а 1000 вызовов `insert` — ~5000ms (1000 транзакций, 1000 fsync). Ускорение — 100 раз.

Второй способ — явное управление транзакцией через `withTransaction`. Это нужно когда внутри одной атомарной операции ты выполняешь разнородные действия: удаление, вставка, обновление.

```kotlin
suspend fun syncMessages(
    db: AppDatabase,
    toDelete: List<Long>,
    toInsert: List<Message>
) {
    db.withTransaction {                     // Одна транзакция на всё
        db.messageDao().deleteByIds(toDelete)
        db.messageDao().insertAll(toInsert)
    }
    // Один commit, один fsync — атомарно и быстро
}
```

Этот паттерн критичен для операций синхронизации с сервером: удалить устаревшие данные и вставить новые нужно атомарно. Если приложение крашится между удалением и вставкой — пользователь потеряет данные. `withTransaction` гарантирует: либо обе операции выполнены, либо ни одна.

### Сравнительная таблица производительности

| Операция | Время (1000 строк) | Причина |
|----------|:-------------------:|---------|
| 1000 отдельных INSERT | ~5000ms | 1000 транзакций, 1000 fsync |
| insertAll(List) | ~50ms | 1 транзакция, 1 fsync |
| withTransaction { 1000 insert } | ~50ms | 1 транзакция, 1 fsync |
| 1000 INSERT без WAL | ~8000ms | Rollback journal ещё медленнее |

> **Ключевое правило:** Никогда не вставляй данные в цикле без явной транзакции. Если Room DAO принимает `List<Entity>` — используй это. Если нужны разнородные операции — оборачивай в `withTransaction`.

Мы ускорили запись. Но что делать, когда данных слишком много для единовременной загрузки в память?

---

## Большие данные и Paging: работа с таблицами на 100K+ строк

### Проблема: загрузить всё в память невозможно

Таблица из 100 000 сообщений. Каждое сообщение — ~200 байт как объект в памяти. 100 000 × 200 = 20 MB объектов в heap. Плюс overhead Kotlin-объектов (ещё ~16 байт на каждый), плюс строки (String в JVM — отдельный объект в heap с собственным header). Итого ~30-40 MB. Для RecyclerView, который отображает 15-20 видимых элементов, — это расточительство.

Более того, создание 100 000 Kotlin-объектов — это нагрузка на garbage collector. GC pause на Android может вызвать jank (пропуск кадров), что пользователь увидит как "подёргивание" интерфейса. Загружать всё в память — плохо и по памяти, и по CPU, и по user experience.

### Paging 3 + Room

Room интегрирован с Paging 3 из Jetpack. DAO возвращает `PagingSource`, который загружает данные порциями (страницами) по мере прокрутки списка. На экране 20 элементов, в памяти — 60-100 (текущая страница + буфер), остальные 99 900 остаются в базе.

```kotlin
@Dao
interface MessageDao {
    @Query("""
        SELECT * FROM messages
        WHERE chat_id = :chatId
        ORDER BY timestamp DESC
    """)
    fun getMessages(chatId: Long): PagingSource<Int, Message>
}
// Room автоматически генерирует LIMIT/OFFSET запросы
// Paging 3 подгружает следующую порцию при скролле
```

Room автоматически добавляет `LIMIT` и `OFFSET` к запросу при использовании `PagingSource`. Первая страница: `LIMIT 20 OFFSET 0`. Следующая: `LIMIT 20 OFFSET 20`. И так далее. Пользователь скроллит — данные подгружаются.

### LIMIT/OFFSET vs Keyset pagination

У OFFSET-пагинации есть проблема производительности: `OFFSET 10000` заставляет SQLite пропустить первые 10 000 строк. Чем дальше пользователь скроллит, тем медленнее становится загрузка — SQLite тратит время на чтение и пропуск строк.

Keyset pagination решает это: вместо OFFSET используется значение последнего элемента предыдущей страницы.

```sql
-- OFFSET pagination (медленнеет с глубиной):
SELECT * FROM messages WHERE chat_id = 42
ORDER BY timestamp DESC LIMIT 20 OFFSET 10000;
-- SQLite читает и пропускает 10000 строк!

-- Keyset pagination (постоянная скорость):
SELECT * FROM messages WHERE chat_id = 42
  AND timestamp < :lastTimestamp
ORDER BY timestamp DESC LIMIT 20;
-- SQLite сразу прыгает к нужному месту через индекс
```

Paging 3 из Room по умолчанию использует OFFSET. Для большинства приложений с таблицами до 50 000 строк это приемлемо. Для больших таблиц стоит реализовать keyset pagination вручную через кастомный `PagingSource`.

### Lazy loading relations

Room по умолчанию НЕ загружает вложенные объекты. Если у `Message` есть связь с `User`, запрос `SELECT * FROM messages` не загрузит пользователей автоматически. Это осознанное решение — eager loading (загрузка всех связей) привёл бы к загрузке всей базы данных в память из-за каскадных связей. Представь цепочку: Message → User → Organization → Country. Eager loading одного сообщения потянул бы за собой пользователя, организацию и страну.

Для загрузки связанных данных используй `@Relation` или явные JOIN в запросе. `@Relation` выполняет отдельный SQL-запрос для каждой связи — это N+1 проблема. Если загружаешь 50 сообщений с авторами через `@Relation`, Room выполнит 1 запрос для сообщений + 1 запрос для пользователей (Room группирует). Это приемлемо. Но если у тебя вложенные `@Relation` в три уровня — количество запросов умножается. Явный JOIN (`SELECT m.*, u.name FROM messages m JOIN users u ON m.user_id = u.id`) выполняется за один запрос, но требует ручного маппинга результата.

---

## Memory и CursorWindow: граница между SQLite и Java

### CursorWindow: 2 MB буфер

Когда SQLite возвращает результаты запроса, данные не передаются напрямую в Java-объекты. Они проходят через CursorWindow — буфер в нативной памяти размером 2 MB по умолчанию. SQLite заполняет этот буфер строками результата, а Room (через Cursor API) читает оттуда и создаёт Java/Kotlin-объекты.

Аналогия: CursorWindow — это поднос в столовой. Повар (SQLite) кладёт тарелки (строки) на поднос. Если все тарелки влезают — отлично, один поход. Если нет — нужно несколько ходов. А если одна тарелка слишком большая (BLOB на 3 MB) — она не влезет на поднос вообще.

Проблема возникает в двух случаях. Первый: запрос возвращает слишком много строк, и CursorWindow не вмещает все. Room обрабатывает это автоматически — читает порциями. Второй случай серьёзнее: одна строка содержит BLOB (бинарные данные) больше 2 MB. Это вызывает exception.

### BLOB: хранить путь, не данные

Распространённая ошибка — хранить изображения или файлы в базе данных как BLOB. Изображение в 3 MB не влезет в CursorWindow. Даже если влезет — SQLite будет читать его при каждом запросе к этой строке, раздувая memory footprint.

Правильный подход: хранить файл в файловой системе (Internal Storage или cache directory), а в базе данных хранить путь к файлу.

```kotlin
@Entity
data class Photo(
    @PrimaryKey val id: Long,
    val filePath: String,  // ✅ Путь к файлу: "/data/app/photos/123.jpg"
    // val imageData: ByteArray  // ❌ BLOB — не делай так!
    val thumbnailPath: String,
    val capturedAt: Long
)
```

Это радикально уменьшает размер базы данных и скорость запросов. Строка с путём занимает ~100 байт. Строка с изображением — 3 000 000 байт. Разница в 30 000 раз.

### TransactionTooLargeException

Эта ошибка возникает когда Cursor пытается передать данные между процессами (через Binder) и размер превышает лимит (~1 MB). В контексте Room это может случиться при использовании ContentProvider поверх Room или при передаче больших результатов между процессами. Решение — ограничивать размер результатов через LIMIT или не передавать крупные результаты между процессами.

> **Подводный камень:** `SELECT *` на таблице с BLOB-колонкой загрузит бинарные данные даже если ты их не используешь. Всегда указывай конкретные колонки: `SELECT id, name, timestamp FROM photos` вместо `SELECT * FROM photos`.

---

## Database Inspector: диагностика в реальном времени

### Подключение к работающему приложению

Database Inspector встроен в Android Studio начиная с версии 4.1. Для подключения: откройте App Inspection (View → Tool Windows → App Inspection), выберите запущенное приложение на устройстве/эмуляторе, и перейдите на вкладку Database Inspector. Приложение должно быть debuggable.

Inspector показывает все таблицы Room, их схему и данные. Можно выполнять SQL-запросы в реальном времени — в том числе EXPLAIN QUERY PLAN, PRAGMA-команды и модифицирующие запросы (с осторожностью).

### Что проверять

Первое — **планы запросов**. Для каждого DAO-запроса выполни EXPLAIN QUERY PLAN и убедись, что нет SCAN TABLE на больших таблицах. Второе — **размер таблиц**: `SELECT COUNT(*) FROM messages` покажет сколько строк в таблице. Третье — **размер индексов**: `PRAGMA index_list('messages')` покажет все индексы таблицы. Четвёртое — **режим журнала**: `PRAGMA journal_mode` должен показать `wal`.

### Альтернативы

Stetho от Facebook был популярным инструментом для отладки баз данных, но объявлен deprecated в 2021 году. Flipper — его преемник — поддерживает инспекцию баз данных через плагин, но требует интеграции SDK в приложение. Database Inspector не требует изменений в коде приложения — это преимущество для production-сборок (debuggable).

Мы разобрали диагностику. Но как правильно измерить производительность, чтобы иметь объективные цифры?

---

## Benchmarking: измерение производительности базы данных

### Почему "на глаз" не работает

Субъективная оценка ("кажется быстрее") ненадёжна по нескольким причинам. Первый запуск всегда медленнее (cold cache) — SQLite читает страницы с диска. Второй запуск — быстрее: данные уже в page cache операционной системы, и чтение идёт из оперативной памяти. Фоновые процессы на телефоне (обновление приложений, синхронизация почты, GC) влияют на результаты непредсказуемо. Температура устройства влияет на thermal throttling CPU. Даже уровень заряда батареи может влиять — некоторые устройства снижают производительность при низком заряде. Единственный надёжный способ — benchmark с достаточным количеством повторений и правильной метрикой.

### Macrobenchmark для database операций

Jetpack Macrobenchmark позволяет измерять производительность на реальном устройстве с реалистичными условиями. Для базы данных создаётся benchmark, который выполняет типичные операции: вставка N строк, запрос списка, поиск по условию.

```kotlin
@RunWith(AndroidJUnit4::class)
class DatabaseBenchmark {
    @get:Rule
    val benchmarkRule = BenchmarkRule()

    @Test
    fun insertBatch() = benchmarkRule.measureRepeated {
        runBlocking {
            db.withTransaction {
                dao.insertAll(testMessages)  // 1000 сообщений
            }
        }
    }
}
```

Этот benchmark измеряет время вставки 1000 сообщений в транзакции. `measureRepeated` выполняет операцию множество раз и вычисляет статистику: median, min, max, стандартное отклонение.

### Правильные метрики

Не используй среднее (average) — оно скрывает хвосты распределения. Один запрос из ста может занять 500ms, но average покажет приемлемые 20ms. Правильные метрики:

**p50 (median)** — 50% запросов выполняется быстрее этого значения. Это "типичный" опыт пользователя.

**p95** — 95% запросов быстрее. Это "почти худший случай" — каждый 20-й запрос может быть таким.

**p99** — 99% запросов быстрее. Крайний случай — но для приложения с 10 000 запросов в день это 100 медленных запросов.

| Метрика | Хорошо | Приемлемо | Плохо |
|---------|:------:|:---------:|:-----:|
| p50 SELECT (отображение списка) | < 5ms | 5-20ms | > 20ms |
| p50 INSERT (batch 100) | < 20ms | 20-50ms | > 50ms |
| p95 SELECT | < 20ms | 20-50ms | > 50ms |
| p99 SELECT | < 50ms | 50-100ms | > 100ms |

### Test data generation

Бенчмарк без реалистичных данных бесполезен. Если тестируешь на таблице из 100 строк, а в production — 50 000, результаты нерепрезентативны. SQLite выбирает стратегию выполнения запроса (использовать индекс или full scan) на основе статистики таблицы — размер и распределение данных напрямую влияют на plan.

Три аспекта реалистичности тестовых данных. Первый — **объём**: если в production у пользователя 30 000 сообщений, генерируй 30 000 тестовых сообщений. Второй — **распределение**: если 80% сообщений приходятся на 5 активных чатов, а остальные 20% размазаны по 50 чатам — воспроизведи это распределение. Равномерное распределение (`chat_id = random(1, 55)`) покажет другие характеристики индексов, чем скошенное. Третий — **размер строк**: если текст сообщения в среднем 150 символов, не генерируй строки из 3 символов — это изменит количество строк на страницу и повлияет на I/O.

---

## Production optimization checklist

Семь пунктов — проверь каждый перед релизом.

1. **EXPLAIN QUERY PLAN для каждого DAO-запроса.** Ни один частый запрос не должен показывать SCAN TABLE на таблице > 1000 строк. Добавь индексы где видишь SCAN.

2. **Batch вставки через List или withTransaction.** Никаких циклов с одиночными INSERT. Если синхронизируешь данные с сервером — всё в одной транзакции.

3. **Paging для списков.** Любой экран, показывающий потенциально большой список, должен использовать Paging 3 с PagingSource.

4. **Нет BLOB в базе данных.** Файлы — на диске, пути — в базе. Проверь все Entity на наличие ByteArray.

5. **Нет SELECT * на таблицах с неиспользуемыми колонками.** Если отображаешь список, тебе не нужен полный текст статьи — создай отдельный lightweight Entity для списка.

6. **WAL mode активен.** Проверь через `PRAGMA journal_mode`. Room включает по умолчанию, но кастомная конфигурация могла отключить.

7. **Benchmark на целевом устройстве.** Эмулятор с SSD — не телефон с flash. Измеряй на реальном устройстве, желательно бюджетном — это будет worst case для пользователей.

---

## Распространённые заблуждения

| Заблуждение | Реальность |
|-------------|------------|
| "Room медленнее чем прямой SQLite" | Room генерирует тот же код что ты написал бы вручную. Compile-time overhead, не runtime. Benchmark показывает разницу < 1% |
| "Индекс на каждую колонку ускорит всё" | Каждый индекс замедляет запись и увеличивает размер БД. Индексы нужны только для колонок в WHERE/JOIN/ORDER BY частых запросов |
| "Composite index заменяет single-column" | Index [A, B] помогает WHERE A=? и WHERE A=? AND B=?, но НЕ помогает WHERE B=? (leftmost prefix rule) |
| "OFFSET пагинация всегда достаточна" | При OFFSET > 10000 производительность деградирует. Keyset pagination сохраняет постоянную скорость |
| "В памяти база быстрее" | In-memory DB не переживает перезапуск процесса. Для кэша — да, для хранения — нет. WAL + индексы дают достаточную скорость |
| "Транзакции замедляют работу" | Наоборот: batch внутри одной транзакции в 100 раз быстрее отдельных операций |
| "Full-text search решается LIKE '%query%'" | LIKE без индекса — full table scan. Для полнотекстового поиска нужен FTS (Full-Text Search) — отдельная виртуальная таблица |

---

## Подводные камни

**Миграции с добавлением индекса.** Создание индекса на существующей таблице с 500 000 строк может занять несколько секунд. SQLite при создании индекса читает каждую строку, строит B-tree и записывает его на диск — это O(n log n) операция. Если миграция выполняется на UI-потоке (при первом запуске после обновления), приложение зависнет. Пользователь увидит ANR (Application Not Responding). Решение: выполнять миграцию в фоне или предупреждать пользователя splash-экраном с прогресс-баром.

**LiveData/Flow и тяжёлые запросы.** Room автоматически перезапускает запрос при любом изменении таблицы, если DAO возвращает `Flow` или `LiveData`. Если запрос тяжёлый (JOIN трёх таблиц без индексов), а таблица обновляется часто — каждое обновление запускает тяжёлый запрос заново. Решение: оптимизируй запрос индексами, используй `distinctUntilChanged()` в Flow.

**WAL-файл растёт неограниченно.** Если долгая читающая транзакция (например, экспорт данных) держит snapshot, checkpoint не может выполниться. WAL-файл может вырасти до сотен мегабайт. Решение: не держать длинные транзакции, разбивать экспорт на порции.

**Room и многопроцессность.** Если несколько процессов (основной + Service в отдельном процессе) обращаются к одной базе данных, нужна особая конфигурация: `enableMultiInstanceInvalidation()`. Без этого один процесс не узнает об изменениях другого, и кэш Room станет невалидным.

**@RawQuery без параметров.** Если SQL-запрос собирается строкой (конкатенацией), а не через параметры `:param`, это открывает дверь для SQL-injection и не позволяет SQLite кэшировать plan выполнения. Всегда используй параметризованные запросы.

**Забытый VACUUM.** Со временем, после множества DELETE и UPDATE операций, файл базы данных фрагментируется — появляются "пустые" страницы. SQLite не уменьшает файл автоматически. Команда `VACUUM` перестраивает файл, удаляя пустоты. Но VACUUM требует временного пространства, равного размеру базы, и блокирует все операции на время выполнения. Выполнять VACUUM стоит в фоне, редко (раз в неделю или при простое приложения), и только если размер базы значительно превышает объём полезных данных.

**Наблюдатели без отписки.** Если DAO возвращает `Flow` и никто не отменяет collect (например, забыли привязать к lifecycle), Room продолжает слушать изменения таблицы и перезапускать запросы. Десять забытых наблюдателей на тяжёлых запросах — ощутимая нагрузка при каждом INSERT.

---

## Связь с другими темами

**[[android-room-deep-dive]]** — фундамент для этой главы. Без понимания архитектуры Room (Entity, DAO, Database, TypeConverter) оптимизация невозможна. Та глава отвечает на "что такое Room и как его использовать", эта — на "почему Room медленный и как исправить". Рекомендуется читать сначала deep-dive, потом эту главу.

**[[android-room-migrations]]** — миграции напрямую связаны с производительностью. Добавление индекса — это миграция. Изменение схемы таблицы с 500 000 строк — это секунды работы. Понимание миграций нужно для безопасного применения оптимизаций на production.

**[[android-data-persistence]]** — общая картина хранения данных на Android. Иногда проблема с производительностью Room решается выбором другого инструмента: DataStore для key-value настроек, файловое хранилище для бинарных данных. Эта глава помогает понять когда Room — правильный выбор, а когда нет.

**[[android-performance-profiling]]** — инструменты профилирования: Systrace, CPU Profiler, Memory Profiler. Database Inspector показывает что происходит внутри базы, а Profiler показывает как это влияет на приложение в целом: UI jank, memory allocation, CPU usage. Комбинация обоих инструментов — ключ к системной оптимизации.

**[[database-design-optimization]]** — теория проектирования баз данных, применимая к любой СУБД. Нормализация, денормализация, выбор типов данных, проектирование схемы. Знания из этой главы переносятся на Room напрямую — SQLite поддерживает те же принципы реляционного проектирования.

---

## Источники и дальнейшее чтение

- **Kleppmann, M. (2017). Designing Data-Intensive Applications.** — главы 3 (Storage and Retrieval) и 7 (Transactions). Фундаментальное объяснение B-tree, LSM-tree, WAL и транзакций. Лучшее из доступного для понимания как базы данных работают внутри. Концепции напрямую применимы к SQLite.

- **Hipp, D.R. SQLite Documentation (sqlite.org/docs.html).** — официальная документация SQLite. Разделы "How SQLite Works", "Query Planning", "Write-Ahead Logging" — первоисточник для всего, что касается SQLite internals. Hipp пишет удивительно понятно для автора СУБД.

- **Meier, R. (2022). Professional Android.** — главы по Room, data persistence, performance. Практические паттерны использования Room в production-приложениях. Хорошие примеры batch-операций и работы с Paging.

- **Google. Android Developers Documentation: Room Persistence Library.** — официальные гайды по Room: define entities, DAOs, database views, testing, migrations. Обновляются с каждой версией Room и содержат актуальные best practices.

- **Owens, M. (2006). The Definitive Guide to SQLite.** — глубокое погружение в архитектуру SQLite: B-tree, pager, virtual machine. Книга старая, но внутренняя архитектура SQLite не изменилась принципиально с тех пор.

---

*Создано: 2026-02-11*
