---
title: "JVM Concurrent Collections: потокобезопасные коллекции"
created: 2025-11-25
modified: 2025-12-02
tags:
  - topic/jvm
  - concurrency
  - collections
  - concurrent
  - type/deep-dive
  - level/intermediate
type: deep-dive
status: published
area: programming
confidence: high
prerequisites:
  - "[[jvm-concurrency-overview]]"
  - "[[jvm-synchronization]]"
related:
  - "[[jvm-concurrency-overview]]"
  - "[[jvm-synchronization]]"
  - "[[jvm-executors-futures]]"
---

# JVM Concurrent Collections: потокобезопасные коллекции

Когда несколько потоков одновременно читают и пишут в одну коллекцию, обычные `HashMap` или `ArrayList` ломаются — от невидимых потерь данных до бесконечных циклов. Пакет `java.util.concurrent` предлагает коллекции, спроектированные для параллелизма с нуля: `ConcurrentHashMap` обеспечивает миллионы операций в секунду через lock striping, `CopyOnWriteArrayList` гарантирует безопасную итерацию через снимки, а `BlockingQueue` координирует потоки-производители и потоки-потребители. Эта глава разбирает внутреннее устройство, эволюцию и подводные камни каждой из этих структур.

---

## Зачем это знать

Многопоточный код без потокобезопасных коллекций — это мина замедленного действия. Баги проявляются нерегулярно, под нагрузкой, в production, и почти невоспроизводимы в тестах. Понимание внутреннего устройства concurrent collections позволяет выбрать правильную структуру данных, избежать скрытых проблем с производительностью и не попасть в ловушку ложного чувства безопасности, когда коллекция потокобезопасна, но составная операция над ней — нет.

---

## Терминология

| Термин | Значение | Аналогия из жизни |
|--------|----------|-------------------|
| **Lock Striping** | Разделение данных на сегменты с отдельными блокировками | Парковка с несколькими въездами — машины на разных въездах не мешают друг другу |
| **Bucket** | Ячейка хэш-таблицы, куда попадают элементы по хэшу ключа | Полка в гардеробе — номер полки определяется номером на жетоне |
| **CAS (Compare-and-Swap)** | Атомарная операция: «если значение равно X, замени на Y» | Бронирование столика: «если свободен — занимаю, если нет — ищу другой» |
| **Copy-on-Write** | Создание полной копии структуры при каждой модификации | Музейная экспозиция: посетители смотрят на витрину, реставратор работает с копией в мастерской |
| **Weakly Consistent** | Итератор видит состояние на момент создания, но может пропустить параллельные изменения | Фотография городской улицы: фиксирует момент, но люди продолжают двигаться |
| **Backpressure** | Механизм замедления производителя, когда потребитель не успевает обрабатывать | Конвейер на заводе: если рабочий на следующем этапе не успевает — лента останавливается |
| **False Sharing** | Кэш-линии разных CPU конфликтуют из-за близости данных в памяти | Соседи в коммунальной квартире: один включает свет — другому мешает |

---

## Историческая справка: как появился java.util.concurrent

До Java 5 (2004) у разработчиков было ровно два варианта для многопоточной работы с коллекциями: ручная синхронизация через `synchronized` или обёртки `Collections.synchronizedMap()` / `Collections.synchronizedList()`. Оба варианта использовали один глобальный lock на всю структуру — при тысяче потоков производительность падала катастрофически.

Дуг Ли (Doug Lea), профессор Университета штата Нью-Йорк в Освего, ещё в 1998 году опубликовал библиотеку `dl.util.concurrent` — набор потокобезопасных коллекций, пулов потоков и примитивов синхронизации. Библиотека стала настолько популярной, что Sun Microsystems пригласила Ли возглавить JSR-166 — спецификацию, которая вошла в Java 5 как пакет `java.util.concurrent`.

Это был переломный момент. Впервые JDK предложил не просто «обёртки с замком», а структуры данных, спроектированные для параллелизма с нуля. `ConcurrentHashMap` использовал lock striping вместо глобальной блокировки. `CopyOnWriteArrayList` устранил проблему `ConcurrentModificationException` для read-heavy сценариев. `BlockingQueue` формализовал паттерн producer-consumer, который до этого реализовывался вручную через `wait/notify`.

> **Ключевая идея:** java.util.concurrent — это не набор «улучшенных коллекций». Это фундаментально другой подход к параллелизму: вместо «возьми обычную структуру и добавь замок» — «спроектируй структуру так, чтобы замок был минимальным или не нужен вовсе».

---

## Prerequisites

| Что нужно знать | Где изучить |
|-----------------|-------------|
| Основы concurrency: потоки, race conditions, happens-before | [[jvm-concurrency-overview]] |
| Примитивы синхронизации: synchronized, volatile, CAS | [[jvm-synchronization]] |
| Основы хэш-таблиц: хэш-функции, коллизии, resize | Любой учебник по структурам данных |

---

## Почему обычные коллекции не подходят для многопоточности

`HashMap` при параллельном доступе может не просто вернуть неправильные данные — он может уйти в бесконечный цикл. Внутри HashMap — массив связных списков (или деревьев с Java 8). При resize (увеличении размера) ссылки перестраиваются. Если два потока делают это одновременно, список может замкнуться в кольцо. Поток, итерирующий по нему, никогда не остановится. Это не теоретическая угроза — это реальный баг, который десятки команд встречали в production.

`Collections.synchronizedMap()` решает проблему корректности, но создаёт новую — один глобальный lock на всю структуру. Тысяча потоков, работающих с разными ключами, всё равно ждут друг друга. Это как если бы на парковке с тысячей мест был единственный шлагбаум: даже если свободных мест полно, все стоят в одной очереди.

Concurrent collections решают обе проблемы одновременно: корректность + высокий параллелизм. Каждая из них использует свой подход — lock striping, copy-on-write или блокирующие операции — в зависимости от паттерна доступа, для которого она оптимизирована.

### Сравнение подходов

| Коллекция | Блокировка | Когда использовать |
|-----------|------------|-------------------|
| `HashMap` | Нет | Строго один поток |
| `synchronizedMap` | Одна на всё | Мало потоков, простота важнее производительности |
| `ConcurrentHashMap` | По bucket'ам (Java 8+) | Много потоков, нужна производительность |
| `CopyOnWriteArrayList` | Копирование при записи | Много чтений, редкие записи |

---

## ConcurrentHashMap: парковка с несколькими въездами

ConcurrentHashMap — рабочая лошадка многопоточного Java-кода. Это не просто «HashMap с блокировками», а отдельная структура данных, спроектированная для параллелизма с нуля. Чтобы понять её устройство, представьте большую подземную парковку. У обычной `synchronizedMap` — один въезд: все машины стоят в одной очереди, даже если едут на разные этажи. У ConcurrentHashMap — отдельный въезд на каждый этаж (сегмент). Машины, едущие на разные этажи, вообще не пересекаются.

### Эволюция дизайна: от Java 7 к Java 8

Внутреннее устройство ConcurrentHashMap радикально изменилось между Java 7 и Java 8. Понимание этой эволюции помогает оценить, почему современный дизайн настолько эффективен.

**Java 7: Segment-based lock striping.** ConcurrentHashMap в Java 7 делил внутренний массив на фиксированное количество сегментов (по умолчанию 16). Каждый сегмент — это отдельная мини-HashMap со своим `ReentrantLock`. При операции `put(key, value)` вычислялся хэш ключа, определялся сегмент, и блокировался только этот сегмент. Остальные 15 сегментов оставались доступными для параллельных операций.

Проблема этого подхода — ригидность. Количество сегментов фиксировалось при создании и не могло меняться. Если данные распределялись неравномерно (hot keys попадали в один сегмент), этот сегмент становился bottleneck, а остальные простаивали. Кроме того, при операции `size()` приходилось захватывать все 16 locks одновременно — дорогая операция.

**Java 8: CAS + synchronized на уровне bucket.** Дизайн был полностью переработан Дагом Ли. Сегменты исчезли. Теперь каждая ячейка (bucket) массива — это отдельная точка синхронизации. При вставке в пустой bucket используется CAS (Compare-and-Swap) — атомарная операция без блокировки вообще. Если bucket уже содержит элементы — используется `synchronized` на первом узле цепочки этого bucket.

```
Java 7 (Segment-based):
┌──────────────────┐ ┌──────────────────┐
│  Segment 0       │ │  Segment 1       │
│  ReentrantLock   │ │  ReentrantLock   │
│  bucket[0..7]    │ │  bucket[8..15]   │
└──────────────────┘ └──────────────────┘
Гранулярность: 16 сегментов (фиксировано)

Java 8 (Per-bucket CAS + synchronized):
┌────────┐ ┌────────┐ ┌────────┐ ┌────────┐
│ bucket │ │ bucket │ │ bucket │ │ bucket │
│  CAS   │ │  CAS   │ │  sync  │ │  CAS   │
│  [0]   │ │  [1]   │ │  [2]   │ │  [3]   │
└────────┘ └────────┘ └────────┘ └────────┘
Гранулярность: каждый bucket отдельно
```

Это изменение дало два ключевых преимущества. Во-первых, гранулярность блокировки стала максимальной — конфликт возникает только когда два потока пишут в один и тот же bucket. Во-вторых, чтение стало полностью lock-free: значения узлов объявлены как `volatile`, что гарантирует видимость последних записей без блокировок.

### Treeification: когда список превращается в дерево

Ещё одно важное изменение Java 8 — treeification. Когда в одном bucket накапливается больше 8 элементов (порог `TREEIFY_THRESHOLD`), связный список преобразуется в красно-чёрное дерево. Это меняет сложность поиска в bucket с O(n) на O(log n).

Зачем это нужно? При плохой хэш-функции (или намеренной атаке через HashDoS) все ключи могут попасть в один bucket. Без treeification это превращает `ConcurrentHashMap` в связный список с O(n) на каждую операцию. С treeification даже worst-case остаётся O(log n). Обратное преобразование (untreeify) происходит при уменьшении количества элементов ниже 6.

> **Почему именно так:** Переход от segments к per-bucket locking — это применение принципа «минимальной блокировки». Чем меньше данных защищает один lock, тем выше параллелизм. CAS для пустых bucket'ов — это вообще отсутствие блокировки. Synchronized вместо ReentrantLock в Java 8 — потому что JVM научилась оптимизировать `synchronized` (biased locking, lightweight locking) лучше, чем явный ReentrantLock.

### Почему быстрее synchronizedMap

Следующий пример показывает фундаментальную разницу между глобальной блокировкой и lock striping — два потока, работающие с разными ключами, в ConcurrentHashMap выполняются параллельно, а в synchronizedMap — последовательно.

```java
// synchronizedMap — одна блокировка на всё
Map<String, User> users = Collections.synchronizedMap(new HashMap<>());
// Поток 1 пишет "alice" → ВСЕ потоки ждут
// Поток 2 хочет писать "bob" → ЖДЁТ, хотя ключ другой

// ConcurrentHashMap — блокировка по bucket'ам
ConcurrentHashMap<String, User> users = new ConcurrentHashMap<>();
// Поток 1 пишет "alice" → CAS/lock на bucket 5
// Поток 2 пишет "bob" → CAS/lock на bucket 12 → ПАРАЛЛЕЛЬНО
```

Разница становится драматической под нагрузкой. При 1000 потоках ConcurrentHashMap показывает примерно 10-кратное преимущество в пропускной способности, потому что потоки конкурируют не за одну блокировку, а за отдельные bucket'ы — и в большинстве случаев обходятся вообще без блокировки, используя CAS.

Мы разобрали, как ConcurrentHashMap устроен внутри. Но даже идеальная структура данных не поможет, если неправильно ей пользоваться. Следующий раздел — об атомарных операциях, без которых потокобезопасная коллекция превращается в иллюзию безопасности.

---

### Атомарные операции — ключ к корректности

Главная ошибка при работе с concurrent коллекциями — составные операции. «Проверить и добавить» — это ДВЕ операции. Между ними другой поток может вклиниться. Коллекция потокобезопасна на уровне отдельных вызовов, но комбинация вызовов — нет.

Следующий код демонстрирует классическую ошибку «check-then-act» и её исправление через атомарную операцию. Проблема в том, что между `containsKey` и `put` другой поток может вставить своё значение.

```java
// ❌ Race condition: два потока могут оба пройти проверку
if (!map.containsKey(key)) {   // Поток B может вставить здесь
    map.put(key, value);        // И мы перезапишем его значение
}

// ✅ Одна атомарная операция — race condition невозможен
map.putIfAbsent(key, value);
```

Этот пример показывает, что потокобезопасность коллекции не означает потокобезопасность вашего кода. Операция `putIfAbsent` выполняет проверку и вставку как одно неделимое действие — ни один поток не может вклиниться между ними.

ConcurrentHashMap предоставляет богатый набор атомарных операций для типичных сценариев. Следующий код демонстрирует три наиболее полезных: ленивую инициализацию, слияние значений и атомарное обновление.

```java
ConcurrentHashMap<String, Integer> counts = new ConcurrentHashMap<>();

// Атомарно: вычислить значение при первом обращении (lazy init)
counts.computeIfAbsent("key", k -> expensiveCalculation(k));

// Атомарно: merge — идеально для счётчиков
counts.merge("errors", 1, Integer::sum);  // errors += 1

// Атомарно: заменить значение только если текущее равно ожидаемому
counts.replace("errors", 5, 0);  // если errors==5, обнулить
```

Важное предостережение: лямбда внутри `computeIfAbsent` может вызываться под lock на bucket. Она должна быть быстрой и не иметь побочных эффектов. Если лямбда обращается к другому bucket той же map, возможен deadlock.

### Bulk-операции: параллельная обработка

Java 8 добавила в ConcurrentHashMap набор bulk-операций, которые используют внутренний параллелизм ForkJoinPool. Три вида операций: `forEach`, `search` и `reduce` — каждая принимает параметр `parallelismThreshold`. Если количество элементов в map превышает этот порог, операция выполняется параллельно.

Следующий код демонстрирует параллельный поиск значения — операция `search` распределяется по нескольким потокам, и первый найденный результат возвращается немедленно.

```java
ConcurrentHashMap<String, Integer> map = new ConcurrentHashMap<>();
// parallelismThreshold = 1000: если элементов > 1000, параллельно
String result = map.search(1000, (key, value) -> {
    return value > 100 ? key : null;  // Вернуть первый ключ с value > 100
});
```

Операция `search` прекращает работу, как только любой поток вернёт non-null результат. Это эффективно для раннего выхода. `forEach` и `reduce` обрабатывают все элементы. Порог `1` означает максимальный параллелизм, `Long.MAX_VALUE` — последовательное выполнение. На практике порог 10000-50000 — разумный компромисс между overhead'ом параллелизма и выигрышем от многоядерности.

### Производительность: что показывают бенчмарки

```
Тест: 1000 потоков, 50% put / 50% get, 1M ключей

synchronizedMap:    ~1.2M ops/sec
ConcurrentHashMap:  ~12M ops/sec   — 10× быстрее

При 95% get / 5% put (read-heavy):
synchronizedMap:    ~3M ops/sec
ConcurrentHashMap:  ~45M ops/sec   — 15× быстрее
```

Преимущество ConcurrentHashMap растёт с увеличением доли чтений, потому что чтение полностью lock-free (volatile read), тогда как synchronizedMap блокирует даже на get.

---

## CopyOnWriteArrayList: музейная экспозиция

Представьте музей, где в одном зале выставлена картина. Сотни посетителей одновременно её рассматривают. Когда реставратор хочет внести изменения, он не выгоняет всех из зала. Вместо этого он забирает картину в мастерскую, делает копию, вносит изменения в копию, а затем заменяет оригинал в витрине на обновлённую версию. Посетители, которые смотрели на старую версию, продолжают видеть её. Новые посетители увидят уже обновлённую.

Именно так работает `CopyOnWriteArrayList`. Внутри — volatile-ссылка на массив. При чтении поток получает ссылку на текущий массив и работает с ним. При записи создаётся полная копия массива, в копию вносятся изменения, и volatile-ссылка атомарно переключается на новый массив. Старый массив остаётся нетронутым — все потоки, которые уже получили на него ссылку, продолжают работать.

### Стоимость копирования и когда она оправдана

Каждый вызов `add()`, `set()` или `remove()` — это аллокация нового массива размером N и копирование всех N элементов. Для списка из 1000 элементов это 1000 копирований на каждую вставку. Для списка из 100 000 элементов — 100 000 копирований. Сложность записи — O(n), и это не амортизированное O(n), а честное O(n) на каждую операцию.

Звучит ужасно — и для многих сценариев это действительно ужасно. Но для определённого класса задач это идеальное решение. Ключевой вопрос: каково соотношение чтений к записям?

Следующий код показывает классический сценарий, для которого CopyOnWriteArrayList создан: список слушателей событий, где добавление происходит редко (при инициализации), а итерация — постоянно (при каждом событии).

```java
CopyOnWriteArrayList<EventListener> listeners = new CopyOnWriteArrayList<>();

// Запись (редко): создаёт новый массив, копирует + добавляет
listeners.add(new MyListener());  // O(n) — дорого, но редко

// Чтение (постоянно): получает snapshot и итерирует
for (EventListener listener : listeners) {
    listener.onEvent(event);  // Никаких блокировок, никаких исключений
    // Даже если другой поток сделает add — мы итерируем по snapshot
}
```

Итератор CopyOnWriteArrayList работает по snapshot'у — массиву, который существовал в момент создания итератора. Это означает, что итерация никогда не бросит `ConcurrentModificationException`, но также означает, что итератор не увидит изменения, сделанные после его создания. Для слушателей событий это идеально: мы хотим оповестить всех, кто был подписан на момент события, а новые подписчики получат следующее событие.

### Когда использовать, а когда — нет

```
Подходит:
  ✅ Слушатели событий (add при инициализации, iterate при каждом событии)
  ✅ Конфигурация (меняется при перезагрузке, читается тысячами запросов)
  ✅ Белые/чёрные списки (обновляются раз в час, проверяются на каждый запрос)
  ✅ Маленькие кэши с редкими обновлениями (< 100 элементов)

Не подходит:
  ❌ Частые записи (каждый add = полное копирование массива)
  ❌ Большие списки (копирование мегабайтов на каждую запись)
  ❌ Нужна мгновенная видимость записей (reader видит snapshot)
  ❌ Операции remove по индексу в цикле (каждый remove — O(n))
```

> **Подводный камень:** `CopyOnWriteArraySet` использует `CopyOnWriteArrayList` внутри. Операция `add()` проверяет наличие элемента через линейный поиск O(n), а затем копирует массив O(n). Для больших множеств с частыми записями это катастрофа. Используйте `ConcurrentHashMap.newKeySet()` вместо этого.

Ещё один неочевидный момент: CopyOnWriteArrayList не поддерживает `subList().add()` или `subList().remove()` — любая модификация через subList бросает `UnsupportedOperationException`. Это связано с внутренней механикой: subList привязан к конкретному snapshot массива, и модификация нарушила бы инвариант copy-on-write. Если нужна модифицируемая подвыборка — скопируйте элементы в обычный ArrayList.

Мы разобрали структуры для хранения данных с параллельным доступом. Но как потоки могут координировать свою работу — передавать задачи друг другу, ждать результатов, регулировать скорость обработки? Для этого существует BlockingQueue.

---

## BlockingQueue: конвейер на заводе

Представьте конвейер на автомобильном заводе. Один рабочий (producer) устанавливает двигатели на ленту. Другой рабочий (consumer) в конце ленты забирает собранные двигатели и устанавливает их в кузова. Если лента полная — первый рабочий останавливается и ждёт. Если лента пустая — второй рабочий ждёт. Лента конечной длины автоматически балансирует скорость обоих рабочих. Это и есть BlockingQueue.

BlockingQueue — основа паттерна Producer-Consumer. Это не просто потокобезопасная очередь, а механизм координации между потоками, который решает три проблемы одновременно: потокобезопасную передачу данных, ожидание без busy-waiting и backpressure.

### Три способа взаимодействия: poll, take и offer

Обычная очередь при `poll()` пустой очереди возвращает null. Потребитель должен крутиться в цикле, постоянно проверяя. Это называется busy-waiting (активное ожидание) и тратит CPU впустую — поток крутится в цикле, хотя мог бы спать.

BlockingQueue предлагает три стратегии поведения, и выбор между ними зависит от требований к отзывчивости и устойчивости:

| Метод | Поведение при пустой очереди | Поведение при полной очереди | Когда использовать |
|-------|------------------------------|-----------------------------|--------------------|
| `poll()` | Возвращает null немедленно | Возвращает false немедленно | Неблокирующая проверка: «есть что-нибудь?» |
| `poll(timeout, unit)` | Ждёт указанное время, затем null | Ждёт указанное время, затем false | Компромисс: ждём, но не вечно |
| `take()` | Блокирует поток до появления элемента | — | Классический consumer: «жду работу» |
| `put(element)` | — | Блокирует поток до освобождения места | Классический producer с backpressure |
| `offer(element)` | — | Возвращает false немедленно | Неблокирующая вставка: «если есть место» |
| `offer(element, timeout, unit)` | — | Ждёт указанное время, затем false | Producer с ограниченным ожиданием |

Вариант с timeout — часто лучший выбор для production. Он позволяет потоку периодически «просыпаться» и проверять, не нужно ли завершиться (например, при shutdown), вместо того чтобы висеть в `take()` бесконечно.

Следующий код показывает базовый паттерн producer-consumer с backpressure через ограниченную очередь. Если consumer не успевает — producer автоматически замедляется.

```java
BlockingQueue<Task> queue = new ArrayBlockingQueue<>(100);

// Producer: блокируется, если очередь полная (backpressure)
executor.submit(() -> {
    queue.put(task);  // Спит, пока не появится место
});

// Consumer: блокируется, если очередь пустая
executor.submit(() -> {
    Task task = queue.take();  // Спит, пока не появится задача
    process(task);
});
```

Оба потока автоматически синхронизируются через очередь: producer не может забить систему задачами, consumer не тратит CPU на пустые проверки. Это элегантное решение проблемы координации без явной синхронизации.

### Backpressure через ограниченную очередь

`ArrayBlockingQueue(100)` — это не просто «очередь размером 100». Это механизм backpressure — обратного давления. Если consumer не успевает обрабатывать задачи, очередь заполняется. Когда достигнут лимит — producer блокируется на `put()`. Система автоматически балансируется: скорость producer'а подстраивается под скорость consumer'а.

Unbounded очередь (`LinkedBlockingQueue()` без указания размера) — опасна. Её размер по умолчанию — `Integer.MAX_VALUE`, то есть фактически бесконечная. Producer может наполнять её быстрее, чем consumer обрабатывает. Очередь растёт, пока не закончится память — `OutOfMemoryError`. Это одна из самых частых причин аварий в production-системах на JVM.

> **Ключевая идея:** Всегда указывайте явный размер очереди. Unbounded queue — это отсутствие backpressure, а отсутствие backpressure — это OutOfMemoryError под нагрузкой.

### Варианты очередей: какую выбрать

| Очередь | Внутренняя структура | Особенность | Когда использовать |
|---------|---------------------|-------------|-------------------|
| `ArrayBlockingQueue` | Массив фиксированного размера | Один lock на put и take | Нужен backpressure, предсказуемое потребление памяти |
| `LinkedBlockingQueue` | Связный список | Раздельные locks для put и take | Гибкость размера, более высокая пропускная способность |
| `PriorityBlockingQueue` | Двоичная куча | Элементы извлекаются по приоритету | Задачи с приоритетами (но нет backpressure — unbounded!) |
| `SynchronousQueue` | Нет хранилища | Прямая передача из рук в руки | Handoff между потоками, используется в `CachedThreadPool` |
| `DelayQueue` | Куча с delay | Элемент доступен только после истечения delay | Отложенные задачи, TTL-кэши |

`SynchronousQueue` заслуживает отдельного внимания. В ней никогда ничего не хранится — размер всегда 0. `put()` блокируется, пока другой поток не вызовет `take()`. Это прямая передача из рук в руки, как эстафетная палочка. Используется в `Executors.newCachedThreadPool()`: каждая новая задача либо передаётся свободному потоку, либо для неё создаётся новый поток.

`LinkedBlockingQueue` имеет важное отличие от `ArrayBlockingQueue`: раздельные locks для операций put и take. Это означает, что producer и consumer могут работать одновременно, не блокируя друг друга. У `ArrayBlockingQueue` — один lock на обе операции. На практике `LinkedBlockingQueue` показывает более высокую пропускную способность при высокой конкуренции, но потребляет больше памяти из-за узлов связного списка.

---

## Распространённые заблуждения

| Заблуждение | Почему это неправильно |
|-------------|----------------------|
| «ConcurrentHashMap всегда лучше HashMap» | ConcurrentHashMap имеет overhead: volatile reads, CAS-операции, padding для предотвращения false sharing. Для single-thread сценариев HashMap на 10-30% быстрее. Используйте ConcurrentHashMap только когда доступ из нескольких потоков |
| «CopyOnWriteArrayList быстрый для чтения» | Чтение такое же быстрое, как у обычного ArrayList. Преимущество не в скорости чтения, а в отсутствии блокировок при чтении и безопасности итерации. Платите вы за это при записи |
| «Collections.synchronizedMap = ConcurrentHashMap» | synchronizedMap блокирует всю map одним lock. ConcurrentHashMap использует per-bucket CAS/synchronized. При 1000 потоках разница в производительности — порядок величины |
| «BlockingQueue.poll() блокирует» | `poll()` не блокирует, возвращает null немедленно. Блокирует `take()`. `poll(timeout)` — компромисс: ждёт указанное время |
| «Итерация по ConcurrentHashMap полностью thread-safe» | Итератор weakly consistent — может не видеть concurrent updates, может отразить часть обновлений. Для большинства случаев это нормально, но если нужен строгий snapshot — копируйте в обычную коллекцию |
| «size() на ConcurrentHashMap точен» | `size()` возвращает приблизительное значение. Во время подсчёта другие потоки могут добавлять и удалять элементы. Для точного подсчёта используйте `mappingCount()` (возвращает long) или внешнюю синхронизацию |

---

## Подводные камни и когда НЕ применяется

**ConcurrentHashMap и null.** В отличие от HashMap, ConcurrentHashMap не допускает null ни для ключей, ни для значений. Причина: `get(key)` возвращает null, когда ключа нет. Если бы null-значения были разрешены, невозможно было бы отличить «ключ отсутствует» от «ключ есть, значение null» без дополнительной проверки — а эта дополнительная проверка не атомарна.

**CopyOnWriteArrayList и remove в цикле.** Удаление элементов по условию кажется простым, но каждый `remove()` создаёт новый массив. Удаление 100 элементов из списка в 1000 — это 100 копирований по 999, 998, 997... элементов. Лучше собрать элементы для удаления, а потом вызвать `removeAll()` — одна копия вместо ста.

**BlockingQueue и отравленные сообщения.** Если consumer обрабатывает сообщение и падает с исключением, сообщение теряется (уже извлечено из очереди). В критичных системах нужен механизм подтверждения — consumer извлекает сообщение, обрабатывает, и только после успешной обработки удаляет. `BlockingQueue` не поддерживает это из коробки — для таких случаев используют JMS или Kafka.

---

## CS-фундамент

| CS-концепция | Применение в Concurrent Collections |
|--------------|-------------------------------------|
| **Lock Striping** | ConcurrentHashMap делит данные на bucket'ы с отдельными точками синхронизации |
| **Copy-on-Write** | CopyOnWriteArrayList: новый массив при каждой записи, snapshot при чтении |
| **Producer-Consumer** | BlockingQueue связывает producers и consumers с автоматическим backpressure |
| **Compare-and-Swap** | ConcurrentHashMap использует CAS для lock-free вставки в пустые bucket'ы |
| **Weak Consistency** | Итераторы видят snapshot, не бросают ConcurrentModificationException |
| **Treeification** | ConcurrentHashMap превращает длинные цепочки в красно-чёрные деревья |

---

## Связь с другими темами

**[[jvm-concurrency-overview]]** — Concurrent collections — это высокоуровневые абстракции, построенные на примитивах синхронизации (CAS, volatile, locks), описанных в обзоре concurrency. ConcurrentHashMap использует CAS для lock-free операций при низкой конкуренции и synchronized для bucket-level блокировки при высокой. Понимание memory model и happens-before guarantees необходимо для объяснения, почему weakly consistent итераторы ConcurrentHashMap безопасны, но могут пропускать concurrent updates. Рекомендуется сначала изучить основы concurrency, затем переходить к коллекциям.

**[[jvm-synchronization]]** — Synchronized, volatile и atomic — строительные блоки, из которых построены concurrent collections. ConcurrentHashMap внутренне использует CAS (через Unsafe/VarHandle) и synchronized; CopyOnWriteArrayList использует ReentrantLock для защиты записи; BlockingQueue реализует wait/notify через Condition variables. Понимание synchronized vs CAS trade-offs объясняет, почему ConcurrentHashMap в Java 8 перешёл от segment-based locks к per-bucket CAS: при низком contention CAS не требует context switch, в отличие от synchronized.

**[[jvm-executors-futures]]** — ExecutorService и BlockingQueue тесно связаны: ThreadPoolExecutor внутренне использует BlockingQueue для хранения задач, ожидающих выполнения. Выбор типа очереди (ArrayBlockingQueue, LinkedBlockingQueue, SynchronousQueue) напрямую влияет на поведение пула потоков: bounded queue обеспечивает backpressure, SynchronousQueue создаёт поток на каждую задачу (как в newCachedThreadPool). Изучение BlockingQueue в контексте executor pools помогает понять, почему ThreadPoolExecutor с неограниченной очередью может привести к OutOfMemoryError.

---

## Что читать дальше

Рекомендуемый порядок дальнейшего изучения: начните с [[jvm-synchronization]] для понимания примитивов (synchronized, CAS, volatile), на которых построены concurrent collections. Затем вернитесь к этому материалу. После — переходите к [[jvm-executors-futures]], чтобы увидеть, как BlockingQueue используется внутри ThreadPoolExecutor. Наконец, [[java-modern-features]] покажет, как Virtual Threads меняют подход к concurrency в целом.

---

## Источники и дальнейшее чтение

- Goetz B. et al. (2006). *Java Concurrency in Practice*. — Каноническая книга по многопоточности на JVM. Главы 5 «Building Blocks» и 11 «Performance and Scalability» детально разбирают ConcurrentHashMap, CopyOnWriteArrayList, BlockingQueue с анализом lock striping и performance trade-offs. Обязательна к прочтению для любого Java-разработчика.
- Lea D. (2000). *Concurrent Programming in Java: Design Principles and Patterns*, 2nd Edition. — Книга от создателя пакета java.util.concurrent. Описывает design decisions и теоретические основы, лежащие в основе concurrent collections. Помогает понять, ПОЧЕМУ структуры спроектированы именно так.
- Herlihy M., Shavit N. (2012). *The Art of Multiprocessor Programming*, Revised Edition. — Глубокая теория lock-free и wait-free структур данных, включая CAS-based hash maps и lock-free queues. Для тех, кто хочет понять теоретические гарантии, на которых основаны JDK concurrent collections.

---

*Проверено: 2026-02-11 — Педагогический контент проверен*
