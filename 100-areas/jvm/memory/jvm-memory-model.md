---
title: "JVM Memory Model: где живут объекты"
created: 2025-11-25
modified: 2025-12-28
tags:
  - topic/jvm
  - memory
  - heap
  - stack
  - concurrency
  - type/deep-dive
  - level/intermediate
type: deep-dive
status: published
area: programming
confidence: high
prerequisites:
  - "[[jvm-basics-history]]"
  - "[[jvm-virtual-machine-concept]]"
related:
  - "[[jvm-gc-tuning]]"
  - "[[jvm-production-debugging]]"
  - "[[jvm-performance-overview]]"
  - "[[kotlin-coroutines]]"
  - "[[caching-strategies]]"
  - "[[microservices-vs-monolith]]"
---

# JVM Memory Model: где живут объекты

> JVM делит память на области с разным назначением. Heap хранит объекты (GC). Stack хранит локальные переменные. Java Memory Model (JMM) определяет правила видимости между потоками. Generational ZGC (Java 21) обеспечивает паузы <1ms при heap до 16TB.

---

## Зачем это нужно

### Проблема: Неправильное понимание памяти = production incidents

| Ситуация | Причина | Последствия |
|----------|---------|-------------|
| OutOfMemoryError: heap | Утечки памяти, недостаточный heap | Приложение падает |
| Высокие GC паузы | Неправильный выбор GC, настройки | Latency spikes, timeouts |
| Race conditions | Неправильная работа с volatile/synchronized | Data corruption |
| Container OOM Kill | Неучёт native memory | Kubernetes restart pod |

Память JVM — это не просто "heap и stack". Это сложная система с несколькими областями, каждая со своими правилами, ограничениями и инструментами настройки. Неправильное понимание приводит к инцидентам, которые сложно диагностировать: приложение работает месяцами, а потом внезапно падает с OutOfMemoryError, потому что static cache медленно заполнялся без ограничений.

### Аналогия: Heap как складской комплекс

Представьте большой складской комплекс. **Heap** — это основной склад, где хранятся все товары (объекты). Товары привозят постоянно: каждый HTTP-запрос — это грузовик с коробками. Большинство коробок нужны на пару минут (обработка запроса), потом их можно выбросить. Но некоторые товары хранятся годами — это кэши, connection pools, конфигурации.

Склад разделён на две зоны. **Зона приёмки** (Young Generation) — сюда попадают все новые коробки. Уборщик (Minor GC) приходит часто, выбрасывает коробки, которые уже не нужны. Это быстро, потому что большинство коробок в зоне приёмки — мусор. **Зона долгосрочного хранения** (Old Generation) — сюда перемещают коробки, которые пережили несколько уборок и явно нужны надолго. Уборка здесь (Major GC) происходит реже, но занимает больше времени — нужно проверить каждый стеллаж.

Если склад переполнен и уборщик не может освободить место — это OutOfMemoryError. Если уборка занимает слишком долго — клиенты (потоки) ждут у ворот, и это GC-паузы.

---

### Актуальность в 2024-2025

**Java 21 LTS — ключевые изменения:**

| Фича | Описание | Влияние на память |
|------|----------|-------------------|
| **Virtual Threads** | Миллионы потоков | Микроскопические стеки, меньше памяти |
| **Generational ZGC** | GC <1ms pause | -75% memory, +4x throughput vs old ZGC |
| **Sequenced Collections** | Новые API | — |

**Сравнение GC (2024-2025):**

| GC | Pause Time | Throughput | Heap Size | Когда использовать |
|----|------------|------------|-----------|---------------------|
| **G1GC** | 10-200ms | Высокий | До 64GB | Default, general purpose |
| **ZGC Gen** | <1ms | Высокий | До 16TB | Low latency, большие heap |
| **Shenandoah** | <10ms | Средний | До 1TB | OpenJDK alternative |

Рекомендация для большинства приложений на Java 21+ — использовать ZGC с generational mode, что обеспечивает минимальные паузы при высокой пропускной способности.

```bash
# Для большинства приложений (Java 21+)
-XX:+UseZGC -XX:+ZGenerational -Xmx4g

# Для legacy или ограниченных ресурсов
-XX:+UseG1GC -Xmx4g -XX:MaxGCPauseMillis=200
```

Эти флаги — стартовая точка. Дальнейшая настройка зависит от профиля нагрузки конкретного приложения: allocation rate, соотношение short-lived и long-lived объектов, требования к latency.

### Container-aware настройки (критично!)

С Java 8u191+ JVM автоматически определяет лимиты контейнера. Это важно, потому что без container support JVM видит всю память хоста и может запросить больше, чем выделено контейнеру — результат: OOM Kill от операционной системы.

```bash
# Автоматически (по умолчанию включено)
-XX:+UseContainerSupport

# Heap = 25% от container memory limit
# Можно изменить:
-XX:MaxRAMPercentage=75.0

# Пример: container с 2GB limit
# Heap ≈ 1.5GB (75% от 2GB)
```

**Важно:** Native memory (Metaspace, threads, buffers) не входит в Xmx! Оставляйте запас минимум 25% от container limit для non-heap памяти. Без этого запаса контейнер будет убит OOM Killer, и в логах не останется Java stack trace — только `Killed` в dmesg.

---

## Терминология

| Термин | Значение | Аналогия |
|--------|----------|----------|
| **Heap (Куча)** | Область памяти для всех объектов, управляется GC | Склад товаров — вещи хранятся пока нужны, потом убирают |
| **Stack (Стек)** | Память потока для локальных переменных и вызовов | Стопка тарелок в ресторане — последняя положенная первой снимается |
| **Young Gen** | Область для короткоживущих объектов | Зона приёмки на складе — быстрый оборот |
| **Old Gen** | Область для долгоживущих объектов | Зона долгосрочного хранения — редко проверяется |
| **Metaspace** | Память для метаданных классов (вне heap) | Каталог товаров — описание, что где лежит |
| **GC Root** | Точка входа для определения достижимости объектов | Указатели на стеллажах: "этот товар заказан клиентом" |

---

## Структура памяти JVM

Память JVM делится на две большие категории: Heap (куча) — общая для всех потоков область, где живут объекты, и Non-Heap — остальная память, включающая Metaspace и стеки потоков. Это разделение фундаментально: heap управляется Garbage Collector и доступен всем потокам, non-heap управляется по другим правилам и частично приватна для каждого потока.

```
┌─────────────────────────────────────────────────────────────┐
│                        JVM MEMORY                            │
├──────────────────────────┬──────────────────────────────────┤
│     HEAP (shared)        │        NON-HEAP                  │
│                          │                                   │
│  ┌─────────────────────┐ │  ┌─────────────────────────────┐ │
│  │    Young Gen        │ │  │   Metaspace                 │ │
│  │  ┌──────┬────────┐  │ │  │   (класс метаданные)        │ │
│  │  │Eden  │Survivor│  │ │  └─────────────────────────────┘ │
│  │  └──────┴────────┘  │ │                                   │
│  └─────────────────────┘ │  ┌─────────────────────────────┐ │
│  ┌─────────────────────┐ │  │   Thread Stacks             │ │
│  │    Old Gen          │ │  │   (по одному на поток)      │ │
│  │   (tenured)         │ │  └─────────────────────────────┘ │
│  └─────────────────────┘ │                                   │
└──────────────────────────┴──────────────────────────────────┘
```

На этой диаграмме видна главная граница: левая часть (Heap) — территория Garbage Collector, правая часть (Non-Heap) — управляется иначе. Все объекты, создаваемые через `new`, попадают в Heap. Метаданные о классах, стеки потоков, JIT-скомпилированный код и внутренние структуры JVM — в Non-Heap.

**Heap** — единственная область, управляемая Garbage Collector. Когда вы пишете `new Object()`, память выделяется именно здесь. Размер контролируется флагами `-Xms` (начальный) и `-Xmx` (максимальный). Рекомендуется ставить `-Xms` и `-Xmx` одинаковыми: это избегает costly heap resizing в runtime, когда JVM запрашивает у ОС дополнительную память.

**Metaspace** — хранит информацию о загруженных классах: структуру полей, методы, байткод. В отличие от старого PermGen (Java 7 и ранее), Metaspace находится в нативной памяти и растёт автоматически. Почему отказались от PermGen? Потому что его фиксированный размер приводил к `OutOfMemoryError: PermGen space` — проблеме, которая была почти невозможна для пользователя: нужно было угадать правильный размер для количества классов, которое заранее неизвестно. Metaspace решает это, используя нативную память ОС с автоматическим ростом. Проблемы здесь редки, но возможны при динамической генерации классов (например, много Groovy скриптов или hot-reload в development).

**Thread Stacks** — каждый поток получает свой стек фиксированного размера (по умолчанию ~1MB). При 1000 потоках это уже 1GB только на стеки, что часто упускают при расчёте памяти. Это одна из главных причин, почему Virtual Threads (Java 21) так важны: их стеки занимают килобайты, а не мегабайты.

---

## Heap: где живут объекты

### Generational Hypothesis

Heap разделён на поколения на основе эмпирического наблюдения, сделанного ещё в 1984 году Дэвидом Унгаром (David Ungar) в работе по сборке мусора для Smalltalk: подавляющее большинство объектов живут очень недолго. Исследования показывают, что 90-98% объектов становятся мусором в течение нескольких миллисекунд после создания. Это наблюдение настолько устойчиво в разных языках и приложениях, что получило название "Generational Hypothesis" — гипотеза поколений.

> **Аналогия: больница и палаты.** Представьте больницу. Большинство пациентов приходят на приём (Young Gen) и уходят в тот же день — анализы, консультация, рецепт. Только небольшая часть остаётся на стационарном лечении (Old Gen) — те, кому нужна длительная терапия. Было бы абсурдно каждый день обходить все палаты стационара, чтобы проверить, не выздоровел ли кто-то из давних пациентов. Вместо этого: приёмное отделение обходят часто (Minor GC), стационар — реже (Major GC), но тщательнее.

Типичный пример — обработка HTTP-запроса. За один запрос создаются десятки временных объектов: DTO для передачи данных, StringBuilder для формирования ответа, итераторы для обхода коллекций, промежуточные результаты вычислений. Все они нужны только на время обработки запроса и сразу после становятся мусором.

Если бы GC проверял все объекты одинаково, он тратил бы много времени на проверку долгоживущих объектов (кэши, синглтоны, connection pools), которые годами остаются живыми. Разделение на поколения решает эту проблему: Young Gen собирается часто, но быстро (потому что большинство объектов уже мертвы), Old Gen — редко, но дольше.

Следующий пример показывает типичный паттерн создания короткоживущих объектов в серверном приложении — каждый вызов метода генерирует десятки объектов, которые живут только время обработки запроса.

```java
public List<UserDTO> getUsers() {
    List<User> users = userRepository.findAll();

    // Все эти объекты — короткоживущие, идеальные кандидаты для Young Gen
    List<UserDTO> dtos = new ArrayList<>();  // Временный список
    for (User user : users) {
        UserDTO dto = new UserDTO();         // Временный объект
        dto.setName(user.getName());         // Временная строка (возможно)
        dtos.add(dto);
    }
    return dtos;  // Только dtos выживет и уйдёт в Old Gen (если доживёт)
}
```

Здесь ArrayList, каждый UserDTO, итератор цикла — всё это кандидаты на Young Gen. Если метод вызывается 1000 раз в секунду, это тысячи объектов в секунду, и все они умирают почти мгновенно. Именно для такого паттерна спроектирован Young Gen — быстрая сборка короткоживущего мусора.

---

### Жизненный цикл объекта

Каждый объект проходит через определённые этапы жизни в памяти. Понимание этого цикла помогает диагностировать проблемы с памятью и оптимизировать приложение. Это не просто техническая деталь — это основа для понимания GC logs, которые вы будете читать при production-инцидентах.

**Eden Space** — место рождения объектов. При вызове `new` объект создаётся здесь. Eden обычно составляет 80% Young Gen и заполняется быстро. Для ускорения аллокации каждый поток получает свой приватный буфер в Eden — TLAB (Thread-Local Allocation Buffer). Благодаря TLAB создание объекта — это просто сдвиг указателя, без синхронизации между потоками. Это одна из причин, почему `new` в Java настолько быстр — часто быстрее, чем `malloc` в C.

**Minor GC** — когда Eden заполняется, запускается Minor GC. Он проверяет только Young Gen, находит живые объекты и копирует их в Survivor Space. Мёртвые объекты просто забываются — их память становится свободной. Ключевой момент: Minor GC не сканирует Old Gen целиком. Но что если объект в Old Gen ссылается на объект в Young Gen? Для этого существует Card Table — структура данных, отслеживающая ссылки из Old Gen в Young Gen. Это позволяет проверять только "грязные" карточки, а не весь Old Gen.

**Survivor Spaces (S0 и S1)** — два пространства, работающие по принципу ping-pong. Живые объекты копируются из одного в другое при каждом Minor GC. Каждое копирование увеличивает "возраст" объекта. Почему два пространства, а не одно? Потому что копирующий алгоритм (copying collector) работает эффективнее: он копирует только живые объекты в непрерывный блок памяти, избегая фрагментации. Если бы Survivor был один, пришлось бы дефрагментировать его на месте — значительно сложнее и медленнее.

**Promotion (продвижение)** — когда объект пережил достаточно Minor GC (по умолчанию 15, настраивается через `-XX:MaxTenuringThreshold`), он считается долгоживущим и перемещается в Old Gen. Порог 15 — это эвристика: если объект пережил 15 уборок, вероятность того, что он скоро умрёт, крайне мала. Но JVM может промотировать объекты раньше — например, если Survivor Space переполнен.

```
new Object()
    │
    ▼
Eden Space (новые объекты)
    │
    │ Minor GC
    ▼
Survivor S0 (age=1)
    │
    │ Minor GC
    ▼
Survivor S1 (age=2)
    │
    │ ... повторяется до age=15
    ▼
Old Gen (age >= 15)
    │
    │ Major GC (когда Old Gen заполнен)
    ▼
Удалён (если нет ссылок)
```

Эта диаграмма показывает "счастливый путь" объекта: рождение в Eden, выживание через Survivor Spaces, повышение в Old Gen и наконец удаление. В реальности 95%+ объектов не доживают даже до первого Survivor — они умирают прямо в Eden.

---

### Настройка размеров

Размеры областей памяти критично влияют на производительность. Слишком маленький Young Gen приводит к частым Minor GC, слишком большой — к длинным паузам. Правильный баланс зависит от характера приложения.

```bash
# Общий heap: -Xms (начальный) и -Xmx (максимальный)
# Рекомендация: ставить одинаковыми, чтобы избежать resize в runtime
-Xms2g -Xmx2g

# Соотношение Old:Young (по умолчанию 2:1)
# При -Xmx3g это означает Old=2g, Young=1g
-XX:NewRatio=2

# Соотношение Eden:Survivor (по умолчанию 8:1)
# При Young=1g это означает Eden=800MB, каждый Survivor=100MB
-XX:SurvivorRatio=8
```

Эти параметры — отправная точка. В production решения о размерах принимаются на основе данных профилирования: GC logs показывают частоту и длительность сборок, allocation profiler — скорость создания объектов.

**Практические следствия:**
- Увеличение Young Gen уменьшает частоту Minor GC, но увеличивает их длительность
- Для приложений с большим количеством короткоживущих объектов (веб-сервисы) стоит увеличить Young Gen
- Для приложений с большими долгоживущими кэшами — увеличить Old Gen

---

## Stack: вызовы методов

### Аналогия: Stack как стопка тарелок в ресторане

Представьте стопку тарелок на кухне ресторана. Повар ставит чистую тарелку сверху — это вызов нового метода. Официант берёт тарелку сверху — метод завершился и вернул результат. Нельзя вытащить тарелку из середины стопки — это нарушит всю конструкцию. Последняя положенная тарелка всегда снимается первой — это принцип LIFO (Last In, First Out), и именно так работает Stack.

Каждый поток в JVM имеет собственный Stack, недоступный другим потокам. Это ключевое отличие от Heap: данные в Stack не требуют синхронизации, потому что принадлежат только одному потоку. Ни один другой поток не может заглянуть в ваш Stack — это частная территория.

Stack хранит два типа данных:
- **Локальные переменные** — примитивы хранятся полностью (int, boolean, double), для объектов хранится только ссылка (сам объект в Heap)
- **Stack frames** — информация о вызовах методов (какой метод, откуда вызван, куда вернуться)

При вызове метода создаётся новый frame, при возврате — frame удаляется. Это автоматическое управление памятью без участия GC. Никакой сборки мусора, никаких пауз — просто сдвиг указателя стека. Это делает Stack значительно быстрее Heap для хранения данных, но с жёстким ограничением: данные живут только пока метод выполняется.

Следующий пример показывает, как одни и те же данные могут жить в Stack (примитивы, ссылки) и в Heap (сами объекты).

```java
public void main() {
    int x = 10;                    // Stack: примитив (4 байта)
    User user = new User("Alice"); // Stack: ссылка (8 байт) → Heap: объект
    calculate(x);
}

public void calculate(int a) {
    int result = a * 2;            // Stack: новый frame с локальными переменными
}  // ← frame удаляется, result исчезает
```

Обратите внимание: переменная `user` в Stack — это не объект, а ссылка (8 байт на 64-bit JVM). Сам объект `User("Alice")` живёт в Heap. Когда метод `main()` завершится, ссылка `user` исчезнет из Stack, но объект User может продолжать жить в Heap, если на него есть другие ссылки.

Визуализация памяти при выполнении `calculate(x)`:

```
STACK (Thread main)              HEAP
┌──────────────────┐            ┌────────────────┐
│ calculate()      │            │ User object    │
│   a = 10         │            │  name="Alice"  │
│   result = 20    │            └────────────────┘
├──────────────────┤                  ▲
│ main()           │                  │
│   x = 10         │                  │
│   user ──────────┼──────────────────┘
└──────────────────┘
```

На диаграмме видно: Stack растёт вверх (каждый вызов метода добавляет frame), а ссылка `user` в Stack указывает на объект в Heap. Когда `calculate()` завершится, его frame исчезнет. Когда `main()` завершится — исчезнет и frame main, и ссылка на User. Если других ссылок на User нет — GC его удалит при следующей сборке.

---

### StackOverflowError

Stack имеет фиксированный размер (по умолчанию ~1MB на поток). Переполнение происходит при слишком глубокой вложенности вызовов — чаще всего из-за бесконечной рекурсии. Каждый вызов метода добавляет frame в Stack, и если вызовов слишком много — Stack заканчивается.

```java
public void recursive() {
    recursive();  // Каждый вызов добавляет frame в Stack
}
// → StackOverflowError после ~10000-20000 вызовов (зависит от размера frame)
```

Количество вызовов до переполнения зависит от размера каждого frame: метод с 10 локальными переменными создаёт больший frame, чем метод без переменных. Поэтому точное число вызовов непредсказуемо — оно зависит от конкретного кода.

Размер Stack настраивается флагом `-Xss`. Увеличивать стоит осторожно — это влияет на каждый поток:

```bash
-Xss512k   # Уменьшить для приложений с тысячами потоков
-Xss2m     # Увеличить для глубокой рекурсии

# Пример расчёта памяти:
# 1000 потоков × 1MB = 1GB только на стеки
# 1000 потоков × 512KB = 500MB — уже экономия
```

Здесь видно практическое значение размера стека: при 1000 потоках разница между 1MB и 512KB стеком — 500MB памяти. В контейнере с лимитом 4GB это может быть разницей между стабильной работой и OOM Kill.

**Практические следствия:**
- При создании много потоков (серверные приложения) уменьшайте размер Stack
- При глубокой рекурсии увеличивайте Stack или переписывайте на итерацию
- Virtual Threads (Java 21) решают проблему, используя микроскопические стеки

---

## GC Roots: что держит объекты живыми

Garbage Collector работает по принципу достижимости (reachability). Объект считается живым, если до него можно добраться от одного из GC Roots — специальных "точек входа". Это фундаментальный принцип: GC не считает ссылки (как reference counting в Python или Swift) — он обходит граф объектов от корней.

> **Аналогия: электрическая сеть.** Представьте электростанцию (GC Root) и сеть проводов (ссылки), ведущих к домам (объекты). Дом считается "подключённым" (живым), если существует непрерывный путь от электростанции до этого дома. Если провода где-то оборваны и путь от станции прерывается — дом обесточен (объект мёртв), даже если сам дом целый и провода от него куда-то идут. GC ищет именно такие "обесточенные" дома и освобождает их территорию.

**GC Roots включают:**
- **Локальные переменные активных методов** (в Stack) — пока метод выполняется, все его локальные переменные удерживают объекты
- **Static поля классов** — живут пока класс загружен, то есть практически всегда
- **Активные потоки** — сам объект Thread является GC Root
- **JNI ссылки** (ссылки из нативного кода) — созданные через JNI Global References

Всё, что недостижимо от GC Roots, считается мусором и будет удалено. Не важно, сколько объектов ссылаются друг на друга — если ни один из них не достижим от GC Root, вся группа будет удалена. Это решает проблему циклических ссылок, которая является головной болью для reference counting систем.

```
GC Roots:
├─ Локальные переменные (stack всех потоков)
├─ Static поля загруженных классов
├─ Активные потоки (Thread объекты)
└─ JNI Global References
```

Следующий пример демонстрирует, как static поле (GC Root) может непреднамеренно удерживать объекты, создавая утечку памяти.

```java
// Static поле — это GC Root
static Map<String, User> cache = new HashMap<>();

void process() {
    User temp = new User("Bob");  // temp — локальная переменная = GC Root
    cache.put("bob", temp);       // Теперь User достижим через cache
}  // temp уходит из Stack, но User ЖИВ через static cache!

// Через месяц cache содержит миллион записей
// GC не может их удалить — они достижимы от GC Root (static поле)
```

Это классический пример "логической утечки": GC работает корректно — объекты действительно достижимы. Но программист не имел в виду хранить их вечно. Решение: bounded cache с eviction policy (Caffeine, Guava Cache) или WeakHashMap для объектов, которые можно потерять.

**Практические следствия:**
- Static коллекции без ограничений — частая причина утечек
- Используйте WeakHashMap или bounded caches (Caffeine, Guava Cache)
- Подписки на события (listeners) — вторая частая причина: объект подписался, но не отписался

---

## Java Memory Model (JMM): видимость между потоками

JMM — это не про структуру памяти, а про **правила видимости** изменений между потоками. Без понимания JMM легко написать код с race conditions. Важно понимать эту разницу: предыдущие разделы описывали, где физически размещаются данные (heap, stack, metaspace). JMM описывает, как данные в этих областях видны разным потокам.

### Почему видимость — проблема

Современные CPU имеют многоуровневые кэши (L1, L2, L3). Когда поток записывает значение переменной, он записывает его в кэш своего CPU, а не сразу в основную память. Другой поток на другом CPU может не увидеть это изменение, потому что его кэш содержит старое значение. Это не баг — это оптимизация: доступ к L1 кэшу в 100 раз быстрее доступа к RAM.

JMM формализует, когда изменения одного потока гарантированно видны другому. Без этих гарантий многопоточный код непредсказуем: на одной машине работает, на другой — нет. На одном JVM — работает, после обновления — ломается.

### Проблема видимости

Каждый поток может иметь локальную копию переменных (CPU cache). Без синхронизации изменения одного потока могут быть невидимы другому — и это не теоретическая проблема, а реальная ситуация, которая случается на серверах с несколькими CPU.

```java
// ПРОБЛЕМА: поток 2 может никогда не увидеть flag = true
class Visibility {
    boolean flag = false;  // Не volatile!

    void thread1() {
        flag = true;  // Записали в CPU cache потока 1
    }

    void thread2() {
        while (!flag) {  // Читаем из CPU cache потока 2
            // Бесконечный цикл!
        }
    }
}
```

Этот код может работать на вашей машине во время тестирования (один CPU, общий кэш) и зависнуть в production (несколько CPU, раздельные кэши). JIT-компилятор усугубляет проблему: видя, что `flag` не volatile и не меняется в текущем потоке, он может вынести проверку из цикла и превратить `while (!flag)` в `if (!flag) while(true)`.

---

### Happens-Before: гарантии порядка

JMM определяет отношение **happens-before**: если A happens-before B, то все изменения, сделанные до A, видны в B. Это формальное определение, введённое в JSR-133 (2004), и оно заменило предыдущую, слишком слабую спецификацию из Java 1.0.

| Правило | Пример |
|---------|--------|
| **Thread.start()** | Всё до start() видно в новом потоке |
| **Thread.join()** | Всё в потоке видно после join() |
| **volatile write -> read** | Запись видна последующим чтениям |
| **synchronized exit -> enter** | Выход из synchronized видно при входе |

Happens-before — транзитивно: если A happens-before B, и B happens-before C, то A happens-before C. Это позволяет строить цепочки гарантий. Например, если вы записали данные, затем установили volatile flag, а другой поток прочитал flag — он увидит и данные тоже, потому что запись данных happens-before volatile write, а volatile write happens-before volatile read.

---

### volatile

`volatile` — самый лёгкий механизм синхронизации. Он гарантирует две вещи:

1. **Видимость** — запись в volatile переменную видна всем потокам. JVM вставляет memory barrier (инструкцию CPU, которая сбрасывает кэш), гарантируя, что значение попадёт в основную память.
2. **Запрет reordering** — компилятор и CPU не могут переставлять операции через volatile read/write. Это предотвращает ситуацию, когда оптимизатор "переставляет" строки кода, нарушая видимую логику.

```java
class SafeVisibility {
    volatile boolean flag = false;  // volatile!

    void thread1() {
        flag = true;  // Запись с memory barrier
    }

    void thread2() {
        while (!flag) {  // Чтение с memory barrier
            // Корректно завершится
        }
    }
}
```

С volatile JVM вставляет StoreLoad barrier после записи и LoadLoad/LoadStore barrier перед чтением. Это дороже обычного доступа к переменной, но значительно дешевле synchronized.

**Важно:** volatile НЕ делает операции атомарными! Операция `counter++` — это три шага: прочитать, увеличить, записать. volatile гарантирует видимость каждого шага, но не гарантирует, что между шагами не вклинится другой поток.

```java
volatile int counter = 0;

void increment() {
    counter++;  // НЕ атомарно! Read-modify-write
}

// Решение: AtomicInteger или synchronized
AtomicInteger counter = new AtomicInteger(0);
counter.incrementAndGet();  // Атомарно через CAS
```

AtomicInteger использует CAS (Compare-And-Swap) — аппаратную инструкцию CPU, которая атомарно сравнивает текущее значение с ожидаемым и заменяет, если совпадает. Это быстрее synchronized, потому что не требует блокировки.

---

### Double-Checked Locking

Классический пример, где volatile критичен. Этот паттерн пытается объединить ленивую инициализацию с потокобезопасностью без накладных расходов synchronized на каждый вызов.

Без volatile проблема в том, что `instance = new Singleton()` — это не одна операция. Это три шага: (1) выделить память, (2) вызвать конструктор, (3) присвоить ссылку. CPU и JIT могут переставить шаги 2 и 3: сначала присвоить ссылку на неинициализированный объект, потом вызвать конструктор. Другой поток увидит ненулевой `instance` и вернёт полусконструированный объект.

```java
// БЕЗ volatile — сломано!
class Singleton {
    private static Singleton instance;

    static Singleton getInstance() {
        if (instance == null) {
            synchronized (Singleton.class) {
                if (instance == null) {
                    instance = new Singleton();  // Может быть reordered!
                }
            }
        }
        return instance;
    }
}

// С volatile — корректно
class Singleton {
    private static volatile Singleton instance;  // volatile!

    static Singleton getInstance() {
        if (instance == null) {
            synchronized (Singleton.class) {
                if (instance == null) {
                    instance = new Singleton();
                }
            }
        }
        return instance;
    }
}
```

volatile запрещает reordering: запись в `instance` не произойдёт до завершения конструктора. Другой поток либо увидит null (и войдёт в synchronized), либо увидит полностью сконструированный объект.

---

## Virtual Threads (Java 21)

Virtual Threads меняют правила работы с памятью. Это одно из самых значительных изменений в JVM за последнее десятилетие, потому что оно устраняет компромисс между простотой кода и масштабируемостью.

### Преимущества

| Аспект | Platform Threads | Virtual Threads |
|--------|------------------|-----------------|
| **Stack size** | ~1MB | ~несколько KB |
| **1M потоков** | ~1TB RAM | ~несколько GB |
| **Переключение** | OS scheduler (дорого) | JVM (дёшево) |

Разница в порядках величин объясняется просто: platform thread — это обёртка над потоком ОС, со стеком, выделенным заранее на весь срок жизни. Virtual thread — это объект в heap, чей стек растёт динамически и сохраняется/восстанавливается при каждом переключении.

### Особенности памяти

Следующий пример показывает создание миллиона virtual threads — задачу, невозможную с platform threads из-за ограничений памяти.

```java
// Создание миллиона virtual threads
try (var executor = Executors.newVirtualThreadPerTaskExecutor()) {
    IntStream.range(0, 1_000_000).forEach(i -> {
        executor.submit(() -> {
            Thread.sleep(Duration.ofSeconds(1));
            return i;
        });
    });
}
// ~несколько GB вместо ~1TB для platform threads
```

Миллион platform threads потребовал бы ~1TB RAM только на стеки (1MB каждый). Миллион virtual threads — несколько гигабайт. Это открывает возможности для "thread-per-request" модели: каждый HTTP-запрос обрабатывается в отдельном virtual thread, без thread pools и reactive programming.

### Pinning (блокировка carrier thread)

Virtual thread "приклеивается" к carrier thread (платформенному потоку-носителю) в двух ситуациях:
- `synchronized` блоки — потому что монитор привязан к конкретному потоку ОС
- Native методы — потому что нативный код не знает о virtual threads

Pinning означает, что carrier thread заблокирован и не может обслуживать другие virtual threads. При массовом pinning pool carrier threads исчерпывается, и приложение фактически деградирует до модели с ограниченным числом потоков.

```java
// ПЛОХО — pinning, блокирует carrier thread
synchronized (lock) {
    Thread.sleep(1000);  // Virtual thread не может отсоединиться
}

// ХОРОШО — ReentrantLock не вызывает pinning
ReentrantLock lock = new ReentrantLock();
lock.lock();
try {
    Thread.sleep(1000);  // Virtual thread может отсоединиться
} finally {
    lock.unlock();
}
```

ReentrantLock работает через `java.util.concurrent` API, который поддерживает virtual threads. synchronized использует встроенные мониторы JVM, привязанные к ОС-потокам. В Java 24+ планируется устранить pinning для synchronized, но на текущий момент (Java 21-23) рекомендуется использовать ReentrantLock в коде, работающем с virtual threads.

### ThreadLocal осторожно!

ThreadLocal с virtual threads — потенциальная проблема памяти. С platform threads ThreadLocal обычно имеет десятки-сотни экземпляров (по числу потоков в пуле). С virtual threads каждый из миллиона потоков получает свою копию.

```java
// ПЛОХО — миллионы virtual threads = миллионы копий
ThreadLocal<ExpensiveObject> cache = new ThreadLocal<>();

// ХОРОШО — ScopedValue (Java 21)
// Или shared cache с синхронизацией
```

Используйте ScopedValue (preview в Java 21, finalized в Java 23) — он спроектирован для virtual threads и не создаёт per-thread копии.

---

## Native Memory Tracking (NMT)

JVM использует память за пределами heap. Это native memory: Metaspace, thread stacks, JIT-скомпилированный код, GC structures, direct byte buffers. NMT (Native Memory Tracking) помогает отследить эту "невидимую" память, которая часто является причиной OOM Kill в контейнерах.

### Включение NMT

NMT добавляет 5-10% overhead, поэтому обычно включается только для диагностики. В summary режиме показывает категории памяти, в detail — отдельные выделения.

```bash
# Включить NMT (5-10% overhead)
-XX:NativeMemoryTracking=summary   # или detail

# Получить отчёт
jcmd <pid> VM.native_memory summary

# Сравнение (найти утечки)
jcmd <pid> VM.native_memory baseline
# ... время проходит ...
jcmd <pid> VM.native_memory summary.diff
```

Команда `summary.diff` показывает, какие категории выросли с момента baseline. Если Thread memory выросла на 200MB — кто-то создаёт потоки без остановки. Если Code выросла — JIT компилирует слишком много методов.

### Категории native memory

```
Native Memory Tracking:
Total: 2345MB
- Java Heap:     1024MB  ← -Xmx
- Class:         150MB   ← Metaspace
- Thread:        120MB   ← Stack × потоки
- Code:          80MB    ← JIT compiled code
- GC:            60MB    ← GC structures
- Internal:      50MB    ← JVM internal
- Symbol:        30MB    ← Symbol table
- Native Memory Tracking: 20MB ← NMT overhead
```

Этот отчёт показывает типичное распределение: heap — крупнейшая категория, но за его пределами ещё ~1.3GB памяти. Именно эту память не учитывает `-Xmx`, и именно из-за неё контейнеры получают OOM Kill.

### Важно для контейнеров

При расчёте memory limit для контейнера нужно учитывать все категории native memory, а не только heap.

```bash
# Container memory = Heap + Native
# Пример для 4GB container:
# - Heap: 2.5GB (-Xmx2500m)
# - Metaspace: 256MB
# - Thread stacks: 200MB (200 threads × 1MB)
# - Buffers, GC, etc: 500MB
# - Safety margin: 544MB
# Total: ~4GB
```

Правило большого пальца: Heap должен занимать не более 60-75% от container memory limit. Остальное — для native memory и safety margin.

---

## OutOfMemoryError: виды и диагностика

OutOfMemoryError — это не одна ошибка, а семейство ошибок с разными причинами и решениями. Понимание вида OOM — первый шаг к решению.

### Java heap space

```
java.lang.OutOfMemoryError: Java heap space
```

**Что произошло:** Heap переполнен, GC не может освободить достаточно памяти для создания нового объекта. GC пытался несколько раз, потратил значительную часть CPU, но live objects занимают почти весь heap.

**Причины:**
- Утечка памяти — объекты накапливаются, но не удаляются (static кэши, listeners)
- Недостаточный heap для объёма данных (загрузка огромного файла целиком в память)
- Большие объекты (десятимегабайтные строки, массивы)

**Диагностика:**

Первый шаг — получить heap dump для анализа. Флаг `HeapDumpOnOutOfMemoryError` автоматически создаёт dump в момент OOM — это критически важно, потому что после OOM приложение часто перезапускается, и момент упущен.

```bash
# Увеличить heap (временное решение)
-Xmx4g

# Автоматический heap dump при OOM (для анализа)
-XX:+HeapDumpOnOutOfMemoryError
-XX:HeapDumpPath=/var/log/

# Анализ heap dump
# 1. Открыть в Eclipse MAT
# 2. Leak Suspects Report покажет подозрительные объекты
# 3. Dominator Tree покажет что держит больше всего памяти
```

Увеличение heap — это не решение, а временная мера. Она покупает время для анализа. Если причина — утечка, увеличение heap лишь отодвигает OOM на несколько часов.

### Metaspace

```
java.lang.OutOfMemoryError: Metaspace
```

**Что произошло:** Область метаданных классов переполнена.

**Причины:**
- Динамическая генерация классов (Groovy, hot-reload frameworks)
- Утечка ClassLoader — загруженные классы не выгружаются
- Слишком много зависимостей с уникальными классами

**Диагностика:**
```bash
# Увеличить лимит Metaspace
-XX:MaxMetaspaceSize=512m

# Мониторинг количества загруженных классов
jcmd <pid> VM.class_hierarchy
```

Если количество загруженных классов растёт без остановки — это утечка ClassLoader. Типичная причина: hot-reload в dev-режиме создаёт новый ClassLoader при каждом изменении кода, но старый не выгружается.

### StackOverflowError

```
java.lang.StackOverflowError
```

**Что произошло:** Stack потока переполнен из-за слишком глубокой вложенности вызовов.

**Причины:**
- Бесконечная рекурсия (самая частая)
- Очень глубокая легитимная рекурсия (обход глубоких деревьев)

**Решение:**
```bash
# Увеличить размер Stack
-Xss2m

# Или переписать рекурсию на итерацию (лучше)
```

Переписывание на итерацию предпочтительнее увеличения стека, потому что устраняет корневую причину, а не маскирует симптом.

### Unable to create native thread

```
java.lang.OutOfMemoryError: unable to create new native thread
```

**Что произошло:** ОС не может создать новый поток.

**Причины:**
- Достигнут лимит потоков ОС (ulimit)
- Недостаточно памяти для Stack нового потока
- Слишком много потоков уже создано

**Решение:**
```bash
# Linux: увеличить лимит процессов
ulimit -u 65536

# Уменьшить размер Stack каждого потока
-Xss512k

# Использовать пулы потоков вместо создания новых
```

В контейнерах лимит потоков может быть ограничен cgroup. Проверяйте `/proc/sys/kernel/threads-max` и `cgroup` настройки.

---

## Memory Leaks в Java

Технически в Java нет классических утечек памяти (как в C, где забыли вызвать `free()`). GC удаляет все недостижимые объекты. Но есть "логические утечки": объекты, которые приложению больше не нужны, но остаются достижимыми от GC Roots. GC не может отличить "нужный" объект от "забытого" — он видит только достижимость.

### Типичные паттерны утечек

**1. Static коллекции без ограничений:**

Самый частый паттерн. Разработчик создаёт "простой кэш" через HashMap и забывает добавить eviction policy. Коллекция растёт линейно с количеством обработанных запросов.

```java
// ПРОБЛЕМА: cache никогда не очищается
static List<User> cache = new ArrayList<>();

void process(User user) {
    cache.add(user);  // Добавляем, но никогда не удаляем
}

// РЕШЕНИЕ: использовать bounded cache
static Cache<String, User> cache = Caffeine.newBuilder()
    .maximumSize(10_000)
    .expireAfterWrite(Duration.ofMinutes(10))
    .build();
```

Caffeine автоматически удаляет старые записи, когда кэш достигает максимального размера или записи устарели. Это гарантирует, что кэш не вырастет больше заданного предела.

**2. Незакрытые ресурсы:**

Ресурсы (файлы, соединения, потоки) часто удерживают native memory за пределами heap. Незакрытый InputStream — это не только утечка файлового дескриптора, но и native buffer в памяти.

```java
// ПРОБЛЕМА: ресурс держит нативную память
FileInputStream fis = new FileInputStream(path);
// Забыли fis.close()

// РЕШЕНИЕ: try-with-resources
try (FileInputStream fis = new FileInputStream(path)) {
    // работа с файлом
}  // автоматически закроется
```

try-with-resources гарантирует закрытие даже при исключении. Это не просто хорошая практика — это обязательный паттерн для работы с ресурсами.

**3. Listeners без отписки:**

Event-driven архитектура создаёт скрытые ссылки: объект подписывается на события и остаётся "живым" через ссылку в event bus, даже если по бизнес-логике он уже не нужен.

```java
// ПРОБЛЕМА: listener держит ссылку на объект
eventBus.register(this);  // Подписались
// Объект "удалён", но живёт через eventBus

// РЕШЕНИЕ: явная отписка
@Override
public void onDestroy() {
    eventBus.unregister(this);
}
```

Этот паттерн особенно опасен в Android-разработке, где Activity и Fragment имеют жизненный цикл, но listener может пережить их.

**4. ThreadLocal без очистки:**

В пулах потоков ThreadLocal живёт дольше, чем ожидает разработчик: поток не уничтожается после выполнения задачи, а возвращается в пул. ThreadLocal остаётся привязанным к этому потоку.

```java
// ПРОБЛЕМА: в пуле потоков ThreadLocal живёт вечно
ThreadLocal<User> currentUser = new ThreadLocal<>();
currentUser.set(user);
// Поток вернулся в пул, но ThreadLocal остался

// РЕШЕНИЕ: очистка в finally
try {
    currentUser.set(user);
    // работа
} finally {
    currentUser.remove();
}
```

`remove()` в finally блоке — обязательный паттерн при использовании ThreadLocal с thread pools. Без него данные одного запроса могут "утечь" в следующий запрос, обработанный тем же потоком.

### Диагностика утечек

Heap dump — основной инструмент диагностики утечек. Два способа получить dump:

```bash
# Получить heap dump
jcmd <pid> GC.heap_dump /tmp/heap.hprof

# Или через jmap
jmap -dump:live,format=b,file=heap.hprof <pid>
```

Рекомендуется использовать `jcmd` — он безопаснее для production и не требует остановки приложения на длительное время.

**Анализ в Eclipse MAT:**
1. **Leak Suspects Report** — автоматически находит подозрительные объекты, которые занимают непропорционально много памяти
2. **Dominator Tree** — показывает иерархию: какой объект "удерживает" больше всего памяти
3. **Path to GC Roots** — показывает цепочку ссылок от GC Root до конкретного объекта. Именно эта цепочка объясняет, **почему** объект жив

---

## Quick Reference

| Область | Что хранит | Управление | Ошибка переполнения |
|---------|-----------|------------|---------------------|
| Heap | Объекты | GC | OutOfMemoryError: heap |
| Stack | Локальные переменные, вызовы | Автоматически (при выходе) | StackOverflowError |
| Metaspace | Метаданные классов | GC (частично) | OutOfMemoryError: Metaspace |

| Флаг | Назначение | Пример |
|------|-----------|--------|
| `-Xms` / `-Xmx` | Min/max heap | `-Xms2g -Xmx2g` |
| `-Xss` | Stack на поток | `-Xss512k` |
| `-XX:NewRatio` | Old:Young соотношение | `-XX:NewRatio=2` |
| `-XX:MaxMetaspaceSize` | Лимит Metaspace | `-XX:MaxMetaspaceSize=512m` |
| `-XX:+HeapDumpOnOutOfMemoryError` | Dump при OOM | — |

---

## Распространённые заблуждения

| Миф | Реальность |
|-----|-----------|
| "Java Memory Model = структура памяти JVM" | JMM — это правила видимости между потоками (happens-before), не про Heap/Stack. Структура памяти — отдельная тема |
| "volatile делает операции атомарными" | volatile гарантирует видимость и запрет reordering. Но counter++ не атомарен! Используйте AtomicInteger |
| "-Xmx определяет всю память JVM" | Xmx — только heap. Native memory (Metaspace, threads, buffers) не включена. В контейнерах оставляйте 25% запас |
| "GC паузы = плохой код" | GC паузы — normal behavior. G1 10-200ms, ZGC <1ms. Проблема в неправильном выборе GC для use case |
| "Young Gen всегда 1/3 heap" | Соотношение настраивается. Для веб-сервисов (много short-lived objects) Young Gen можно увеличить |
| "ThreadLocal безопасен в пулах потоков" | ThreadLocal может протечь! В пулах потоки переиспользуются. Всегда remove() в finally |
| "OutOfMemoryError = heap переполнен" | OOM имеет разные виды: heap, Metaspace, native threads, unable to create thread. Причины разные |
| "Virtual Threads решают все проблемы памяти" | Virtual Threads экономят stack memory. Но ThreadLocal с ними опасен — миллион VT = миллион копий |
| "Static = живёт вечно" | Static fields — GC roots. Они держат объекты живыми. Static cache без ограничений = утечка |
| "Heap dump — это всё для диагностики" | Heap dump показывает объекты. Thread dump показывает что делают потоки. Часто нужны оба |

---

## Связь с другими темами

**[[jvm-gc-tuning]]** — memory model определяет структуру heap (Young/Old Generation, regions), а GC tuning использует это знание для выбора и настройки сборщика мусора. Без понимания, как объекты размещаются в Eden, перемещаются в Survivor и промотируются в Old Gen, невозможно осмысленно интерпретировать GC логи и настраивать параметры. Изучите memory model как теоретический фундамент перед практическим GC tuning.

**[[jvm-production-debugging]]** — heap dump, thread dump и JFR recording — всё это инструменты для диагностики проблем с памятью. Понимание memory model позволяет интерпретировать результаты: почему объекты в Old Gen не собираются, откуда native memory leaks, как virtual threads меняют stack consumption. Memory model объясняет "почему", debugging даёт инструменты "как найти и починить".

**[[jvm-performance-overview]]** — memory layout и allocation patterns напрямую влияют на производительность: TLAB для быстрого allocation, escape analysis для stack allocation, object padding и false sharing в cache lines. Performance overview связывает знания о памяти с JIT compilation, CPU cache и I/O, давая целостную картину оптимизации. Рекомендуется использовать performance overview как карту для навигации между детальными материалами.

**[[kotlin-coroutines]]** — coroutines создают continuations — объекты, хранящие состояние приостановленной функции в heap. В отличие от platform threads с мегабайтными стеками, coroutine continuation занимает десятки-сотни байт. Понимание memory model помогает оценить memory footprint тысяч одновременных coroutines и их влияние на GC. Рекомендуется изучить memory model перед оптимизацией coroutine-heavy приложений.

**[[caching-strategies]]** — кэширование в JVM-приложениях напрямую связано с управлением памятью: unbounded cache — самая частая причина memory leaks. Понимание heap структуры помогает правильно dimensionировать кэши (какую часть Old Gen они могут занять), выбирать eviction policy и использовать WeakReference/SoftReference для GC-friendly кэшей. Memory model объясняет, почему Soft References предпочтительнее Weak References для кэшей: GC удаляет Soft References только при нехватке памяти, а Weak — при любой сборке.

**[[microservices-vs-monolith]]** — архитектурный выбор между микросервисами и монолитом напрямую влияет на потребление памяти. Каждый JVM-процесс несёт фиксированный overhead: Metaspace, thread stacks, JIT code cache, GC structures. Монолит оплачивает этот overhead один раз, микросервисы — для каждого сервиса. При 20 микросервисах с overhead ~300MB каждый — это 6GB только на инфраструктуру JVM. Понимание memory model помогает обосновать архитектурные решения конкретными цифрами.

---

## Источники и дальнейшее чтение

- Goetz B. et al. (2006). *Java Concurrency in Practice.* — Каноническое объяснение happens-before, volatile и synchronized. Без этой книги невозможно понять visibility и ordering гарантии JMM. Главы 3 (Sharing Objects) и 16 (Java Memory Model) — must-read для любого Java-разработчика.

- Lindholm T. et al. (2014). *The Java Virtual Machine Specification, Java SE 8 Edition.* — Формальное описание runtime data areas: heap, method area, stacks, program counter. Это первоисточник — всё остальное является интерпретацией этой спецификации. Глава 2.5 (Runtime Data Areas) содержит точные определения каждой области памяти.

- Oaks S. (2014). *Java Performance: The Definitive Guide.* — Практическое руководство по GC tuning, heap sizing и memory diagnostics. Связывает теорию memory model с production-задачами: как выбрать размер heap, какой GC использовать, как интерпретировать GC logs. Второе издание (2020) добавляет контейнеры и Java 11.

- Shipilev A. (2014-2023). *JVM Anatomy Quarks (blog series).* — Серия коротких статей от разработчика OpenJDK о внутреннем устройстве JVM. Каждая статья разбирает одну тему (TLAB, compressed oops, object layout) с benchmarks и jol-инструментарием. Лучший источник для понимания деталей реализации.

---

*Проверено: 2026-02-11 | Педагогический контент проверен — Уровень достоверности: high*
